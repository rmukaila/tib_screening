{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8f82f5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keyphrase_vectorizers import KeyphraseCountVectorizer\n",
    "from keybert import KeyBERT\n",
    "from keyphrase_vectorizers import KeyphraseCountVectorizer\n",
    "from helpers import get_preprocessed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3b7be57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preprocessing\n",
    "#Both the training and test data were cloned into\n",
    "#separate local repositories as training-data and test-data respectively\n",
    "\n",
    "training_data_path = \"../../ncg_task_repo/training-data/*/*/info-units/research-problem.json\"\n",
    "test_data_path = \"../../ncg_task_repo/test-data/*/*/info-units/research-problem.json\"\n",
    "\n",
    "#Create a dict of all the the research problem sentence and respective phrase\n",
    "research_keyPhrase_and_sentence_dict, json_cnts = get_preprocessed_data(training_data_path)\n",
    "test_keyPhrase_and_sentence_dict, test_json_cnts = get_preprocessed_data(test_data_path)\n",
    "train_docs = list(research_keyPhrase_and_sentence_dict.values())\n",
    "test_docs = list(test_keyPhrase_and_sentence_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e512fe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init default vectorizer.\n",
    "vectorizer = KeyphraseCountVectorizer()\n",
    "# print(vectorizer.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "de4f4a95",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# After initializing the vectorizer, it can be fitted\n",
    "# to learn the keyphrases from the text documents.\n",
    "# Afterwards, the vectorizer can transform the documents \n",
    "# to a document-keyphrase matrix.\n",
    "# Matrix rows indicate the documents and columns indicate the unique keyphrases.\n",
    "# Each cell represents the count.\n",
    "\n",
    "document_keyphrase_matrix = vectorizer.fit_transform(train_docs).toarray()\n",
    "print(document_keyphrase_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4cd39ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyphrases = vectorizer.get_feature_names_out()\n",
    "# print(keyphrases[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9339a25c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emotionless/.local/lib/python3.8/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n",
      "  warnings.warn(\n",
      "429it [00:00, 813.58it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[('grapheme', 0.5524),\n",
       "  ('ensemble distillation', 0.5607),\n",
       "  ('phoneme conversion', 0.5855),\n",
       "  ('grapheme phoneme', 0.619),\n",
       "  ('distillation grapheme', 0.7011)],\n",
       " [('speech recognition', 0.5108),\n",
       "  ('g2p conversion', 0.5151),\n",
       "  ('grapheme', 0.5763),\n",
       "  ('phoneme g2p', 0.6582),\n",
       "  ('grapheme phoneme', 0.714)],\n",
       " [('text', 0.4416),\n",
       "  ('fastspeech fast', 0.4664),\n",
       "  ('fastspeech', 0.4749),\n",
       "  ('controllable text', 0.5102),\n",
       "  ('text speech', 0.6574)],\n",
       " [('quality synthesized', 0.3797),\n",
       "  ('end text', 0.3925),\n",
       "  ('speech tts', 0.5316),\n",
       "  ('text speech', 0.5608),\n",
       "  ('synthesized speech', 0.6568)],\n",
       " [('speech', 0.4179),\n",
       "  ('tts', 0.4337),\n",
       "  ('text', 0.4501),\n",
       "  ('text speech', 0.667),\n",
       "  ('speech tts', 0.6833)],\n",
       " [('conventional concatenative', 0.3926),\n",
       "  ('tts', 0.4535),\n",
       "  ('based tts', 0.5223),\n",
       "  ('tts outperformed', 0.5425),\n",
       "  ('speech quality', 0.5495)],\n",
       " [('multispeaker text', 0.5284),\n",
       "  ('learning speaker', 0.6021),\n",
       "  ('speech synthesis', 0.6071),\n",
       "  ('verification multispeaker', 0.6353),\n",
       "  ('speaker verification', 0.6545)],\n",
       " [('speech tts', 0.5544),\n",
       "  ('audio voice', 0.5603),\n",
       "  ('text speech', 0.5781),\n",
       "  ('speech audio', 0.6025),\n",
       "  ('generate speech', 0.6562)],\n",
       " [('speech variety', 0.4912),\n",
       "  ('speakers data', 0.4952),\n",
       "  ('build tts', 0.543),\n",
       "  ('natural speech', 0.551),\n",
       "  ('tts generate', 0.6505)],\n",
       " [('uncertainties', 0.3933),\n",
       "  ('learning document', 0.5116),\n",
       "  ('embeddings', 0.6725),\n",
       "  ('document embeddings', 0.7504),\n",
       "  ('embeddings uncertainties', 0.7875)],\n",
       " [('generative gaussian', 0.4164),\n",
       "  ('embeddings', 0.4373),\n",
       "  ('classifier topic', 0.4862),\n",
       "  ('document embeddings', 0.5737),\n",
       "  ('topic identification', 0.6279)],\n",
       " [('retrieval speech', 0.4679),\n",
       "  ('information retrieval', 0.4739),\n",
       "  ('embeddings', 0.5086),\n",
       "  ('earning word', 0.5641),\n",
       "  ('document embeddings', 0.5796)],\n",
       " [('recognition', 0.3734),\n",
       "  ('deep learning', 0.4853),\n",
       "  ('smile', 0.6539),\n",
       "  ('learning smile', 0.7288),\n",
       "  ('smile recognition', 0.767)],\n",
       " [('particular smile', 0.4989),\n",
       "  ('networks facial', 0.5046),\n",
       "  ('smile', 0.5173),\n",
       "  ('deep convolutional', 0.5261),\n",
       "  ('smile recognition', 0.6651)],\n",
       " [('audio text', 0.4978),\n",
       "  ('multimodal', 0.5127),\n",
       "  ('emotion recognition', 0.5697),\n",
       "  ('speech emotion', 0.6328),\n",
       "  ('multimodal speech', 0.6645)],\n",
       " [('rotatory attention', 0.3804),\n",
       "  ('based sentiment', 0.4118),\n",
       "  ('aspect based', 0.4349),\n",
       "  ('sentiment analysis', 0.4562),\n",
       "  ('separated neural', 0.4819)],\n",
       " [('classification aspect', 0.5331),\n",
       "  ('sentiment classification', 0.5439),\n",
       "  ('aspect based', 0.5931),\n",
       "  ('aspect sentiment', 0.6826),\n",
       "  ('aspect extraction', 0.6875)],\n",
       " [('emotion detection', 0.519),\n",
       "  ('dialoguernn', 0.5474),\n",
       "  ('attentive rnn', 0.5849),\n",
       "  ('dialoguernn attentive', 0.5921),\n",
       "  ('rnn emotion', 0.6519)],\n",
       " [('fine grained', 0.4573),\n",
       "  ('using bert', 0.4867),\n",
       "  ('sentiment', 0.4949),\n",
       "  ('sentiment classification', 0.6776),\n",
       "  ('grained sentiment', 0.7254)],\n",
       " [('service topic', 0.338),\n",
       "  ('classification important', 0.4944),\n",
       "  ('classification', 0.4997),\n",
       "  ('sentiment', 0.5611),\n",
       "  ('sentiment classification', 0.7783)],\n",
       " [('network multimodal', 0.4727),\n",
       "  ('interactive conversational', 0.5286),\n",
       "  ('emotion detection', 0.5441),\n",
       "  ('conversational memory', 0.6127),\n",
       "  ('multimodal emotion', 0.6519)],\n",
       " [('emotion', 0.4718),\n",
       "  ('development empathetic', 0.4841),\n",
       "  ('empathetic', 0.5519),\n",
       "  ('emotion recognition', 0.6142),\n",
       "  ('empathetic machines', 0.7046)],\n",
       " [('emotional', 0.4734),\n",
       "  ('conversations', 0.6032),\n",
       "  ('dynamics conversations', 0.6978),\n",
       "  ('emotional dynamics', 0.7226),\n",
       "  ('analyzing emotional', 0.7344)],\n",
       " [('contextual inter', 0.4886),\n",
       "  ('attention multi', 0.547),\n",
       "  ('multi modal', 0.5609),\n",
       "  ('modal attention', 0.6077),\n",
       "  ('modal sentiment', 0.6182)],\n",
       " [('task sentiment', 0.5245),\n",
       "  ('aspect level', 0.5382),\n",
       "  ('level sentiment', 0.5662),\n",
       "  ('sentiment analysis', 0.5804),\n",
       "  ('sentiment classification', 0.6651)],\n",
       " [('aspect level', 0.4511),\n",
       "  ('attention neural', 0.4709),\n",
       "  ('classification attention', 0.5048),\n",
       "  ('level sentiment', 0.5565),\n",
       "  ('sentiment classification', 0.6115)],\n",
       " [('classification tasks', 0.5074),\n",
       "  ('reviews determining', 0.5277),\n",
       "  ('binary sentiment', 0.5982),\n",
       "  ('document classification', 0.6733),\n",
       "  ('sentiment classification', 0.6807)],\n",
       " [('opinions text', 0.5208),\n",
       "  ('level sentiment', 0.5451),\n",
       "  ('aspect level', 0.5472),\n",
       "  ('classification aspect', 0.6087),\n",
       "  ('sentiment classification', 0.6505)],\n",
       " [('memory aspect', 0.4524),\n",
       "  ('sentiment analysis', 0.4719),\n",
       "  ('recurrent attention', 0.5279),\n",
       "  ('attention network', 0.5281),\n",
       "  ('aspect sentiment', 0.5754)],\n",
       " [('network emotion', 0.4591),\n",
       "  ('emotion recognition', 0.4723),\n",
       "  ('dyadic dialogue', 0.499),\n",
       "  ('conversational memory', 0.5589),\n",
       "  ('dialogue videos', 0.5598)],\n",
       " [('detection videos', 0.434),\n",
       "  ('analyze emotion', 0.5008),\n",
       "  ('videos dyadic', 0.5454),\n",
       "  ('emotion detection', 0.5714),\n",
       "  ('dyadic conversations', 0.5859)],\n",
       " [('emotion', 0.4222),\n",
       "  ('chatbots', 0.4427),\n",
       "  ('opinion mining', 0.4547),\n",
       "  ('homes chatbots', 0.4849),\n",
       "  ('emotion detection', 0.6363)],\n",
       " [('aspect', 0.3943),\n",
       "  ('networks aspect', 0.42),\n",
       "  ('memory networks', 0.4728),\n",
       "  ('sentiment classification', 0.5751),\n",
       "  ('aspect sentiment', 0.6161)],\n",
       " [('aspect', 0.4773),\n",
       "  ('sentiment analysis', 0.5243),\n",
       "  ('classification asc', 0.5404),\n",
       "  ('sentiment classification', 0.6113),\n",
       "  ('aspect sentiment', 0.6804)],\n",
       " [('major drawback', 0.4495),\n",
       "  ('existing attention', 0.4834),\n",
       "  ('mechanism asc', 0.5034),\n",
       "  ('attention mechanism', 0.519),\n",
       "  ('asc suffers', 0.5804)],\n",
       " [('supervised aspect', 0.4487),\n",
       "  ('variational semi', 0.4593),\n",
       "  ('semi supervised', 0.4632),\n",
       "  ('term sentiment', 0.5262),\n",
       "  ('sentiment analysis', 0.5451)],\n",
       " [('analysis absa', 0.5222),\n",
       "  ('atsa aspect', 0.5488),\n",
       "  ('aspect term', 0.5598),\n",
       "  ('aspect based', 0.5684),\n",
       "  ('aspect category', 0.5931)],\n",
       " [('sentiment polarity', 0.4934),\n",
       "  ('goal acsa', 0.53),\n",
       "  ('predict sentiment', 0.5346),\n",
       "  ('acsa', 0.5559),\n",
       "  ('acsa predict', 0.6246)],\n",
       " [('sentiment polarity', 0.3668),\n",
       "  ('multi word', 0.4222),\n",
       "  ('atsa identify', 0.4886),\n",
       "  ('goal atsa', 0.4924),\n",
       "  ('atsa', 0.5187)],\n",
       " [('graph', 0.3401),\n",
       "  ('eeg based', 0.4201),\n",
       "  ('regularized graph', 0.4564),\n",
       "  ('emotion recognition', 0.4977),\n",
       "  ('graph neural', 0.5491)],\n",
       " [('emotions', 0.4639),\n",
       "  ('emotions based', 0.493),\n",
       "  ('human emotions', 0.506),\n",
       "  ('motion recognition', 0.5363),\n",
       "  ('affective computing', 0.6078)],\n",
       " [('encoder network', 0.4522),\n",
       "  ('sentiment classification', 0.5058),\n",
       "  ('attentional', 0.5071),\n",
       "  ('targeted sentiment', 0.6097),\n",
       "  ('attentional encoder', 0.7187)],\n",
       " [('aspect level', 0.479),\n",
       "  ('level sentiment', 0.5429),\n",
       "  ('sentiment analysis', 0.5491),\n",
       "  ('sentiment classification', 0.5885),\n",
       "  ('grained sentiment', 0.6923)],\n",
       " [('sentiment', 0.4148),\n",
       "  ('grained targeted', 0.4276),\n",
       "  ('models infancy', 0.4391),\n",
       "  ('sentiment classification', 0.5502),\n",
       "  ('targeted sentiment', 0.5749)],\n",
       " [('task deep', 0.3883),\n",
       "  ('sentiment analysis', 0.4448),\n",
       "  ('lstm', 0.5457),\n",
       "  ('lstm attention', 0.5904),\n",
       "  ('deep lstm', 0.5924)],\n",
       " [('twitter', 0.4454),\n",
       "  ('sentiment', 0.4653),\n",
       "  ('analysis twitter', 0.4759),\n",
       "  ('sentiment analysis', 0.5018),\n",
       "  ('task sentiment', 0.5104)],\n",
       " [('extraction sarcasm', 0.4371),\n",
       "  ('nlp sub', 0.4379),\n",
       "  ('sentiment', 0.4948),\n",
       "  ('aspect extraction', 0.5161),\n",
       "  ('sentiment analysis', 0.6758)],\n",
       " [('based sentiment', 0.4463),\n",
       "  ('aspect based', 0.4664),\n",
       "  ('convolutional networks', 0.4665),\n",
       "  ('sentiment analysis', 0.5204),\n",
       "  ('gated convolutional', 0.5304)],\n",
       " [('predict sentiment', 0.4812),\n",
       "  ('absa', 0.5067),\n",
       "  ('aspect based', 0.542),\n",
       "  ('analysis absa', 0.5572),\n",
       "  ('sentiment analysis', 0.5907)],\n",
       " [('term sentiment', 0.5124),\n",
       "  ('aspect', 0.5254),\n",
       "  ('category sentiment', 0.5588),\n",
       "  ('aspect term', 0.5607),\n",
       "  ('aspect category', 0.6185)],\n",
       " [('bearing phrases', 0.4743),\n",
       "  ('aspects', 0.5047),\n",
       "  ('absa classifier', 0.5673),\n",
       "  ('sentiment bearing', 0.5731),\n",
       "  ('aspects sentiment', 0.6451)],\n",
       " [('aspect level', 0.4399),\n",
       "  ('effective attention', 0.4604),\n",
       "  ('level sentiment', 0.4942),\n",
       "  ('sentiment classification', 0.5725),\n",
       "  ('attention modeling', 0.5841)],\n",
       " [('learning aspect', 0.4041),\n",
       "  ('level sentiment', 0.4046),\n",
       "  ('sentiment analysis', 0.4366),\n",
       "  ('supervised attention', 0.4599),\n",
       "  ('attention learning', 0.4976)],\n",
       " [('neural', 0.4378),\n",
       "  ('attention mechanisms', 0.4504),\n",
       "  ('models attention', 0.4552),\n",
       "  ('level sentiment', 0.4919),\n",
       "  ('sentiment classification', 0.5247)],\n",
       " [('useful attention', 0.5414),\n",
       "  ('refine attention', 0.5525),\n",
       "  ('attention supervision', 0.5974),\n",
       "  ('attention learning', 0.6074),\n",
       "  ('supervised attention', 0.6322)],\n",
       " [('aspects', 0.5335),\n",
       "  ('aspect level', 0.5474),\n",
       "  ('classification asc', 0.5772),\n",
       "  ('aspect category', 0.5837),\n",
       "  ('aspect term', 0.5897)],\n",
       " [('neural networks', 0.5258),\n",
       "  ('recurrent neural', 0.5516),\n",
       "  ('convolutional neural', 0.5883),\n",
       "  ('networks recurrent', 0.6679),\n",
       "  ('neural filters', 0.669)],\n",
       " [('rnns naturally', 0.4724),\n",
       "  ('convolution filters', 0.4887),\n",
       "  ('rnns', 0.4928),\n",
       "  ('capture compositionality', 0.4946),\n",
       "  ('filters rnns', 0.6696)],\n",
       " [('improved semantic', 0.4858),\n",
       "  ('representations tree', 0.513),\n",
       "  ('memory networks', 0.5727),\n",
       "  ('term memory', 0.5791),\n",
       "  ('semantic representations', 0.6362)],\n",
       " [('lstms outperform', 0.522),\n",
       "  ('lstm', 0.5269),\n",
       "  ('predicting semantic', 0.5632),\n",
       "  ('sentiment treebank', 0.5848),\n",
       "  ('tree lstms', 0.5853)],\n",
       " [('attention', 0.3861),\n",
       "  ('sentiment analysis', 0.4519),\n",
       "  ('level sentiment', 0.4612),\n",
       "  ('attention network', 0.5554),\n",
       "  ('bidirectional attention', 0.6106)],\n",
       " [('iemocap', 0.5),\n",
       "  ('emotion recognition', 0.5964),\n",
       "  ('recognition iemocap', 0.5993),\n",
       "  ('iemocap neural', 0.6241),\n",
       "  ('modal emotion', 0.6294)],\n",
       " [('sentiment caused', 0.5389),\n",
       "  ('sentiment', 0.5441),\n",
       "  ('emotion recognition', 0.5679),\n",
       "  ('positive sentiment', 0.6121),\n",
       "  ('negative sentiment', 0.6305)],\n",
       " [('eeg', 0.4698),\n",
       "  ('emotion recognition', 0.4762),\n",
       "  ('hemispheric discrepancy', 0.5243),\n",
       "  ('model eeg', 0.5345),\n",
       "  ('eeg emotion', 0.6372)],\n",
       " [('differences hemispheres', 0.5104),\n",
       "  ('eeg emotion', 0.5671),\n",
       "  ('electroencephalograph', 0.5695),\n",
       "  ('electroencephalograph eeg', 0.5934),\n",
       "  ('hemispheres electroencephalograph', 0.6658)],\n",
       " [('emotions', 0.4538),\n",
       "  ('human machine', 0.4653),\n",
       "  ('emotions emotion', 0.5151),\n",
       "  ('human emotions', 0.5722),\n",
       "  ('emotion recognition', 0.6131)],\n",
       " [('tree', 0.4406),\n",
       "  ('neural sentence', 0.4422),\n",
       "  ('tree based', 0.4605),\n",
       "  ('discriminative neural', 0.5349),\n",
       "  ('sentence modeling', 0.5396)],\n",
       " [('bert', 0.4543),\n",
       "  ('aspect based', 0.49),\n",
       "  ('sentiment analysis', 0.4945),\n",
       "  ('utilizing bert', 0.5505),\n",
       "  ('bert aspect', 0.6544)],\n",
       " [('aspect', 0.4813),\n",
       "  ('absa aims', 0.4972),\n",
       "  ('analysis absa', 0.5042),\n",
       "  ('aspect based', 0.5322),\n",
       "  ('sentiment analysis', 0.6031)],\n",
       " [('multi grained', 0.4337),\n",
       "  ('level sentiment', 0.4546),\n",
       "  ('sentiment classification', 0.4896),\n",
       "  ('grained attention', 0.5204),\n",
       "  ('attention network', 0.5366)],\n",
       " [('aspect mentions', 0.554),\n",
       "  ('aspect term', 0.5665),\n",
       "  ('sentiment orientation', 0.5766),\n",
       "  ('extracted aspect', 0.6162),\n",
       "  ('detecting sentiment', 0.6341)],\n",
       " [('aspect level', 0.3766),\n",
       "  ('attention based', 0.4368),\n",
       "  ('sentiment analysis', 0.4528),\n",
       "  ('level sentiment', 0.4793),\n",
       "  ('hierarchical attention', 0.5148)],\n",
       " [('aspect', 0.5334),\n",
       "  ('aspect level', 0.5536),\n",
       "  ('level sentiment', 0.5609),\n",
       "  ('identify sentiment', 0.61),\n",
       "  ('sentiment classification', 0.6479)],\n",
       " [('sentiment', 0.4281),\n",
       "  ('networks target', 0.4711),\n",
       "  ('transformation networks', 0.5267),\n",
       "  ('oriented sentiment', 0.5508),\n",
       "  ('sentiment classification', 0.6427)],\n",
       " [('level sentiment', 0.475),\n",
       "  ('based lstm', 0.5317),\n",
       "  ('lstm', 0.5361),\n",
       "  ('sentiment classification', 0.5629),\n",
       "  ('lstm aspect', 0.6741)],\n",
       " [('rnns', 0.5148),\n",
       "  ('networks rnns', 0.5176),\n",
       "  ('sentiment analysis', 0.5326),\n",
       "  ('rnns attention', 0.5492),\n",
       "  ('oriented sentiment', 0.559)],\n",
       " [('knowledge enriched', 0.3851),\n",
       "  ('enriched transformer', 0.3994),\n",
       "  ('textual conversations', 0.4646),\n",
       "  ('emotion detection', 0.4803),\n",
       "  ('transformer emotion', 0.5286)],\n",
       " [('emotions', 0.4723),\n",
       "  ('textual conversations', 0.5484),\n",
       "  ('opinion mining', 0.595),\n",
       "  ('detecting emotions', 0.6625),\n",
       "  ('emotions textual', 0.725)],\n",
       " [('angry textual', 0.592),\n",
       "  ('textual conversations', 0.6133),\n",
       "  ('emotion utterance', 0.6607),\n",
       "  ('conversations emotion', 0.6676),\n",
       "  ('detecting emotions', 0.6845)],\n",
       " [('emotion', 0.4556),\n",
       "  ('emo2', 0.4859),\n",
       "  ('emo2 vec', 0.526),\n",
       "  ('generalized emotion', 0.5711),\n",
       "  ('emotion representation', 0.6257)],\n",
       " [('cosine similarity', 0.401),\n",
       "  ('embeddings', 0.4506),\n",
       "  ('embeddings trained', 0.4929),\n",
       "  ('document embeddings', 0.5075),\n",
       "  ('sentiment classification', 0.6436)],\n",
       " [('classification aspect', 0.4391),\n",
       "  ('chinese oriented', 0.4557),\n",
       "  ('polarity classification', 0.4631),\n",
       "  ('aspect term', 0.5198),\n",
       "  ('aspect polarity', 0.5406)],\n",
       " [('subtask aspect', 0.4215),\n",
       "  ('term extraction', 0.4987),\n",
       "  ('term polarity', 0.5017),\n",
       "  ('aspect', 0.5772),\n",
       "  ('aspect term', 0.6861)],\n",
       " [('chinese review', 0.3894),\n",
       "  ('aspect', 0.3913),\n",
       "  ('aspect term', 0.4609),\n",
       "  ('term extraction', 0.4771),\n",
       "  ('aspect polarity', 0.4909)],\n",
       " [('aspects', 0.533),\n",
       "  ('aspect based', 0.5747),\n",
       "  ('aspects predict', 0.582),\n",
       "  ('extract aspects', 0.5847),\n",
       "  ('sentiment analysis', 0.6286)],\n",
       " [('classification problem', 0.5209),\n",
       "  ('classification', 0.5278),\n",
       "  ('task kind', 0.5352),\n",
       "  ('apc', 0.6065),\n",
       "  ('apc task', 0.8029)],\n",
       " [('deep learning', 0.4537),\n",
       "  ('lstm methodologies', 0.4772),\n",
       "  ('lstm', 0.4837),\n",
       "  ('apc tasks', 0.5374),\n",
       "  ('memory lstm', 0.5566)],\n",
       " [('treebank', 0.5244),\n",
       "  ('recursive deep', 0.5479),\n",
       "  ('semantic compositionality', 0.6353),\n",
       "  ('compositionality sentiment', 0.672),\n",
       "  ('sentiment treebank', 0.7236)],\n",
       " [('sentiment detection', 0.5581),\n",
       "  ('tasks sentiment', 0.5595),\n",
       "  ('compositionality', 0.575),\n",
       "  ('understanding compositionality', 0.6152),\n",
       "  ('compositionality tasks', 0.6579)],\n",
       " [('sentiment', 0.4001),\n",
       "  ('sentiment analysis', 0.4413),\n",
       "  ('learning deep', 0.4447),\n",
       "  ('transfer learning', 0.5413),\n",
       "  ('deep sentiment', 0.5853)],\n",
       " [('sentiment', 0.4808),\n",
       "  ('deep neural', 0.5026),\n",
       "  ('polarity classification', 0.5295),\n",
       "  ('sentiment polarity', 0.6036),\n",
       "  ('supervised sentiment', 0.65)],\n",
       " [('sentiment', 0.4447),\n",
       "  ('sentiment analyser', 0.5779),\n",
       "  ('arabic', 0.5791),\n",
       "  ('online arabic', 0.6288),\n",
       "  ('arabic sentiment', 0.802)],\n",
       " [('natural language', 0.417),\n",
       "  ('analysis sa', 0.4285),\n",
       "  ('sentiment', 0.4655),\n",
       "  ('sa useful', 0.5024),\n",
       "  ('sentiment analysis', 0.6518)],\n",
       " [('tasks comment', 0.44),\n",
       "  ('sentence level', 0.4412),\n",
       "  ('absa', 0.4687),\n",
       "  ('sa absa', 0.4907),\n",
       "  ('absa sentence', 0.5837)],\n",
       " [('bidirectional', 0.4059),\n",
       "  ('suffix bidirectional', 0.5367),\n",
       "  ('lstm', 0.5833),\n",
       "  ('sentence modeling', 0.6453),\n",
       "  ('bidirectional lstm', 0.6959)],\n",
       " [('sequential data', 0.4435),\n",
       "  ('recurrent', 0.4442),\n",
       "  ('textual', 0.4644),\n",
       "  ('textual data', 0.5325),\n",
       "  ('recurrent neural', 0.5843)],\n",
       " [('fine grained', 0.402),\n",
       "  ('sentiment', 0.4129),\n",
       "  ('question classification', 0.4867),\n",
       "  ('sentiment classification', 0.6078),\n",
       "  ('grained sentiment', 0.6626)],\n",
       " [('rnn', 0.5394),\n",
       "  ('networks rnn', 0.6164),\n",
       "  ('recurrent neural', 0.6369),\n",
       "  ('sequential data', 0.6505),\n",
       "  ('modeling sequential', 0.6537)],\n",
       " [('ambiguity resolution', 0.4616),\n",
       "  ('multimodal', 0.5368),\n",
       "  ('emotion recognition', 0.5689),\n",
       "  ('speech emotion', 0.6328),\n",
       "  ('multimodal speech', 0.6776)],\n",
       " [('speech nontrivial', 0.532),\n",
       "  ('emotion', 0.5371),\n",
       "  ('definition emotion', 0.6032),\n",
       "  ('emotion speech', 0.6597),\n",
       "  ('identifying emotion', 0.6686)],\n",
       " [('task speech', 0.3936),\n",
       "  ('deep learning', 0.4039),\n",
       "  ('recognition ser', 0.4273),\n",
       "  ('emotion recognition', 0.5763),\n",
       "  ('speech emotion', 0.6017)],\n",
       " [('features', 0.4137),\n",
       "  ('learning models', 0.4229),\n",
       "  ('features ser', 0.4744),\n",
       "  ('models heavily', 0.4749),\n",
       "  ('deep learning', 0.5035)],\n",
       " [('delayed memory', 0.4206),\n",
       "  ('sentiment analysis', 0.4593),\n",
       "  ('targeted aspect', 0.4651),\n",
       "  ('aspect based', 0.4713),\n",
       "  ('recurrent entity', 0.5525)],\n",
       " [('sentiment', 0.5),\n",
       "  ('aspect based', 0.5145),\n",
       "  ('targeted aspect', 0.5458),\n",
       "  ('based sentiment', 0.5468),\n",
       "  ('sentiment analysis', 0.5606)],\n",
       " [('sentiment', 0.3759),\n",
       "  ('length vector', 0.4015),\n",
       "  ('classification document', 0.4328),\n",
       "  ('level sentiment', 0.4533),\n",
       "  ('sentiment classification', 0.5971)],\n",
       " [('learning systems', 0.4611),\n",
       "  ('learning', 0.4744),\n",
       "  ('representation', 0.4864),\n",
       "  ('machine learning', 0.5118),\n",
       "  ('representation learning', 0.6217)],\n",
       " [('discourse', 0.4876),\n",
       "  ('sentence level', 0.4895),\n",
       "  ('level discourse', 0.5181),\n",
       "  ('parsing sentiment', 0.5675),\n",
       "  ('discourse parsing', 0.6782)],\n",
       " [('dataset urban', 0.463),\n",
       "  ('aspect', 0.4805),\n",
       "  ('urban neighbourhoods', 0.482),\n",
       "  ('aspect based', 0.5159),\n",
       "  ('targeted aspect', 0.5369)],\n",
       " [('aspect', 0.5096),\n",
       "  ('based sentiment', 0.5603),\n",
       "  ('sentiment analysis', 0.5873),\n",
       "  ('aspect based', 0.5926),\n",
       "  ('targeted aspect', 0.613)],\n",
       " [('opinion polarities', 0.4545),\n",
       "  ('sentiment', 0.4957),\n",
       "  ('sentences tweet', 0.5756),\n",
       "  ('sentiment analysis', 0.5869),\n",
       "  ('targeted sentiment', 0.792)],\n",
       " [('content aspect', 0.5645),\n",
       "  ('level sentiment', 0.5748),\n",
       "  ('sentiment polarity', 0.6019),\n",
       "  ('sentiment classification', 0.673),\n",
       "  ('classification sentiment', 0.6915)],\n",
       " [('context dependent', 0.4214),\n",
       "  ('sentiment', 0.4583),\n",
       "  ('generated videos', 0.4807),\n",
       "  ('sentiment analysis', 0.507),\n",
       "  ('dependent sentiment', 0.5089)],\n",
       " [('identification sentiments', 0.5145),\n",
       "  ('sentiment analysis', 0.5585),\n",
       "  ('multimodal', 0.5838),\n",
       "  ('sentiments videos', 0.6029),\n",
       "  ('multimodal sentiment', 0.8132)],\n",
       " [('sentiment', 0.4407),\n",
       "  ('sentiment analysis', 0.5547),\n",
       "  ('multimodal', 0.5963),\n",
       "  ('approaches multimodal', 0.623),\n",
       "  ('multimodal sentiment', 0.8566)],\n",
       " [('semantic sentence', 0.4568),\n",
       "  ('embeddings', 0.4953),\n",
       "  ('embeddings using', 0.4966),\n",
       "  ('learning semantic', 0.5737),\n",
       "  ('sentence embeddings', 0.6908)],\n",
       " [('sentence', 0.3195),\n",
       "  ('obtaining sentence', 0.4347),\n",
       "  ('sentence level', 0.5527),\n",
       "  ('level embeddings', 0.636),\n",
       "  ('embeddings', 0.6392)],\n",
       " [('generative', 0.4397),\n",
       "  ('framework paraphrase', 0.515),\n",
       "  ('deep generative', 0.5289),\n",
       "  ('paraphrase', 0.592),\n",
       "  ('paraphrase generation', 0.8594)],\n",
       " [('problem generating', 0.3787),\n",
       "  ('generating', 0.4277),\n",
       "  ('paraphrases', 0.7236),\n",
       "  ('paraphrases automatically', 0.8624),\n",
       "  ('generating paraphrases', 0.919)],\n",
       " [('semantics', 0.4371),\n",
       "  ('semantics gated', 0.5265),\n",
       "  ('knowledge base', 0.5293),\n",
       "  ('modeling semantics', 0.5641),\n",
       "  ('question answering', 0.5999)],\n",
       " [('qa important', 0.4736),\n",
       "  ('qa', 0.4771),\n",
       "  ('answering qa', 0.5875),\n",
       "  ('knowledge base', 0.5985),\n",
       "  ('question answering', 0.6498)],\n",
       " [('qa', 0.4861),\n",
       "  ('feed qa', 0.4873),\n",
       "  ('sentences feed', 0.5016),\n",
       "  ('qa model', 0.5287),\n",
       "  ('sentence selector', 0.6686)],\n",
       " [('semantic', 0.5463),\n",
       "  ('kb qa', 0.5952),\n",
       "  ('parsing', 0.612),\n",
       "  ('parsing approach', 0.613),\n",
       "  ('semantic parsing', 0.7215)],\n",
       " [('queries answered', 0.4466),\n",
       "  ('reading', 0.4572),\n",
       "  ('comprehension', 0.5149),\n",
       "  ('comprehension methods', 0.6477),\n",
       "  ('reading comprehension', 0.6903)],\n",
       " [('reading', 0.4581),\n",
       "  ('textual evidence', 0.519),\n",
       "  ('comprehension', 0.5628),\n",
       "  ('comprehension rc', 0.6285),\n",
       "  ('reading comprehension', 0.6949)],\n",
       " [('assess rc', 0.4159),\n",
       "  ('answering conventionally', 0.4598),\n",
       "  ('children learning', 0.478),\n",
       "  ('learning read', 0.5289),\n",
       "  ('question answering', 0.5797)],\n",
       " [('answer pointer', 0.5931),\n",
       "  ('match lstm', 0.6103),\n",
       "  ('comprehension using', 0.6121),\n",
       "  ('lstm answer', 0.6332),\n",
       "  ('machine comprehension', 0.706)],\n",
       " [('mc gained', 0.3937),\n",
       "  ('mc', 0.4617),\n",
       "  ('comprehension', 0.472),\n",
       "  ('machine comprehension', 0.6446),\n",
       "  ('comprehension mc', 0.6887)],\n",
       " [('lexical understanding', 0.3844),\n",
       "  ('mc', 0.3971),\n",
       "  ('approaches mc', 0.5175),\n",
       "  ('answer extraction', 0.5669),\n",
       "  ('mc task', 0.626)],\n",
       " [('answering', 0.4038),\n",
       "  ('neural models', 0.4253),\n",
       "  ('qa documents', 0.4617),\n",
       "  ('answering qa', 0.5192),\n",
       "  ('question answering', 0.6434)],\n",
       " [('visual text', 0.5308),\n",
       "  ('attention', 0.5412),\n",
       "  ('focal visual', 0.5586),\n",
       "  ('text attention', 0.6126),\n",
       "  ('attention visual', 0.6288)],\n",
       " [('visual question', 0.4715),\n",
       "  ('vqa', 0.5177),\n",
       "  ('visual', 0.5182),\n",
       "  ('question answering', 0.5561),\n",
       "  ('answering vqa', 0.6094)],\n",
       " [('image paper', 0.4295),\n",
       "  ('vqa single', 0.4757),\n",
       "  ('single image', 0.4852),\n",
       "  ('vqa', 0.5332),\n",
       "  ('extending vqa', 0.6914)],\n",
       " [('answering', 0.4334),\n",
       "  ('ranking open', 0.462),\n",
       "  ('evidence aggregation', 0.5336),\n",
       "  ('question answering', 0.5594),\n",
       "  ('answer ranking', 0.6298)],\n",
       " [('qa', 0.4608),\n",
       "  ('answer questions', 0.4679),\n",
       "  ('domain knowledge', 0.5265),\n",
       "  ('question answering', 0.5879),\n",
       "  ('answering qa', 0.6394)],\n",
       " [('qa', 0.4114),\n",
       "  ('domain qa', 0.4653),\n",
       "  ('datasets', 0.4945),\n",
       "  ('datasets squad', 0.5613),\n",
       "  ('qa datasets', 0.6631)],\n",
       " [('scientific publications', 0.4866),\n",
       "  ('intent classification', 0.5364),\n",
       "  ('citation', 0.5451),\n",
       "  ('scaffolds citation', 0.5593),\n",
       "  ('citation intent', 0.6966)],\n",
       " [('scientific papers', 0.5318),\n",
       "  ('citation', 0.5506),\n",
       "  ('intent citation', 0.5521),\n",
       "  ('publications automated', 0.5673),\n",
       "  ('citation scientific', 0.7131)],\n",
       " [('citation', 0.5003),\n",
       "  ('expressed citation', 0.5167),\n",
       "  ('citation context', 0.5847),\n",
       "  ('intent classification', 0.644),\n",
       "  ('citation intent', 0.7153)],\n",
       " [('sequential sentence', 0.449),\n",
       "  ('classification medical', 0.4669),\n",
       "  ('hierarchical neural', 0.5028),\n",
       "  ('scientific abstracts', 0.5331),\n",
       "  ('sentence classification', 0.6045)],\n",
       " [('better classification', 0.4693),\n",
       "  ('sequential sentence', 0.5159),\n",
       "  ('structured prediction', 0.5909),\n",
       "  ('classification structured', 0.6193),\n",
       "  ('sentence classification', 0.7457)],\n",
       " [('contexts sentence', 0.5204),\n",
       "  ('translations', 0.5428),\n",
       "  ('additional contexts', 0.5818),\n",
       "  ('translations additional', 0.6028),\n",
       "  ('sentence classification', 0.6831)],\n",
       " [('based evaluator', 0.5111),\n",
       "  ('evaluator', 0.5288),\n",
       "  ('language model', 0.5394),\n",
       "  ('evaluator sentence', 0.5809),\n",
       "  ('sentence compression', 0.7355)],\n",
       " [('compression', 0.4938),\n",
       "  ('lstms', 0.5964),\n",
       "  ('compression deletion', 0.6008),\n",
       "  ('deletion lstms', 0.6755),\n",
       "  ('sentence compression', 0.7606)],\n",
       " [('modelbased evaluator', 0.4491),\n",
       "  ('evaluator', 0.4586),\n",
       "  ('deletion evaluation', 0.5517),\n",
       "  ('evaluator deletion', 0.5731),\n",
       "  ('sentence compression', 0.6917)],\n",
       " [('paraphrase sentence', 0.5269),\n",
       "  ('paraphrase', 0.5321),\n",
       "  ('compression', 0.5537),\n",
       "  ('shorter paraphrase', 0.6067),\n",
       "  ('sentence compression', 0.8144)],\n",
       " [('learning predict', 0.4503),\n",
       "  ('compression learning', 0.5197),\n",
       "  ('gaze', 0.5301),\n",
       "  ('sentence compression', 0.5861),\n",
       "  ('predict gaze', 0.6616)],\n",
       " [('word representations', 0.4992),\n",
       "  ('prominence text', 0.5076),\n",
       "  ('prosodic', 0.5989),\n",
       "  ('predicting prosodic', 0.7179),\n",
       "  ('prosodic prominence', 0.7227)],\n",
       " [('language processing', 0.4214),\n",
       "  ('prominence written', 0.4923),\n",
       "  ('prosodic', 0.5679),\n",
       "  ('predicting prosodic', 0.6648),\n",
       "  ('prosodic prominence', 0.684)],\n",
       " [('word text', 0.447),\n",
       "  ('emphasis speaker', 0.4517),\n",
       "  ('sequence labeling', 0.5777),\n",
       "  ('prosody', 0.5829),\n",
       "  ('prosody prediction', 0.7406)],\n",
       " [('sql task', 0.4355),\n",
       "  ('parsing', 0.4379),\n",
       "  ('text sql', 0.4434),\n",
       "  ('domain semantic', 0.4929),\n",
       "  ('semantic parsing', 0.553)],\n",
       " [('semantic', 0.5854),\n",
       "  ('parsing', 0.672),\n",
       "  ('processing nlp', 0.6872),\n",
       "  ('parsing sp', 0.7125),\n",
       "  ('semantic parsing', 0.8104)],\n",
       " [('shortcomings', 0.4935),\n",
       "  ('datasets', 0.6014),\n",
       "  ('sp shortcomings', 0.6138),\n",
       "  ('existing datasets', 0.6719),\n",
       "  ('datasets sp', 0.685)],\n",
       " [('semantic parsing', 0.5622),\n",
       "  ('parsing code', 0.5726),\n",
       "  ('parser semantic', 0.5785),\n",
       "  ('abstract syntax', 0.6443),\n",
       "  ('syntax parser', 0.6446)],\n",
       " [('parsing', 0.5508),\n",
       "  ('fine decoding', 0.5586),\n",
       "  ('decoding neural', 0.6199),\n",
       "  ('neural semantic', 0.6215),\n",
       "  ('semantic parsing', 0.64)],\n",
       " [('semantic', 0.5304),\n",
       "  ('parsing aims', 0.5472),\n",
       "  ('utterances structured', 0.5733),\n",
       "  ('parsing', 0.6563),\n",
       "  ('semantic parsing', 0.795)],\n",
       " [('negbert transfer', 0.4594),\n",
       "  ('approach negation', 0.4817),\n",
       "  ('negation', 0.5198),\n",
       "  ('transfer learning', 0.5282),\n",
       "  ('negation detection', 0.6424)],\n",
       " [('models generative', 0.6734),\n",
       "  ('generative models', 0.6784),\n",
       "  ('generative model', 0.6789),\n",
       "  ('training generative', 0.7014),\n",
       "  ('generative adversarial', 0.7055)],\n",
       " [('tokens', 0.4542),\n",
       "  ('limitations goal', 0.4928),\n",
       "  ('limitations', 0.5069),\n",
       "  ('generating sequences', 0.5503),\n",
       "  ('discrete tokens', 0.6281)],\n",
       " [('mimics real', 0.4783),\n",
       "  ('data mimics', 0.5314),\n",
       "  ('unsupervised learning', 0.5516),\n",
       "  ('sequential synthetic', 0.6533),\n",
       "  ('synthetic data', 0.7013)],\n",
       " [('thought vectors', 0.4794),\n",
       "  ('adversarial training', 0.5176),\n",
       "  ('skip thought', 0.5262),\n",
       "  ('generating text', 0.5405),\n",
       "  ('text adversarial', 0.6413)],\n",
       " [('embeddings text', 0.5346),\n",
       "  ('gans', 0.5631),\n",
       "  ('gans word', 0.5982),\n",
       "  ('utilizing gans', 0.6204),\n",
       "  ('text generation', 0.6687)],\n",
       " [('sentiment analysis', 0.4591),\n",
       "  ('natural language', 0.472),\n",
       "  ('machine translation', 0.4961),\n",
       "  ('generation tasks', 0.5641),\n",
       "  ('text generation', 0.6773)],\n",
       " [('generation', 0.4701),\n",
       "  ('adversarial', 0.5383),\n",
       "  ('ranking language', 0.5565),\n",
       "  ('adversarial ranking', 0.6421),\n",
       "  ('language generation', 0.7394)],\n",
       " [('leaked information', 0.4801),\n",
       "  ('adversarial', 0.5037),\n",
       "  ('adversarial training', 0.5611),\n",
       "  ('text generation', 0.6537),\n",
       "  ('generation adversarial', 0.702)],\n",
       " [('semantically meaningful', 0.511),\n",
       "  ('captioning', 0.5175),\n",
       "  ('machine translation', 0.5424),\n",
       "  ('text applications', 0.5469),\n",
       "  ('meaningful text', 0.5878)],\n",
       " [('autoencoders', 0.5172),\n",
       "  ('text modeling', 0.528),\n",
       "  ('improved variational', 0.5439),\n",
       "  ('autoencoders text', 0.5631),\n",
       "  ('variational autoencoders', 0.6632)],\n",
       " [('vae lstm', 0.538),\n",
       "  ('autoencoders', 0.5483),\n",
       "  ('lstm decoders', 0.5564),\n",
       "  ('autoencoders vae', 0.5804),\n",
       "  ('variational autoencoders', 0.6634)],\n",
       " [('semantic dependency', 0.4538),\n",
       "  ('dialogue', 0.5348),\n",
       "  ('dependency dialogue', 0.5666),\n",
       "  ('learning utterance', 0.5957),\n",
       "  ('dialogue generation', 0.7221)],\n",
       " [('chatbots', 0.566),\n",
       "  ('domain chatbots', 0.5855),\n",
       "  ('chatbots goal', 0.6069),\n",
       "  ('automatic dialogue', 0.7033),\n",
       "  ('dialogue generation', 0.708)],\n",
       " [('inputs responses', 0.3244),\n",
       "  ('generation', 0.4129),\n",
       "  ('generation complex', 0.4449),\n",
       "  ('conversation', 0.5671),\n",
       "  ('conversation generation', 0.7758)],\n",
       " [('semantic', 0.389),\n",
       "  ('arabic', 0.44),\n",
       "  ('tha3aroon nsurl', 0.5191),\n",
       "  ('question similarity', 0.6065),\n",
       "  ('similarity arabic', 0.6286)],\n",
       " [('nsurl', 0.4922),\n",
       "  ('similarity task', 0.5092),\n",
       "  ('task nsurl', 0.5213),\n",
       "  ('nsurl 2019', 0.5705),\n",
       "  ('question similarity', 0.6495)],\n",
       " [('semantic', 0.4905),\n",
       "  ('similarity', 0.523),\n",
       "  ('semantic text', 0.5675),\n",
       "  ('similarity sts', 0.6708),\n",
       "  ('text similarity', 0.6925)],\n",
       " [('task sts', 0.4844),\n",
       "  ('paraphrase', 0.5258),\n",
       "  ('sentence paraphrase', 0.5272),\n",
       "  ('example paraphrase', 0.6092),\n",
       "  ('paraphrase identification', 0.6441)],\n",
       " [('similarity', 0.4225),\n",
       "  ('arabic', 0.4484),\n",
       "  ('sqs arabic', 0.4618),\n",
       "  ('arabic language', 0.4803),\n",
       "  ('question similarity', 0.6409)],\n",
       " [('sts aims', 0.4248),\n",
       "  ('sts', 0.4405),\n",
       "  ('variant sts', 0.4749),\n",
       "  ('sqs', 0.6016),\n",
       "  ('sqs variant', 0.6315)],\n",
       " [('prediction', 0.3927),\n",
       "  ('expansion', 0.4574),\n",
       "  ('expansion query', 0.5988),\n",
       "  ('query prediction', 0.6746),\n",
       "  ('document expansion', 0.6893)],\n",
       " [('passage', 0.4293),\n",
       "  ('ranking', 0.4342),\n",
       "  ('bert', 0.5591),\n",
       "  ('passage ranking', 0.7122),\n",
       "  ('ranking bert', 0.75)],\n",
       " [('bert', 0.4081),\n",
       "  ('ranking', 0.4109),\n",
       "  ('implementation bert', 0.5299),\n",
       "  ('bert query', 0.6041),\n",
       "  ('passage ranking', 0.6614)],\n",
       " [('generation', 0.3594),\n",
       "  ('neural question', 0.3903),\n",
       "  ('neural', 0.4239),\n",
       "  ('generation text', 0.5764),\n",
       "  ('question generation', 0.7746)],\n",
       " [('questions text', 0.5558),\n",
       "  ('automatic question', 0.646),\n",
       "  ('generated questions', 0.7136),\n",
       "  ('generate questions', 0.7674),\n",
       "  ('question generation', 0.8185)],\n",
       " [('natural language', 0.4371),\n",
       "  ('questions taking', 0.4457),\n",
       "  ('automatic question', 0.6913),\n",
       "  ('generate questions', 0.7496),\n",
       "  ('question generation', 0.7548)],\n",
       " [('answering', 0.4207),\n",
       "  ('answering question', 0.4342),\n",
       "  ('generation', 0.4479),\n",
       "  ('question answering', 0.5638),\n",
       "  ('question generation', 0.7024)],\n",
       " [('differential network', 0.403),\n",
       "  ('network visual', 0.4224),\n",
       "  ('multimodal', 0.5376),\n",
       "  ('multimodal differential', 0.5559),\n",
       "  ('question generation', 0.5737)],\n",
       " [('questions image', 0.5396),\n",
       "  ('image semantic', 0.5696),\n",
       "  ('learn multimodal', 0.604),\n",
       "  ('multimodal', 0.6118),\n",
       "  ('multimodal representations', 0.6392)],\n",
       " [('thors', 0.4683),\n",
       "  ('thors proposed', 0.5107),\n",
       "  ('au thors', 0.5222),\n",
       "  ('natural questions', 0.5438),\n",
       "  ('questions image', 0.5468)],\n",
       " [('adversarial training', 0.4566),\n",
       "  ('multilingual speech', 0.5417),\n",
       "  ('robust multilingual', 0.6305),\n",
       "  ('speech tagging', 0.6525),\n",
       "  ('tagging adversarial', 0.6676)],\n",
       " [('neural', 0.4308),\n",
       "  ('tagging', 0.5748),\n",
       "  ('neural pos', 0.6272),\n",
       "  ('tagging model', 0.6442),\n",
       "  ('pos tagging', 0.7184)],\n",
       " [('better internal', 0.4395),\n",
       "  ('structure words', 0.4872),\n",
       "  ('labeling', 0.5036),\n",
       "  ('words sequence', 0.5202),\n",
       "  ('sequence labeling', 0.7011)],\n",
       " [('statistical sequence', 0.3852),\n",
       "  ('labeling', 0.501),\n",
       "  ('crf', 0.5243),\n",
       "  ('crf used', 0.5256),\n",
       "  ('sequence labeling', 0.6871)],\n",
       " [('tagging hierarchical', 0.502),\n",
       "  ('transfer learning', 0.5162),\n",
       "  ('hierarchical recurrent', 0.5524),\n",
       "  ('recurrent networks', 0.5532),\n",
       "  ('sequence tagging', 0.659)],\n",
       " [('tagging', 0.4593),\n",
       "  ('multilingual speech', 0.5454),\n",
       "  ('term memory', 0.5527),\n",
       "  ('tagging bidirectional', 0.5957),\n",
       "  ('speech tagging', 0.6952)],\n",
       " [('byte embeddings', 0.4339),\n",
       "  ('lstms word', 0.5251),\n",
       "  ('embeddings pos', 0.5297),\n",
       "  ('pos tagging', 0.5675),\n",
       "  ('bi lstms', 0.5723)],\n",
       " [('tagging', 0.4674),\n",
       "  ('morphosyntactic', 0.472),\n",
       "  ('token encodings', 0.5013),\n",
       "  ('tagging meta', 0.5025),\n",
       "  ('morphosyntactic tagging', 0.7601)],\n",
       " [('lstm', 0.507),\n",
       "  ('cnns crf', 0.5222),\n",
       "  ('directional lstm', 0.5235),\n",
       "  ('lstm cnns', 0.5353),\n",
       "  ('sequence labeling', 0.6427)],\n",
       " [('pre processing', 0.3624),\n",
       "  ('taskspecific knowledge', 0.4301),\n",
       "  ('labeling', 0.5161),\n",
       "  ('labeling systems', 0.616),\n",
       "  ('sequence labeling', 0.7029)],\n",
       " [('entity recognition', 0.5242),\n",
       "  ('linguistic sequence', 0.5382),\n",
       "  ('labeling ofspeech', 0.5409),\n",
       "  ('sequence labeling', 0.563),\n",
       "  ('pos tagging', 0.5894)],\n",
       " [('tagging', 0.4373),\n",
       "  ('parsing', 0.5274),\n",
       "  ('tagging graph', 0.5351),\n",
       "  ('pos tagging', 0.5874),\n",
       "  ('dependency parsing', 0.6989)],\n",
       " [('comprehension', 0.5748),\n",
       "  ('contextual', 0.5749),\n",
       "  ('explicit contextual', 0.6843),\n",
       "  ('contextual semantics', 0.7003),\n",
       "  ('text comprehension', 0.7744)],\n",
       " [('questions document', 0.4428),\n",
       "  ('reading', 0.4726),\n",
       "  ('document comprehend', 0.5365),\n",
       "  ('reading test', 0.6505),\n",
       "  ('machine reading', 0.6998)],\n",
       " [('context', 0.4319),\n",
       "  ('perspective context', 0.5096),\n",
       "  ('comprehension', 0.5592),\n",
       "  ('context matching', 0.6066),\n",
       "  ('machine comprehension', 0.7039)],\n",
       " [('end deep', 0.4118),\n",
       "  ('comprehension', 0.4216),\n",
       "  ('mc datasets', 0.457),\n",
       "  ('comprehension mc', 0.5146),\n",
       "  ('machine comprehension', 0.5709)],\n",
       " [('natural language', 0.3315),\n",
       "  ('attention', 0.4203),\n",
       "  ('self attention', 0.4259),\n",
       "  ('language inference', 0.474),\n",
       "  ('attention network', 0.5857)],\n",
       " [('reasoning', 0.5132),\n",
       "  ('artificial intelligence', 0.5392),\n",
       "  ('inference', 0.5465),\n",
       "  ('reasoning inference', 0.6104),\n",
       "  ('inference central', 0.6196)],\n",
       " [('deep learning', 0.4206),\n",
       "  ('nli', 0.4268),\n",
       "  ('language inference', 0.4802),\n",
       "  ('nli task', 0.5429),\n",
       "  ('inference nli', 0.5876)],\n",
       " [('result snli', 0.5263),\n",
       "  ('nli', 0.5363),\n",
       "  ('performance nli', 0.6553),\n",
       "  ('snli data', 0.7144),\n",
       "  ('nli data', 0.7522)],\n",
       " [('dataset clinical', 0.44),\n",
       "  ('reading', 0.4574),\n",
       "  ('comprehension', 0.4987),\n",
       "  ('machine reading', 0.5712),\n",
       "  ('reading comprehension', 0.6453)],\n",
       " [('comprehension', 0.4411),\n",
       "  ('end reading', 0.453),\n",
       "  ('answer span', 0.5157),\n",
       "  ('comprehension rc', 0.5247),\n",
       "  ('reading comprehension', 0.6042)],\n",
       " [('answer span', 0.3924),\n",
       "  ('rc', 0.4302),\n",
       "  ('question answering', 0.4708),\n",
       "  ('rc formulating', 0.5003),\n",
       "  ('measuring rc', 0.5949)],\n",
       " [('qa', 0.4842),\n",
       "  ('kelp participating', 0.489),\n",
       "  ('qa task', 0.5901),\n",
       "  ('answering qa', 0.6157),\n",
       "  ('question answering', 0.6179)],\n",
       " [('automatically provide', 0.4733),\n",
       "  ('participants asked', 0.4827),\n",
       "  ('qa', 0.559),\n",
       "  ('qa setting', 0.5993),\n",
       "  ('answers qa', 0.6286)],\n",
       " [('neural', 0.4651),\n",
       "  ('nlp tasks', 0.4836),\n",
       "  ('captioning machine', 0.4922),\n",
       "  ('neural networks', 0.5068),\n",
       "  ('nn attention', 0.6181)],\n",
       " [('equipping deep', 0.4533),\n",
       "  ('networks dnn', 0.4766),\n",
       "  ('dnn attention', 0.4944),\n",
       "  ('sequence compression', 0.527),\n",
       "  ('context fusion', 0.602)],\n",
       " [('tree', 0.4626),\n",
       "  ('specific tree', 0.463),\n",
       "  ('compose task', 0.5563),\n",
       "  ('tree structures', 0.5719),\n",
       "  ('learning compose', 0.5978)],\n",
       " [('lstm novel', 0.5085),\n",
       "  ('term memory', 0.5105),\n",
       "  ('tree structured', 0.5284),\n",
       "  ('lstm', 0.5758),\n",
       "  ('tree lstm', 0.6998)],\n",
       " [('rte task', 0.5288),\n",
       "  ('recognizing textual', 0.5616),\n",
       "  ('entailment', 0.6006),\n",
       "  ('textual entailment', 0.6904),\n",
       "  ('entailment rte', 0.7898)],\n",
       " [('language processing', 0.5307),\n",
       "  ('rte systems', 0.5441),\n",
       "  ('information extraction', 0.5539),\n",
       "  ('nlp problems', 0.5682),\n",
       "  ('processing nlp', 0.6432)],\n",
       " [('inference data', 0.4065),\n",
       "  ('universal sentence', 0.48),\n",
       "  ('learning universal', 0.4922),\n",
       "  ('language inference', 0.5384),\n",
       "  ('sentence representations', 0.6446)],\n",
       " [('identification questions', 0.3937),\n",
       "  ('questions noisy', 0.4505),\n",
       "  ('paraphrase', 0.5275),\n",
       "  ('neural paraphrase', 0.6848),\n",
       "  ('paraphrase identification', 0.7138)],\n",
       " [('questions', 0.4305),\n",
       "  ('identification questions', 0.5094),\n",
       "  ('paraphrase', 0.5573),\n",
       "  ('problem paraphrase', 0.5656),\n",
       "  ('paraphrase identification', 0.7982)],\n",
       " [('nlp application', 0.5199),\n",
       "  ('useful nlp', 0.5708),\n",
       "  ('question paraphrase', 0.5921),\n",
       "  ('paraphrase', 0.6127),\n",
       "  ('paraphrase identification', 0.8462)],\n",
       " [('mc challenging', 0.5161),\n",
       "  ('comprehension', 0.5644),\n",
       "  ('machine comprehend', 0.6527),\n",
       "  ('machine comprehension', 0.721),\n",
       "  ('comprehension mc', 0.7374)],\n",
       " [('dataset', 0.4002),\n",
       "  ('dataset machine', 0.4113),\n",
       "  ('comprehension', 0.5055),\n",
       "  ('comprehension medical', 0.6296),\n",
       "  ('machine comprehension', 0.6913)],\n",
       " [('neural', 0.5433),\n",
       "  ('stored program', 0.644),\n",
       "  ('memory', 0.6658),\n",
       "  ('neural stored', 0.7492),\n",
       "  ('program memory', 0.7851)],\n",
       " [('stored program', 0.5137),\n",
       "  ('store weights', 0.5223),\n",
       "  ('memory modern', 0.5473),\n",
       "  ('memory store', 0.6016),\n",
       "  ('program memory', 0.631)],\n",
       " [('paper iclr', 0.4099),\n",
       "  ('iclr', 0.4898),\n",
       "  ('query reduction', 0.5028),\n",
       "  ('iclr 2017', 0.5426),\n",
       "  ('question answering', 0.585)],\n",
       " [('answering', 0.4601),\n",
       "  ('neural models', 0.4618),\n",
       "  ('answer evidence', 0.4672),\n",
       "  ('end neural', 0.5252),\n",
       "  ('question answering', 0.5992)],\n",
       " [('natural language', 0.4678),\n",
       "  ('qa popular', 0.5751),\n",
       "  ('qa', 0.5847),\n",
       "  ('question answering', 0.6701),\n",
       "  ('answering qa', 0.6842)],\n",
       " [('natural language', 0.4654),\n",
       "  ('iclr', 0.4905),\n",
       "  ('iclr 2018', 0.5291),\n",
       "  ('inference interaction', 0.5345),\n",
       "  ('language inference', 0.5493)],\n",
       " [('corpus', 0.5204),\n",
       "  ('large annotated', 0.5573),\n",
       "  ('corpus learning', 0.5746),\n",
       "  ('annotated corpus', 0.6498),\n",
       "  ('language inference', 0.6587)],\n",
       " [('entailment', 0.5557),\n",
       "  ('language inference', 0.5702),\n",
       "  ('determining entailment', 0.5771),\n",
       "  ('nli refers', 0.6158),\n",
       "  ('inference nli', 0.7795)],\n",
       " [('comprehension', 0.4286),\n",
       "  ('neural networks', 0.4509),\n",
       "  ('comprehension mrc', 0.5544),\n",
       "  ('machine reading', 0.5794),\n",
       "  ('reading comprehension', 0.5858)],\n",
       " [('qa', 0.4243),\n",
       "  ('neural', 0.4662),\n",
       "  ('qa simple', 0.5891),\n",
       "  ('making neural', 0.6132),\n",
       "  ('neural qa', 0.7828)],\n",
       " [('natural language', 0.3721),\n",
       "  ('query expressed', 0.3846),\n",
       "  ('answering', 0.514),\n",
       "  ('answering defined', 0.6003),\n",
       "  ('question answering', 0.7154)],\n",
       " [('effective text', 0.4719),\n",
       "  ('matching', 0.5287),\n",
       "  ('alignment features', 0.5469),\n",
       "  ('richer alignment', 0.5495),\n",
       "  ('text matching', 0.7497)],\n",
       " [('linguistic', 0.5054),\n",
       "  ('memory recurrent', 0.5978),\n",
       "  ('recurrent neural', 0.605),\n",
       "  ('knowledge memory', 0.63),\n",
       "  ('linguistic knowledge', 0.6567)],\n",
       " [('dependencies difficult', 0.4536),\n",
       "  ('neural networks', 0.4876),\n",
       "  ('term dependencies', 0.5125),\n",
       "  ('recurrent neural', 0.5768),\n",
       "  ('training recurrent', 0.598)],\n",
       " [('neural', 0.4263),\n",
       "  ('nlu systems', 0.5133),\n",
       "  ('background knowledge', 0.5578),\n",
       "  ('knowledge neural', 0.5686),\n",
       "  ('neural nlu', 0.6226)],\n",
       " [('language understanding', 0.4793),\n",
       "  ('corpora learning', 0.4873),\n",
       "  ('training corpora', 0.527),\n",
       "  ('nlu systems', 0.5416),\n",
       "  ('understanding nlu', 0.5676)],\n",
       " [('discrete hard', 0.4107),\n",
       "  ('approach weakly', 0.4451),\n",
       "  ('weakly', 0.4596),\n",
       "  ('question answering', 0.5109),\n",
       "  ('weakly supervised', 0.6053)],\n",
       " [('directly reading', 0.4667),\n",
       "  ('questions unsolved', 0.4764),\n",
       "  ('documents able', 0.498),\n",
       "  ('unsolved challenge', 0.569),\n",
       "  ('reading documents', 0.5891)],\n",
       " [('memory', 0.4051),\n",
       "  ('reading', 0.4719),\n",
       "  ('term memory', 0.5463),\n",
       "  ('machine reading', 0.6424),\n",
       "  ('memory networks', 0.6818)],\n",
       " [('matching', 0.4023),\n",
       "  ('matching fundamental', 0.421),\n",
       "  ('language sentence', 0.4294),\n",
       "  ('natural language', 0.5882),\n",
       "  ('sentence matching', 0.7761)],\n",
       " [('nlsm', 0.5755),\n",
       "  ('comparing sentences', 0.5841),\n",
       "  ('nlsm task', 0.6602),\n",
       "  ('sentence matching', 0.7114),\n",
       "  ('matching nlsm', 0.7282)],\n",
       " [('sentences paraphrase', 0.573),\n",
       "  ('nlsm used', 0.5738),\n",
       "  ('task nlsm', 0.5934),\n",
       "  ('example paraphrase', 0.6154),\n",
       "  ('paraphrase identification', 0.6773)],\n",
       " [('memory', 0.3935),\n",
       "  ('answering', 0.4343),\n",
       "  ('memory networks', 0.6154),\n",
       "  ('answering memory', 0.6609),\n",
       "  ('question answering', 0.6652)],\n",
       " [('answering', 0.3815),\n",
       "  ('complicated training', 0.4319),\n",
       "  ('training sources', 0.496),\n",
       "  ('answering systems', 0.5734),\n",
       "  ('question answering', 0.6416)],\n",
       " [('impact multitask', 0.4649),\n",
       "  ('transfer learning', 0.495),\n",
       "  ('multitask transfer', 0.5704),\n",
       "  ('multitask', 0.5793),\n",
       "  ('question answering', 0.6122)],\n",
       " [('higher reasoning', 0.4997),\n",
       "  ('reasoning capabilities', 0.5365),\n",
       "  ('problem answering', 0.5538),\n",
       "  ('answering questions', 0.5614),\n",
       "  ('question answering', 0.6376)],\n",
       " [('multi passage', 0.4804),\n",
       "  ('passage machine', 0.497),\n",
       "  ('machine reading', 0.5099),\n",
       "  ('reading comprehension', 0.5979),\n",
       "  ('comprehension cross', 0.6003)],\n",
       " [('machines read', 0.5193),\n",
       "  ('mrc challenging', 0.5856),\n",
       "  ('reading comprehension', 0.6214),\n",
       "  ('machine reading', 0.6251),\n",
       "  ('comprehension mrc', 0.7499)],\n",
       " [('mrc models', 0.547),\n",
       "  ('long questions', 0.5522),\n",
       "  ('decreases answering', 0.5537),\n",
       "  ('answering long', 0.558),\n",
       "  ('accuracy mrc', 0.5664)],\n",
       " [('dynamic meta', 0.4294),\n",
       "  ('embeddings', 0.518),\n",
       "  ('embeddings improved', 0.6127),\n",
       "  ('meta embeddings', 0.6302),\n",
       "  ('sentence representations', 0.7022)],\n",
       " [('representations', 0.4302),\n",
       "  ('embeddings', 0.4907),\n",
       "  ('learning task', 0.4949),\n",
       "  ('meta embeddings', 0.5927),\n",
       "  ('sentence representations', 0.6396)],\n",
       " [('sequential tasks', 0.4702),\n",
       "  ('rnn', 0.4786),\n",
       "  ('associative memory', 0.5176),\n",
       "  ('networks rnn', 0.5436),\n",
       "  ('recurrent neural', 0.5984)],\n",
       " [('capacity manipulate', 0.3562),\n",
       "  ('term memory', 0.3869),\n",
       "  ('memory', 0.447),\n",
       "  ('rnn', 0.5921),\n",
       "  ('rnn limited', 0.6697)],\n",
       " [('generative', 0.4312),\n",
       "  ('answering tasks', 0.4325),\n",
       "  ('commonsense', 0.4332),\n",
       "  ('question answering', 0.5138),\n",
       "  ('commonsense generative', 0.6114)],\n",
       " [('fact finding', 0.4722),\n",
       "  ('reading comprehension', 0.5405),\n",
       "  ('comprehension qa', 0.5463),\n",
       "  ('qa tasks', 0.5784),\n",
       "  ('extractive qa', 0.6301)],\n",
       " [('based qa', 0.5295),\n",
       "  ('machine reading', 0.5408),\n",
       "  ('qa', 0.55),\n",
       "  ('reading comprehension', 0.6055),\n",
       "  ('comprehension mrc', 0.6447)],\n",
       " [('qa', 0.4473),\n",
       "  ('babi dataset', 0.4993),\n",
       "  ('reasoning based', 0.5014),\n",
       "  ('qa babi', 0.5705),\n",
       "  ('mrc qa', 0.5727)],\n",
       " [('fast unified', 0.4441),\n",
       "  ('sentence understanding', 0.5336),\n",
       "  ('parsing sentence', 0.6564),\n",
       "  ('parsing', 0.6921),\n",
       "  ('model parsing', 0.6943)],\n",
       " [('information', 0.4116),\n",
       "  ('attention', 0.5274),\n",
       "  ('attention based', 0.5849),\n",
       "  ('information retriever', 0.5878),\n",
       "  ('fully attention', 0.6305)],\n",
       " [('qa', 0.5181),\n",
       "  ('qa systems', 0.5755),\n",
       "  ('answer queries', 0.6629),\n",
       "  ('answering qa', 0.6746),\n",
       "  ('question answering', 0.6991)],\n",
       " [('language processing', 0.5012),\n",
       "  ('natural language', 0.5161),\n",
       "  ('unstructured', 0.546),\n",
       "  ('understanding unstructured', 0.6801),\n",
       "  ('unstructured text', 0.7666)],\n",
       " [('embeddings', 0.5167),\n",
       "  ('nli iterative', 0.5944),\n",
       "  ('refinement encoders', 0.6278),\n",
       "  ('sentence embeddings', 0.7103),\n",
       "  ('embeddings nli', 0.7433)],\n",
       " [('representations necessary', 0.5199),\n",
       "  ('nlp', 0.5249),\n",
       "  ('various nlp', 0.6092),\n",
       "  ('sentence level', 0.6454),\n",
       "  ('nlp tasks', 0.7167)],\n",
       " [('adversarial', 0.5067),\n",
       "  ('dataset grounded', 0.5599),\n",
       "  ('grounded commonsense', 0.5676),\n",
       "  ('commonsense inference', 0.5749),\n",
       "  ('adversarial dataset', 0.5821)],\n",
       " [('information retrieval', 0.4284),\n",
       "  ('reading', 0.5264),\n",
       "  ('comprehension', 0.5378),\n",
       "  ('comprehension rc', 0.6309),\n",
       "  ('reading comprehension', 0.72)],\n",
       " [('images', 0.4418),\n",
       "  ('images language', 0.6495),\n",
       "  ('embeddings', 0.6926),\n",
       "  ('embeddings images', 0.6995),\n",
       "  ('order embeddings', 0.8025)],\n",
       " [('semantic hierarchy', 0.5337),\n",
       "  ('sentences images', 0.6092),\n",
       "  ('entailment image', 0.6232),\n",
       "  ('visual semantic', 0.6472),\n",
       "  ('hypernymy textual', 0.6722)],\n",
       " [('refer visualsemantic', 0.5067),\n",
       "  ('relations', 0.516),\n",
       "  ('hierarchy', 0.5425),\n",
       "  ('relations seen', 0.5778),\n",
       "  ('visualsemantic hierarchy', 0.7188)],\n",
       " [('history conversational', 0.5185),\n",
       "  ('conversational machine', 0.5227),\n",
       "  ('grasping flow', 0.5314),\n",
       "  ('flowqa grasping', 0.5349),\n",
       "  ('machine comprehension', 0.5615)],\n",
       " [('conversational', 0.4312),\n",
       "  ('dialogs', 0.5378),\n",
       "  ('machine comprehension', 0.5751),\n",
       "  ('conversational machine', 0.5782),\n",
       "  ('seeking dialogs', 0.5826)],\n",
       " [('encoders multi', 0.4394),\n",
       "  ('shortcut stacked', 0.4543),\n",
       "  ('stacked sentence', 0.4655),\n",
       "  ('sentence encoders', 0.5838),\n",
       "  ('domain inference', 0.6089)],\n",
       " [('sequential sentence', 0.4047),\n",
       "  ('natural language', 0.4176),\n",
       "  ('inference', 0.4203),\n",
       "  ('sentence encoder', 0.5505),\n",
       "  ('language inference', 0.5713)],\n",
       " [('networks', 0.435),\n",
       "  ('recurrent', 0.523),\n",
       "  ('relational', 0.5447),\n",
       "  ('relational networks', 0.6991),\n",
       "  ('recurrent relational', 0.8145)],\n",
       " [('representation objects', 0.432),\n",
       "  ('relational', 0.4662),\n",
       "  ('graph representation', 0.5501),\n",
       "  ('relational network', 0.6037),\n",
       "  ('recurrent relational', 0.6808)],\n",
       " [('sen', 0.437),\n",
       "  ('task learning', 0.4914),\n",
       "  ('distributed sen', 0.5205),\n",
       "  ('sen tence', 0.5283),\n",
       "  ('tence representations', 0.5637)],\n",
       " [('distributed vector', 0.4414),\n",
       "  ('nlp', 0.4549),\n",
       "  ('vector representations', 0.4894),\n",
       "  ('processing nlp', 0.5231),\n",
       "  ('nlp driven', 0.5546)],\n",
       " [('sentences', 0.4791),\n",
       "  ('words sentences', 0.5146),\n",
       "  ('sequences words', 0.5217),\n",
       "  ('representations sequences', 0.5245),\n",
       "  ('learning representations', 0.5663)],\n",
       " [('purpose sentence', 0.3714),\n",
       "  ('general purpose', 0.3802),\n",
       "  ('representations', 0.4491),\n",
       "  ('learning general', 0.4784),\n",
       "  ('sentence representations', 0.7631)],\n",
       " [('subgraph', 0.4789),\n",
       "  ('embeddings', 0.5253),\n",
       "  ('question answering', 0.6459),\n",
       "  ('subgraph embeddings', 0.683),\n",
       "  ('answering subgraph', 0.7153)],\n",
       " [('comprehension', 0.5147),\n",
       "  ('answering qa', 0.6056),\n",
       "  ('comprehension based', 0.6347),\n",
       "  ('machine comprehension', 0.7003),\n",
       "  ('question answering', 0.7067)],\n",
       " [('span representations', 0.4391),\n",
       "  ('representations extractive', 0.4684),\n",
       "  ('learning recurrent', 0.516),\n",
       "  ('recurrent span', 0.5389),\n",
       "  ('question answering', 0.5601)],\n",
       " [('extraction task', 0.4146),\n",
       "  ('spans evidence', 0.5),\n",
       "  ('recurrent network', 0.539),\n",
       "  ('document recurrent', 0.5556),\n",
       "  ('answer extraction', 0.6935)],\n",
       " [('comprehension', 0.4472),\n",
       "  ('predicting', 0.5023),\n",
       "  ('predicting happens', 0.6715),\n",
       "  ('comprehension predicting', 0.6825),\n",
       "  ('story comprehension', 0.7379)],\n",
       " [('comprehension', 0.4141),\n",
       "  ('language understanding', 0.4195),\n",
       "  ('comprehension fundamental', 0.4336),\n",
       "  ('automatic story', 0.6147),\n",
       "  ('story comprehension', 0.6787)],\n",
       " [('stories interesting', 0.4613),\n",
       "  ('linguists', 0.5045),\n",
       "  ('automatically understanding', 0.5195),\n",
       "  ('computational linguists', 0.5882),\n",
       "  ('understanding stories', 0.605)],\n",
       " [('cloze', 0.4195),\n",
       "  ('testing ability', 0.4431),\n",
       "  ('cloze task', 0.5306),\n",
       "  ('story cloze', 0.5334),\n",
       "  ('language generation', 0.5974)],\n",
       " [('aggregate', 0.3775),\n",
       "  ('clustering answer', 0.4293),\n",
       "  ('compare aggregate', 0.4341),\n",
       "  ('latent clustering', 0.4721),\n",
       "  ('answer selection', 0.7074)],\n",
       " [('selection', 0.4188),\n",
       "  ('natural language', 0.4406),\n",
       "  ('sentence level', 0.4943),\n",
       "  ('selection task', 0.5192),\n",
       "  ('answer selection', 0.7501)],\n",
       " [('qa primary', 0.5265),\n",
       "  ('automatic question', 0.626),\n",
       "  ('qa', 0.6269),\n",
       "  ('question answering', 0.6422),\n",
       "  ('answering qa', 0.6726)],\n",
       " [('coattention net', 0.4208),\n",
       "  ('fine grain', 0.4215),\n",
       "  ('multi evidence', 0.4601),\n",
       "  ('grain coattention', 0.4787),\n",
       "  ('question answering', 0.49)],\n",
       " [('neural', 0.3763),\n",
       "  ('reasoning localized', 0.4383),\n",
       "  ('end neural', 0.4612),\n",
       "  ('answering systems', 0.5214),\n",
       "  ('question answering', 0.5979)],\n",
       " [('answer questions', 0.466),\n",
       "  ('comprehend text', 0.5135),\n",
       "  ('artificial intelligence', 0.5321),\n",
       "  ('machines read', 0.5564),\n",
       "  ('teaching machines', 0.6512)],\n",
       " [('comprehension mrc', 0.5443),\n",
       "  ('question answering', 0.5453),\n",
       "  ('reading comprehension', 0.5682),\n",
       "  ('understanding meaning', 0.5776),\n",
       "  ('language understanding', 0.6045)],\n",
       " [('holds language', 0.4396),\n",
       "  ('hypothesis holds', 0.4416),\n",
       "  ('language', 0.4467),\n",
       "  ('understanding mrc', 0.463),\n",
       "  ('language understanding', 0.5924)],\n",
       " [('reading', 0.4899),\n",
       "  ('multi paragraph', 0.5484),\n",
       "  ('comprehension', 0.566),\n",
       "  ('paragraph reading', 0.6267),\n",
       "  ('reading comprehension', 0.77)],\n",
       " [('paragraph level', 0.4573),\n",
       "  ('adapting neural', 0.463),\n",
       "  ('neural paragraph', 0.5524),\n",
       "  ('question answering', 0.6078),\n",
       "  ('answering models', 0.6269)],\n",
       " [('success neural', 0.5085),\n",
       "  ('answering questions', 0.5526),\n",
       "  ('neural', 0.5549),\n",
       "  ('neural models', 0.5935),\n",
       "  ('models answering', 0.6438)],\n",
       " [('evaluating semantic', 0.562),\n",
       "  ('parsing', 0.5836),\n",
       "  ('question answering', 0.5866),\n",
       "  ('parsing simple', 0.5918),\n",
       "  ('semantic parsing', 0.7053)],\n",
       " [('attention', 0.481),\n",
       "  ('machine translation', 0.4969),\n",
       "  ('question answering', 0.5205),\n",
       "  ('incorporating attention', 0.534),\n",
       "  ('attention mechanisms', 0.5606)],\n",
       " [('sentence', 0.3436),\n",
       "  ('deep learning', 0.4503),\n",
       "  ('answer sentence', 0.5398),\n",
       "  ('sentence selection', 0.6221),\n",
       "  ('learning answer', 0.6539)],\n",
       " [('qa particular', 0.5167),\n",
       "  ('answering', 0.5511),\n",
       "  ('qa', 0.5754),\n",
       "  ('question answering', 0.6715),\n",
       "  ('answering qa', 0.7606)],\n",
       " [('answering question', 0.498),\n",
       "  ('answer sentence', 0.5215),\n",
       "  ('sentences retrieved', 0.5566),\n",
       "  ('selecting sentences', 0.5911),\n",
       "  ('sentence selection', 0.6231)],\n",
       " [('as2 relevant', 0.5517),\n",
       "  ('engine as2', 0.5748),\n",
       "  ('as2', 0.5904),\n",
       "  ('popularity as2', 0.6102),\n",
       "  ('as2 model', 0.6107)],\n",
       " [('rnns', 0.5319),\n",
       "  ('rnns effectively', 0.5404),\n",
       "  ('recurrent neural', 0.5438),\n",
       "  ('gated rnns', 0.5592),\n",
       "  ('unitary rnns', 0.5617)],\n",
       " [('units grus', 0.5432),\n",
       "  ('lstms', 0.5465),\n",
       "  ('memory lstms', 0.5622),\n",
       "  ('gating units', 0.5645),\n",
       "  ('recurrent units', 0.6049)],\n",
       " [('importance gating', 0.4743),\n",
       "  ('neural networks', 0.4842),\n",
       "  ('recurrent neural', 0.5527),\n",
       "  ('gating units', 0.5816),\n",
       "  ('units recurrent', 0.6194)],\n",
       " [('gated units', 0.4459),\n",
       "  ('rnns', 0.5706),\n",
       "  ('units rnns', 0.6292),\n",
       "  ('rnns primarily', 0.6446),\n",
       "  ('conventional rnns', 0.6475)],\n",
       " [('aware answer', 0.4353),\n",
       "  ('product aware', 0.4526),\n",
       "  ('generation commerce', 0.4807),\n",
       "  ('question answering', 0.5596),\n",
       "  ('answer generation', 0.6272)],\n",
       " [('comprehension', 0.4961),\n",
       "  ('comprehension promising', 0.6177),\n",
       "  ('question answering', 0.6289),\n",
       "  ('reading comprehension', 0.6413),\n",
       "  ('answering qa', 0.6547)],\n",
       " [('comprehension', 0.5424),\n",
       "  ('textual entailment', 0.5636),\n",
       "  ('comprehension tc', 0.6101),\n",
       "  ('reading comprehension', 0.692),\n",
       "  ('text comprehension', 0.7186)],\n",
       " [('generative', 0.4923),\n",
       "  ('style generative', 0.5055),\n",
       "  ('comprehension', 0.5449),\n",
       "  ('reading comprehension', 0.6947),\n",
       "  ('generative reading', 0.7229)],\n",
       " [('comprehension', 0.4583),\n",
       "  ('language generation', 0.4604),\n",
       "  ('generation nlg', 0.4958),\n",
       "  ('generative reading', 0.5907),\n",
       "  ('reading comprehension', 0.5939)],\n",
       " [('generative', 0.4235),\n",
       "  ('masque generative', 0.4968),\n",
       "  ('generative model', 0.504),\n",
       "  ('passage rc', 0.5979),\n",
       "  ('multi passage', 0.6123)],\n",
       " [('representations', 0.4945),\n",
       "  ('sentences', 0.4954),\n",
       "  ('sentences documents', 0.6285),\n",
       "  ('representations sentences', 0.6386),\n",
       "  ('distributed representations', 0.6868)],\n",
       " [('modelling interaction', 0.4277),\n",
       "  ('interaction sentence', 0.4491),\n",
       "  ('lstms', 0.5139),\n",
       "  ('sentence pair', 0.5595),\n",
       "  ('coupled lstms', 0.6833)],\n",
       " [('modelling interactions', 0.4148),\n",
       "  ('sentences', 0.4583),\n",
       "  ('deep neural', 0.4702),\n",
       "  ('sentences deep', 0.4988),\n",
       "  ('interactions sentences', 0.5801)],\n",
       " [('sentence pair', 0.5302),\n",
       "  ('modelling relevance', 0.5307),\n",
       "  ('relevance similarity', 0.6052),\n",
       "  ('text semantic', 0.6224),\n",
       "  ('semantic matching', 0.6778)],\n",
       " [('reasoning critical', 0.4615),\n",
       "  ('critical ai', 0.4638),\n",
       "  ('commonsense', 0.5904),\n",
       "  ('test commonsense', 0.666),\n",
       "  ('commonsense reasoning', 0.7214)],\n",
       " [('commonsense', 0.5142),\n",
       "  ('datadriven', 0.5155),\n",
       "  ('datadriven methods', 0.5307),\n",
       "  ('commonsense reasoning', 0.6625),\n",
       "  ('datasets commonsense', 0.738)],\n",
       " [('introduce commonsense', 0.4762),\n",
       "  ('codah commonsense', 0.5015),\n",
       "  ('commonsense question', 0.51),\n",
       "  ('commonsense', 0.5296),\n",
       "  ('commonsense dataset', 0.5789)],\n",
       " [('comprehension rc', 0.4316),\n",
       "  ('dynamic chunk', 0.4485),\n",
       "  ('neural reading', 0.5135),\n",
       "  ('chunk reader', 0.5189),\n",
       "  ('reading comprehension', 0.5614)],\n",
       " [('rcqa', 0.5615),\n",
       "  ('reading comprehension', 0.6091),\n",
       "  ('question answering', 0.6168),\n",
       "  ('rcqa task', 0.6252),\n",
       "  ('answering rcqa', 0.6731)],\n",
       " [('assumptions rcqa', 0.5253),\n",
       "  ('factoid examples', 0.5291),\n",
       "  ('entities factoid', 0.5427),\n",
       "  ('non factoid', 0.5548),\n",
       "  ('questions entities', 0.555)],\n",
       " [('reading', 0.4468),\n",
       "  ('comprehension', 0.4574),\n",
       "  ('hop reading', 0.4687),\n",
       "  ('reading comprehension', 0.6507),\n",
       "  ('comprehension documents', 0.6971)],\n",
       " [('reasoning', 0.5487),\n",
       "  ('multiple facts', 0.5851),\n",
       "  ('question answering', 0.6573),\n",
       "  ('reasoning multiple', 0.7185),\n",
       "  ('answering reasoning', 0.7817)],\n",
       " [('recurrent', 0.3984),\n",
       "  ('connected recurrent', 0.4442),\n",
       "  ('attentive information', 0.4861),\n",
       "  ('recurrent attentive', 0.5532),\n",
       "  ('sentence matching', 0.6089)],\n",
       " [('language inference', 0.488),\n",
       "  ('inference paraphrase', 0.5105),\n",
       "  ('paraphrase identification', 0.5413),\n",
       "  ('question answering', 0.5605),\n",
       "  ('sentence matching', 0.7274)],\n",
       " [('inference tasks', 0.4602),\n",
       "  ('reading comprehension', 0.4917),\n",
       "  ('language model', 0.5682),\n",
       "  ('language inference', 0.583),\n",
       "  ('language representations', 0.6711)],\n",
       " [('language understanding', 0.4981),\n",
       "  ('contextual language', 0.5054),\n",
       "  ('language representations', 0.5162),\n",
       "  ('universal language', 0.5189),\n",
       "  ('deep contextual', 0.5745)],\n",
       " [('dynamically fused', 0.4102),\n",
       "  ('multi hop', 0.4612),\n",
       "  ('hop reasoning', 0.5314),\n",
       "  ('fused graph', 0.5583),\n",
       "  ('graph network', 0.5705)],\n",
       " [('text based', 0.4429),\n",
       "  ('tbqa', 0.4588),\n",
       "  ('tbqa studied', 0.5871),\n",
       "  ('answering tbqa', 0.6198),\n",
       "  ('question answering', 0.6256)],\n",
       " [('responding questions', 0.4775),\n",
       "  ('comprehension', 0.5241),\n",
       "  ('comprehension squad', 0.5557),\n",
       "  ('question answering', 0.6137),\n",
       "  ('reading comprehension', 0.6288)],\n",
       " [('supervised embedding', 0.4871),\n",
       "  ('embedding models', 0.5058),\n",
       "  ('weakly supervised', 0.5128),\n",
       "  ('answering weakly', 0.5405),\n",
       "  ('question answering', 0.5483)],\n",
       " [('open domain', 0.4154),\n",
       "  ('answer questions', 0.4402),\n",
       "  ('answering', 0.4486),\n",
       "  ('questions domain', 0.551),\n",
       "  ('question answering', 0.6045)],\n",
       " [('word generalize', 0.4484),\n",
       "  ('natural language', 0.4484),\n",
       "  ('rare words', 0.4869),\n",
       "  ('representations rare', 0.4983),\n",
       "  ('learning representations', 0.5448)],\n",
       " [('embeddings fly', 0.4352),\n",
       "  ('learning compute', 0.4774),\n",
       "  ('compute word', 0.5102),\n",
       "  ('embeddings', 0.6183),\n",
       "  ('word embeddings', 0.7953)],\n",
       " [('attention', 0.4309),\n",
       "  ('rnn', 0.4715),\n",
       "  ('network rnn', 0.5383),\n",
       "  ('rnn cnn', 0.5867),\n",
       "  ('attention network', 0.6111)],\n",
       " [('mc style', 0.434),\n",
       "  ('comprehension', 0.4607),\n",
       "  ('comprehension mc', 0.5725),\n",
       "  ('question answering', 0.5993),\n",
       "  ('machine comprehension', 0.6616)],\n",
       " [('language processing', 0.5044),\n",
       "  ('natural language', 0.5108),\n",
       "  ('comprehension', 0.5658),\n",
       "  ('comprehension text', 0.7029),\n",
       "  ('machine comprehension', 0.773)],\n",
       " [('text processing', 0.4784),\n",
       "  ('variational', 0.5156),\n",
       "  ('inference text', 0.5449),\n",
       "  ('neural variational', 0.6348),\n",
       "  ('variational inference', 0.6414)],\n",
       " [('efficient neural', 0.4568),\n",
       "  ('hyperbolic', 0.4677),\n",
       "  ('representation learning', 0.4835),\n",
       "  ('question answering', 0.5271),\n",
       "  ('hyperbolic representation', 0.5489)],\n",
       " [('pairwise word', 0.4395),\n",
       "  ('similarity', 0.4636),\n",
       "  ('similarity measurement', 0.5032),\n",
       "  ('word interaction', 0.5331),\n",
       "  ('semantic similarity', 0.5886)],\n",
       " [('semantics input', 0.4795),\n",
       "  ('similarity', 0.5566),\n",
       "  ('textual', 0.5667),\n",
       "  ('similarity measurement', 0.6369),\n",
       "  ('textual similarity', 0.7696)],\n",
       " [('paraphrase generation', 0.5615),\n",
       "  ('ranking paraphrase', 0.575),\n",
       "  ('similarity sts', 0.6016),\n",
       "  ('semantic textual', 0.6028),\n",
       "  ('textual similarity', 0.688)],\n",
       " [('topics', 0.4353),\n",
       "  ('answer questions', 0.5043),\n",
       "  ('knowledge base', 0.5066),\n",
       "  ('topics knowledge', 0.5551),\n",
       "  ('learns answer', 0.6416)],\n",
       " [('natural language', 0.4849),\n",
       "  ('artificial intelligence', 0.4901),\n",
       "  ('machines automatically', 0.4929),\n",
       "  ('teaching machines', 0.5562),\n",
       "  ('automatically answer', 0.6352)],\n",
       " [('query efficiently', 0.4685),\n",
       "  ('structured knowledge', 0.4701),\n",
       "  ('databases natural', 0.5444),\n",
       "  ('knowledge bases', 0.5455),\n",
       "  ('question answering', 0.608)],\n",
       " [('qa organizing', 0.4711),\n",
       "  ('freebase encompass', 0.4945),\n",
       "  ('answers structured', 0.4991),\n",
       "  ('freebase', 0.5128),\n",
       "  ('kbs freebase', 0.6382)],\n",
       " [('reading', 0.4936),\n",
       "  ('self attention', 0.5071),\n",
       "  ('local convolution', 0.5417),\n",
       "  ('convolution global', 0.5479),\n",
       "  ('attention reading', 0.649)],\n",
       " [('networks rnns', 0.4686),\n",
       "  ('machine reading', 0.5302),\n",
       "  ('rnns attention', 0.5588),\n",
       "  ('answering models', 0.5616),\n",
       "  ('question answering', 0.614)],\n",
       " [('automated question', 0.5184),\n",
       "  ('machine reading', 0.5921),\n",
       "  ('question answering', 0.6162),\n",
       "  ('reading comprehension', 0.6227),\n",
       "  ('comprehension automated', 0.7113)],\n",
       " [('reading', 0.4349),\n",
       "  ('comprehension', 0.4614),\n",
       "  ('networks reading', 0.4759),\n",
       "  ('question answering', 0.5826),\n",
       "  ('reading comprehension', 0.6245)],\n",
       " [('comprehension', 0.4338),\n",
       "  ('selfmatching networks', 0.4617),\n",
       "  ('comprehension style', 0.5675),\n",
       "  ('reading comprehension', 0.5727),\n",
       "  ('question answering', 0.5855)],\n",
       " [('natural language', 0.3578),\n",
       "  ('translation comprehension', 0.3908),\n",
       "  ('sequence pre', 0.4264),\n",
       "  ('language generation', 0.5514),\n",
       "  ('generation translation', 0.5596)],\n",
       " [('sequence models', 0.573),\n",
       "  ('denoising autoencoder', 0.615),\n",
       "  ('autoencoder', 0.6204),\n",
       "  ('pretraining sequence', 0.6269),\n",
       "  ('autoencoder pretraining', 0.668)],\n",
       " [('distant supervision', 0.4593),\n",
       "  ('answering distant', 0.4776),\n",
       "  ('supervision answer', 0.5108),\n",
       "  ('question answering', 0.5207),\n",
       "  ('answer justification', 0.6379)],\n",
       " [('model learning', 0.529),\n",
       "  ('learning ml', 0.5928),\n",
       "  ('interpretable machine', 0.628),\n",
       "  ('ml models', 0.6439),\n",
       "  ('developing interpretable', 0.6618)],\n",
       " [('comprehension', 0.4775),\n",
       "  ('reading', 0.4973),\n",
       "  ('iclr 2017', 0.5019),\n",
       "  ('gating reading', 0.5565),\n",
       "  ('reading comprehension', 0.6413)],\n",
       " [('lingual transfer', 0.546),\n",
       "  ('multilingual sentence', 0.5474),\n",
       "  ('cross lingual', 0.5478),\n",
       "  ('sentence embeddings', 0.5561),\n",
       "  ('massively multilingual', 0.5837)],\n",
       " [('93 languages', 0.515),\n",
       "  ('sentence representations', 0.5816),\n",
       "  ('multilingual sentence', 0.5877),\n",
       "  ('multilingual', 0.5887),\n",
       "  ('joint multilingual', 0.6027)],\n",
       " [('decoder abstractive', 0.5248),\n",
       "  ('text summarization', 0.5426),\n",
       "  ('deep recurrent', 0.5654),\n",
       "  ('generative decoder', 0.5713),\n",
       "  ('recurrent generative', 0.6072)],\n",
       " [('extractive abstractive', 0.4921),\n",
       "  ('summarization', 0.4941),\n",
       "  ('neural abstractive', 0.5335),\n",
       "  ('summarization models', 0.5972),\n",
       "  ('abstractive summarization', 0.6551)],\n",
       " [('summary', 0.4599),\n",
       "  ('summary main', 0.4963),\n",
       "  ('reader comments', 0.4999),\n",
       "  ('abstractive summary', 0.6633),\n",
       "  ('summary generation', 0.792)],\n",
       " [('question generation', 0.5482),\n",
       "  ('teaches summarization', 0.559),\n",
       "  ('summarization model', 0.5769),\n",
       "  ('abstractive summarization', 0.5823),\n",
       "  ('summarization multi', 0.5849)],\n",
       " [('attention', 0.4693),\n",
       "  ('fine attention', 0.5421),\n",
       "  ('summarization', 0.5759),\n",
       "  ('attention models', 0.6323),\n",
       "  ('document summarization', 0.6658)],\n",
       " [('summarization', 0.4532),\n",
       "  ('question generation', 0.4928),\n",
       "  ('multi task', 0.4952),\n",
       "  ('summarization entailment', 0.607),\n",
       "  ('task summarization', 0.687)],\n",
       " [('task learning', 0.4387),\n",
       "  ('abstractive text', 0.4882),\n",
       "  ('summarization', 0.4913),\n",
       "  ('text summarization', 0.5397),\n",
       "  ('summarization soft', 0.6223)],\n",
       " [('abstractive', 0.5242),\n",
       "  ('summarization', 0.6696),\n",
       "  ('abstractive summarization', 0.8713)],\n",
       " [('language summaries', 0.5896),\n",
       "  ('summarization', 0.6726),\n",
       "  ('summaries compress', 0.6787),\n",
       "  ('summarization systems', 0.7635),\n",
       "  ('text summarization', 0.7788)],\n",
       " [('mixture', 0.4586),\n",
       "  ('selection diverse', 0.5141),\n",
       "  ('mixture content', 0.5494),\n",
       "  ('sequence generation', 0.6595),\n",
       "  ('diverse sequence', 0.6764)],\n",
       " [('summarization exhibit', 0.5045),\n",
       "  ('generating diverse', 0.56),\n",
       "  ('diverse sequences', 0.5734),\n",
       "  ('question generation', 0.6079),\n",
       "  ('generation summarization', 0.6918)],\n",
       " [('nlp', 0.5274),\n",
       "  ('generating target', 0.5573),\n",
       "  ('problems nlp', 0.5846),\n",
       "  ('source sequence', 0.6002),\n",
       "  ('target sequences', 0.6618)],\n",
       " [('human translators', 0.548),\n",
       "  ('decoder models', 0.5531),\n",
       "  ('encoder', 0.5563),\n",
       "  ('encoder decoder', 0.5699),\n",
       "  ('translation neural', 0.5976)],\n",
       " [('abstractive sentence', 0.5399),\n",
       "  ('summarization', 0.5431),\n",
       "  ('attentive recurrent', 0.5889),\n",
       "  ('sentence summarization', 0.6436),\n",
       "  ('summarization attentive', 0.7039)],\n",
       " [('source sentence', 0.4926),\n",
       "  ('produces summary', 0.6537),\n",
       "  ('summarization', 0.7167),\n",
       "  ('summarization task', 0.7518),\n",
       "  ('sentence summarization', 0.8132)],\n",
       " [('learning', 0.2553),\n",
       "  ('seq2seq', 0.5114),\n",
       "  ('results summarization', 0.5512),\n",
       "  ('summarization', 0.5692),\n",
       "  ('seq2seq learning', 0.6639)],\n",
       " [('repeating generations', 0.4309),\n",
       "  ('neural abstractive', 0.4702),\n",
       "  ('generations neural', 0.4735),\n",
       "  ('summarization', 0.4875),\n",
       "  ('abstractive summarization', 0.6408)],\n",
       " [('encoder decoder', 0.457),\n",
       "  ('language generation', 0.4655),\n",
       "  ('machine translation', 0.481),\n",
       "  ('nlg tasks', 0.5359),\n",
       "  ('generation nlg', 0.5747)],\n",
       " [('rerank', 0.4786),\n",
       "  ('retrieve rerank', 0.4802),\n",
       "  ('rerank rewrite', 0.5073),\n",
       "  ('summarization', 0.5417),\n",
       "  ('neural summarization', 0.7814)],\n",
       " [('task abstractive', 0.4633),\n",
       "  ('summarization', 0.6308),\n",
       "  ('summarization generates', 0.6447),\n",
       "  ('abstractive sentence', 0.6594),\n",
       "  ('sentence summarization', 0.7049)],\n",
       " [('sequence sequence', 0.4218),\n",
       "  ('sequence seq2seq', 0.5372),\n",
       "  ('summarization abs', 0.5672),\n",
       "  ('abstractive summarization', 0.6059),\n",
       "  ('summarization', 0.6273)],\n",
       " [('passage preserving', 0.4893),\n",
       "  ('version passage', 0.4911),\n",
       "  ('known text', 0.4923),\n",
       "  ('summarization', 0.6413),\n",
       "  ('text summarization', 0.7278)],\n",
       " [('automatically generating', 0.4269),\n",
       "  ('generating summary', 0.5547),\n",
       "  ('summarization', 0.6718),\n",
       "  ('summarization process', 0.7173),\n",
       "  ('automatic summarization', 0.787)],\n",
       " [('cascade contextual', 0.425),\n",
       "  ('sarcasm detector', 0.5802),\n",
       "  ('contextual sarcasm', 0.6241),\n",
       "  ('modeling sarcasm', 0.6613),\n",
       "  ('sarcasm detection', 0.6814)],\n",
       " [('discussion forums', 0.3989),\n",
       "  ('sarcasm', 0.4133),\n",
       "  ('cascade contextual', 0.4189),\n",
       "  ('contextual sarcasm', 0.6759),\n",
       "  ('sarcasm detection', 0.712)],\n",
       " [('lexical syntactic', 0.3215),\n",
       "  ('literature automated', 0.362),\n",
       "  ('sarcasm', 0.428),\n",
       "  ('automated sarcasm', 0.7014),\n",
       "  ('sarcasm detection', 0.7491)],\n",
       " [('predicting predicates', 0.5483),\n",
       "  ('arguments neural', 0.5573),\n",
       "  ('neural semantic', 0.5841),\n",
       "  ('semantic role', 0.5979),\n",
       "  ('role labeling', 0.644)],\n",
       " [('semantic', 0.464),\n",
       "  ('predicateargument relations', 0.5033),\n",
       "  ('labeling srl', 0.6004),\n",
       "  ('role labeling', 0.6383),\n",
       "  ('semantic role', 0.6491)],\n",
       " [('srl', 0.4211),\n",
       "  ('predicate', 0.4245),\n",
       "  ('sentence determining', 0.4313),\n",
       "  ('srl task', 0.5062),\n",
       "  ('extract predicate', 0.5182)],\n",
       " [('shallow semantic', 0.4831),\n",
       "  ('semantic', 0.5187),\n",
       "  ('semantic parsing', 0.531),\n",
       "  ('role labeling', 0.691),\n",
       "  ('semantic role', 0.7109)],\n",
       " [('labeling srl', 0.5663),\n",
       "  ('role labeling', 0.5875),\n",
       "  ('extraction semantic', 0.6112),\n",
       "  ('semantic role', 0.6128),\n",
       "  ('relation extraction', 0.6656)],\n",
       " [('self attention', 0.4973),\n",
       "  ('labeling self', 0.5496),\n",
       "  ('deep semantic', 0.5655),\n",
       "  ('semantic role', 0.5767),\n",
       "  ('role labeling', 0.655)],\n",
       " [('natural language', 0.5182),\n",
       "  ('semantic', 0.5494),\n",
       "  ('labeling srl', 0.6669),\n",
       "  ('role labeling', 0.6773),\n",
       "  ('semantic role', 0.7353)],\n",
       " [('identifying formed', 0.2753),\n",
       "  ('formed natural', 0.288),\n",
       "  ('language questions', 0.4641),\n",
       "  ('questions', 0.4944),\n",
       "  ('natural language', 0.5423)],\n",
       " [('causal', 0.4188),\n",
       "  ('sieve based', 0.4323),\n",
       "  ('causal relation', 0.4368),\n",
       "  ('temporal causal', 0.4908),\n",
       "  ('relation extraction', 0.5395)],\n",
       " [('approach temporal', 0.4117),\n",
       "  ('structured', 0.4274),\n",
       "  ('temporal relation', 0.5022),\n",
       "  ('structured learning', 0.5327),\n",
       "  ('relation extraction', 0.7097)],\n",
       " [('relations events', 0.5573),\n",
       "  ('language understanding', 0.5651),\n",
       "  ('natural language', 0.5959),\n",
       "  ('temporal relations', 0.5999),\n",
       "  ('identifying temporal', 0.619)],\n",
       " [('temporal relation', 0.5807),\n",
       "  ('temporal', 0.5923),\n",
       "  ('timex extraction', 0.6233),\n",
       "  ('tasks temporal', 0.6319),\n",
       "  ('temporal processing', 0.7315)],\n",
       " [('multimodal', 0.5097),\n",
       "  ('multimodal common', 0.5132),\n",
       "  ('image phrase', 0.5199),\n",
       "  ('level multimodal', 0.5276),\n",
       "  ('phrase grounding', 0.6605)],\n",
       " [('common semantic', 0.4829),\n",
       "  ('textual visual', 0.4994),\n",
       "  ('semantic space', 0.5305),\n",
       "  ('grounding learning', 0.6354),\n",
       "  ('phrase grounding', 0.6693)],\n",
       " [('dependency trees', 0.5113),\n",
       "  ('relations dependency', 0.5298),\n",
       "  ('mentions relations', 0.6159),\n",
       "  ('extraction entity', 0.633),\n",
       "  ('entity mentions', 0.6388)],\n",
       " [('relations text', 0.4695),\n",
       "  ('entities relations', 0.4753),\n",
       "  ('tasks nlp', 0.5756),\n",
       "  ('structured prediction', 0.6095),\n",
       "  ('extraction entities', 0.6365)],\n",
       " [('mention relation', 0.5409),\n",
       "  ('entity mention', 0.5574),\n",
       "  ('sentencelevel', 0.5844),\n",
       "  ('relation extraction', 0.7095),\n",
       "  ('extraction sentencelevel', 0.7384)],\n",
       " [('similarity', 0.4271),\n",
       "  ('relation', 0.4424),\n",
       "  ('similarity relation', 0.5228),\n",
       "  ('distributional similarity', 0.5498),\n",
       "  ('relation learning', 0.7885)],\n",
       " [('entities', 0.4742),\n",
       "  ('natural language', 0.5195),\n",
       "  ('language processing', 0.5326),\n",
       "  ('relations entities', 0.5955),\n",
       "  ('extract relations', 0.6721)],\n",
       " [('extraction determine', 0.4028),\n",
       "  ('target entities', 0.4213),\n",
       "  ('relation', 0.4633),\n",
       "  ('relation target', 0.5798),\n",
       "  ('relation extraction', 0.7947)],\n",
       " [('improves relation', 0.4488),\n",
       "  ('graph convolution', 0.4557),\n",
       "  ('relation', 0.4655),\n",
       "  ('dependency trees', 0.5068),\n",
       "  ('relation extraction', 0.6958)],\n",
       " [('relationships entity', 0.505),\n",
       "  ('entity pairs', 0.546),\n",
       "  ('semantic relationships', 0.577),\n",
       "  ('extracting semantic', 0.5979),\n",
       "  ('relation extraction', 0.773)],\n",
       " [('pairs entity', 0.4484),\n",
       "  ('relations multiple', 0.4634),\n",
       "  ('entity mentions', 0.4756),\n",
       "  ('recognize relations', 0.4927),\n",
       "  ('multiplerelations extraction', 0.6436)],\n",
       " [('automatically extracted', 0.4279),\n",
       "  ('facts automatically', 0.5087),\n",
       "  ('populate knowledge', 0.5259),\n",
       "  ('documents improved', 0.5338),\n",
       "  ('knowledge bases', 0.5843)],\n",
       " [('populate knowledge', 0.5407),\n",
       "  ('natural language', 0.5772),\n",
       "  ('relational facts', 0.5805),\n",
       "  ('base relational', 0.592),\n",
       "  ('knowledge base', 0.663)],\n",
       " [('improving distantly', 0.3746),\n",
       "  ('relation', 0.3817),\n",
       "  ('neural relation', 0.4419),\n",
       "  ('distantly supervised', 0.5282),\n",
       "  ('relation extraction', 0.6165)],\n",
       " [('knowledge base', 0.487),\n",
       "  ('unstructured text', 0.4976),\n",
       "  ('relation instances', 0.509),\n",
       "  ('supervised relation', 0.5928),\n",
       "  ('relation extraction', 0.7918)],\n",
       " [('level attention', 0.365),\n",
       "  ('cnns', 0.3864),\n",
       "  ('attention cnns', 0.5077),\n",
       "  ('relation', 0.5189),\n",
       "  ('relation classification', 0.7543)],\n",
       " [('neural', 0.3617),\n",
       "  ('extraction inner', 0.3794),\n",
       "  ('relation', 0.4717),\n",
       "  ('neural relation', 0.5777),\n",
       "  ('relation extraction', 0.6805)],\n",
       " [('relation', 0.4704),\n",
       "  ('relations', 0.5228),\n",
       "  ('relations pairs', 0.5407),\n",
       "  ('extract relations', 0.7566),\n",
       "  ('relation extraction', 0.8267)],\n",
       " [('relation', 0.4284),\n",
       "  ('supervised', 0.4408),\n",
       "  ('distant supervised', 0.6131),\n",
       "  ('relation extraction', 0.6523),\n",
       "  ('supervised relation', 0.6635)],\n",
       " [('transformers', 0.4294),\n",
       "  ('relations', 0.4474),\n",
       "  ('multiple relations', 0.4997),\n",
       "  ('trained transformers', 0.5679),\n",
       "  ('relations pass', 0.5722)],\n",
       " [('input paragraph', 0.4616),\n",
       "  ('relations input', 0.4622),\n",
       "  ('extracting multiple', 0.4751),\n",
       "  ('multiple entity', 0.5167),\n",
       "  ('entity relations', 0.549)],\n",
       " [('corpus achieve', 0.4034),\n",
       "  ('input corpus', 0.415),\n",
       "  ('entityrelations', 0.6018),\n",
       "  ('multiple entityrelations', 0.6202),\n",
       "  ('entityrelations extraction', 0.747)],\n",
       " [('relation', 0.4477),\n",
       "  ('relation pair', 0.4548),\n",
       "  ('entity mentions', 0.5497),\n",
       "  ('semantic relation', 0.5824),\n",
       "  ('relation extraction', 0.7224)],\n",
       " [('entities efficient', 0.3908),\n",
       "  ('input paragraphs', 0.4309),\n",
       "  ('mre', 0.5149),\n",
       "  ('solution mre', 0.5354),\n",
       "  ('mre important', 0.545)],\n",
       " [('supervision', 0.3096),\n",
       "  ('relation', 0.4259),\n",
       "  ('supervision relation', 0.4644),\n",
       "  ('distant supervision', 0.4773),\n",
       "  ('relation extraction', 0.6547)],\n",
       " [('aware representations', 0.4102),\n",
       "  ('representations knowledge', 0.4432),\n",
       "  ('base relation', 0.492),\n",
       "  ('knowledge base', 0.5688),\n",
       "  ('relation extraction', 0.7127)],\n",
       " [('relations', 0.4682),\n",
       "  ('sentence level', 0.4841),\n",
       "  ('target relation', 0.5089),\n",
       "  ('relations sentential', 0.5779),\n",
       "  ('relation extraction', 0.7055)],\n",
       " [('target relation', 0.5674),\n",
       "  ('relation target', 0.5774),\n",
       "  ('relation instance', 0.5798),\n",
       "  ('sentential relation', 0.6088),\n",
       "  ('relation extraction', 0.7127)]]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Init KeyBERT\n",
    "research_problem_model = KeyBERT()\n",
    "research_problem_model.extract_keywords(docs=train_docs, keyphrase_ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8b628593",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emotionless/.local/lib/python3.8/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n",
      "  warnings.warn(\n",
      "429it [00:00, 556.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[('token', 0.2733),\n",
       "  ('conversion', 0.2934),\n",
       "  ('phoneme', 0.3567),\n",
       "  ('level ensemble distillation', 0.5382),\n",
       "  ('grapheme', 0.5524)],\n",
       " [('g2p', 0.4203),\n",
       "  ('phoneme', 0.4532),\n",
       "  ('automatic speech recognition', 0.4773),\n",
       "  ('speech systems', 0.4931),\n",
       "  ('grapheme', 0.5763)],\n",
       " [('fast', 0.1955),\n",
       "  ('speech', 0.4257),\n",
       "  ('text', 0.4416),\n",
       "  ('fastspeech', 0.4749),\n",
       "  ('controllable text', 0.5102)],\n",
       " [('speech', 0.2757),\n",
       "  ('tts', 0.2999),\n",
       "  ('text', 0.3136),\n",
       "  ('neural network', 0.3609),\n",
       "  ('end text', 0.3925)],\n",
       " [('attention', 0.3121),\n",
       "  ('deep learning', 0.4098),\n",
       "  ('speech', 0.4179),\n",
       "  ('tts', 0.4337),\n",
       "  ('text', 0.4501)],\n",
       " [('statistical parametric approaches', 0.2192),\n",
       "  ('speech', 0.245),\n",
       "  ('neural network', 0.3255),\n",
       "  ('tts', 0.4535),\n",
       "  ('speech quality', 0.5495)],\n",
       " [('synthesis', 0.3477),\n",
       "  ('speaker', 0.4316),\n",
       "  ('multispeaker text', 0.5284),\n",
       "  ('speech synthesis', 0.6071),\n",
       "  ('speaker verification', 0.6545)],\n",
       " [('neural network', 0.3687),\n",
       "  ('audio', 0.4286),\n",
       "  ('synthesis', 0.4294),\n",
       "  ('voice', 0.4567),\n",
       "  ('speech audio', 0.6025)],\n",
       " [('speakers', 0.3115),\n",
       "  ('speech', 0.4022),\n",
       "  ('tts', 0.4744),\n",
       "  ('natural speech', 0.551),\n",
       "  ('tts system', 0.5821)],\n",
       " [('learning', 0.341),\n",
       "  ('document', 0.3633),\n",
       "  ('uncertainties', 0.3933),\n",
       "  ('embeddings', 0.6725),\n",
       "  ('document embeddings', 0.7504)],\n",
       " [('classifier', 0.3268),\n",
       "  ('embeddings', 0.4373),\n",
       "  ('generative gaussian linear classifier', 0.5455),\n",
       "  ('document embeddings', 0.5737),\n",
       "  ('topic identification', 0.6279)],\n",
       " [('natural language processing', 0.4006),\n",
       "  ('natural language processing applications', 0.4133),\n",
       "  ('information retrieval', 0.4739),\n",
       "  ('embeddings', 0.5086),\n",
       "  ('document embeddings', 0.5796)],\n",
       " [('learning', 0.259),\n",
       "  ('deep learning', 0.4853),\n",
       "  ('smile recognition', 0.767)],\n",
       " [('convolutional neural networks', 0.5207),\n",
       "  ('deep convolutional neural networks', 0.5593),\n",
       "  ('facial expression recognition', 0.5752),\n",
       "  ('particular smile recognition', 0.6246),\n",
       "  ('smile recognition', 0.6651)],\n",
       " [('audio', 0.3506),\n",
       "  ('emotion', 0.4025),\n",
       "  ('emotion recognition', 0.5697),\n",
       "  ('speech emotion recognition', 0.7241),\n",
       "  ('multimodal speech emotion recognition', 0.9263)],\n",
       " [('rotatory attention', 0.3804),\n",
       "  ('sentiment analysis', 0.4562),\n",
       "  ('based sentiment analysis', 0.4631),\n",
       "  ('right separated neural network', 0.526),\n",
       "  ('aspect based sentiment analysis', 0.6401)],\n",
       " [('based sentiment analysis', 0.5066),\n",
       "  ('sentiment classification', 0.5439),\n",
       "  ('aspect extraction', 0.6875),\n",
       "  ('aspect based sentiment analysis', 0.7675),\n",
       "  ('aspect sentiment classification', 0.7971)],\n",
       " [('emotion', 0.3847),\n",
       "  ('conversations', 0.4045),\n",
       "  ('rnn', 0.434),\n",
       "  ('emotion detection', 0.519),\n",
       "  ('attentive rnn', 0.5849)],\n",
       " [('classification', 0.3434),\n",
       "  ('bert', 0.4373),\n",
       "  ('sentiment', 0.4949),\n",
       "  ('sentiment classification', 0.6776)],\n",
       " [('topic', 0.2723),\n",
       "  ('service', 0.2773),\n",
       "  ('classification', 0.4997),\n",
       "  ('sentiment', 0.5611),\n",
       "  ('sentiment classification', 0.7783)],\n",
       " [('icon', 0.3015),\n",
       "  ('memory', 0.3234),\n",
       "  ('emotion', 0.4039),\n",
       "  ('emotion detection', 0.5441),\n",
       "  ('interactive conversational memory network', 0.6798)],\n",
       " [('machines', 0.2708),\n",
       "  ('conversations', 0.4016),\n",
       "  ('emotion', 0.4718),\n",
       "  ('emotion recognition', 0.6142),\n",
       "  ('empathetic machines', 0.7046)],\n",
       " [('complex', 0.2946),\n",
       "  ('complex challenges', 0.3961),\n",
       "  ('conversations', 0.6032),\n",
       "  ('emotional dynamics', 0.7226)],\n",
       " [('multi', 0.2917),\n",
       "  ('attention', 0.3596),\n",
       "  ('sentiment', 0.362),\n",
       "  ('sentiment analysis', 0.4383),\n",
       "  ('modal attention', 0.6077)],\n",
       " [('aspect', 0.4985),\n",
       "  ('sentiment analysis', 0.5804),\n",
       "  ('sentiment classification', 0.6651),\n",
       "  ('level sentiment classification', 0.6811),\n",
       "  ('aspect level sentiment classification', 0.8749)],\n",
       " [('sentiment', 0.4138),\n",
       "  ('attention neural networks', 0.5217),\n",
       "  ('sentiment classification', 0.6115),\n",
       "  ('level sentiment classification', 0.6616),\n",
       "  ('aspect level sentiment classification', 0.8179)],\n",
       " [('classification', 0.4748),\n",
       "  ('long movie reviews', 0.4819),\n",
       "  ('document classification tasks', 0.6518),\n",
       "  ('binary sentiment classification', 0.6751),\n",
       "  ('sentiment classification', 0.6807)],\n",
       " [('general sentiment classification', 0.6417),\n",
       "  ('sentiment classification', 0.6505),\n",
       "  ('level sentiment classification', 0.6738),\n",
       "  ('aspect level sentiment classification', 0.8618),\n",
       "  ('aspect level sentiment classification identifies opinions', 0.902)],\n",
       " [('attention', 0.381),\n",
       "  ('recurrent', 0.3962),\n",
       "  ('sentiment analysis', 0.4719),\n",
       "  ('attention network', 0.5281),\n",
       "  ('recurrent attention network', 0.633)],\n",
       " [('memory', 0.2711),\n",
       "  ('videos', 0.2761),\n",
       "  ('emotion', 0.3244),\n",
       "  ('emotion recognition', 0.4723),\n",
       "  ('dyadic dialogue videos', 0.6571)],\n",
       " [('videos', 0.3011),\n",
       "  ('emotion', 0.3769),\n",
       "  ('conversations', 0.4169),\n",
       "  ('emotion detection', 0.5714),\n",
       "  ('dyadic conversations', 0.5859)],\n",
       " [('emotion', 0.4222),\n",
       "  ('chatbots', 0.4427),\n",
       "  ('opinion mining', 0.4547),\n",
       "  ('public opinion mining', 0.4841),\n",
       "  ('emotion detection', 0.6363)],\n",
       " [('aspect', 0.3943),\n",
       "  ('sensitive memory networks', 0.4537),\n",
       "  ('memory networks', 0.4728),\n",
       "  ('sentiment classification', 0.5751),\n",
       "  ('aspect sentiment classification', 0.7504)],\n",
       " [('classification', 0.4181),\n",
       "  ('aspect', 0.4773),\n",
       "  ('sentiment analysis', 0.5243),\n",
       "  ('sentiment classification', 0.6113),\n",
       "  ('aspect sentiment classification', 0.8146)],\n",
       " [('attention', 0.404),\n",
       "  ('asc', 0.4329),\n",
       "  ('major drawback', 0.4495),\n",
       "  ('attention mechanism', 0.519)],\n",
       " [('aspect term', 0.4199),\n",
       "  ('sentiment', 0.4317),\n",
       "  ('variational semi', 0.4593),\n",
       "  ('sentiment analysis', 0.5451),\n",
       "  ('term sentiment analysis', 0.5707)],\n",
       " [('aspect', 0.4946),\n",
       "  ('absa', 0.51),\n",
       "  ('category sentiment analysis', 0.5225),\n",
       "  ('aspect term', 0.5598),\n",
       "  ('aspect based sentiment analysis', 0.7191)],\n",
       " [('polarity', 0.3384),\n",
       "  ('categories', 0.4039),\n",
       "  ('sentiment', 0.4394),\n",
       "  ('sentiment polarity', 0.4934),\n",
       "  ('acsa', 0.5559)],\n",
       " [('single word', 0.2968),\n",
       "  ('sentiment', 0.3323),\n",
       "  ('text', 0.3603),\n",
       "  ('sentiment polarity', 0.3668),\n",
       "  ('atsa', 0.5187)],\n",
       " [('emotion', 0.3212),\n",
       "  ('eeg', 0.3345),\n",
       "  ('graph', 0.3401),\n",
       "  ('emotion recognition', 0.4977),\n",
       "  ('based emotion recognition', 0.5223)],\n",
       " [('body language', 0.2978),\n",
       "  ('physiological signals', 0.3544),\n",
       "  ('emotions', 0.4639),\n",
       "  ('human emotions', 0.506),\n",
       "  ('affective computing', 0.6078)],\n",
       " [('classification', 0.2295),\n",
       "  ('sentiment', 0.3513),\n",
       "  ('encoder', 0.3995),\n",
       "  ('sentiment classification', 0.5058),\n",
       "  ('attentional encoder network', 0.7372)],\n",
       " [('sentiment', 0.4394),\n",
       "  ('sentiment analysis', 0.5491),\n",
       "  ('sentiment classification', 0.5885),\n",
       "  ('level sentiment classification', 0.6241),\n",
       "  ('aspect level sentiment classification', 0.7904)],\n",
       " [('infancy', 0.3782),\n",
       "  ('neural network models', 0.399),\n",
       "  ('sentiment', 0.4148),\n",
       "  ('sentiment classification task', 0.5366),\n",
       "  ('sentiment classification', 0.5502)],\n",
       " [('attention', 0.3402),\n",
       "  ('sentiment', 0.3616),\n",
       "  ('sentiment analysis', 0.4448),\n",
       "  ('lstm', 0.5457),\n",
       "  ('deep lstm', 0.5924)],\n",
       " [('semeval', 0.3363),\n",
       "  ('deep learning', 0.3834),\n",
       "  ('twitter', 0.4454),\n",
       "  ('sentiment', 0.4653),\n",
       "  ('sentiment analysis', 0.5018)],\n",
       " [('nlp', 0.436),\n",
       "  ('sarcasm detection', 0.4371),\n",
       "  ('sentiment', 0.4948),\n",
       "  ('aspect extraction', 0.5161),\n",
       "  ('sentiment analysis', 0.6758)],\n",
       " [('aspect', 0.4045),\n",
       "  ('based sentiment analysis', 0.5174),\n",
       "  ('sentiment analysis', 0.5204),\n",
       "  ('gated convolutional networks', 0.5613),\n",
       "  ('aspect based sentiment analysis', 0.704)],\n",
       " [('absa', 0.5067),\n",
       "  ('general sentiment analysis', 0.5417),\n",
       "  ('based sentiment analysis', 0.5477),\n",
       "  ('sentiment analysis', 0.5907),\n",
       "  ('aspect based sentiment analysis', 0.7643)],\n",
       " [('sentiment analysis', 0.5066),\n",
       "  ('aspect', 0.5254),\n",
       "  ('term sentiment analysis', 0.5514),\n",
       "  ('aspect term', 0.5607),\n",
       "  ('category sentiment analysis', 0.6156)],\n",
       " [('phrases', 0.4399),\n",
       "  ('classifier', 0.4478),\n",
       "  ('sentiment', 0.4639),\n",
       "  ('aspects', 0.5047),\n",
       "  ('absa classifier', 0.5673)],\n",
       " [('attention', 0.4265),\n",
       "  ('sentiment classification', 0.5725),\n",
       "  ('level sentiment classification', 0.5953),\n",
       "  ('effective attention modeling', 0.6156),\n",
       "  ('aspect level sentiment classification', 0.7854)],\n",
       " [('aspect', 0.3588),\n",
       "  ('attention', 0.3678),\n",
       "  ('sentiment analysis', 0.4366),\n",
       "  ('level sentiment analysis', 0.4779),\n",
       "  ('attention learning', 0.4976)],\n",
       " [('attention mechanisms', 0.4504),\n",
       "  ('dominant neural models', 0.4919),\n",
       "  ('sentiment classification', 0.5247),\n",
       "  ('level sentiment classification', 0.5666),\n",
       "  ('aspect level sentiment classification', 0.6891)],\n",
       " [('attention mechanisms', 0.4607),\n",
       "  ('attention', 0.4853),\n",
       "  ('neural asc models', 0.542),\n",
       "  ('attention learning', 0.6074),\n",
       "  ('useful attention supervision information', 0.6316)],\n",
       " [('aspects', 0.5335),\n",
       "  ('aspect term', 0.5897),\n",
       "  ('general aspect category', 0.6022),\n",
       "  ('specific aspect term', 0.6116),\n",
       "  ('aspect level sentiment classification', 0.7022)],\n",
       " [('networks', 0.3628),\n",
       "  ('recurrent', 0.4267),\n",
       "  ('neural networks', 0.5258),\n",
       "  ('convolutional neural networks', 0.7185),\n",
       "  ('recurrent neural filters', 0.7901)],\n",
       " [('convolution', 0.3171),\n",
       "  ('language', 0.3434),\n",
       "  ('long term dependencies', 0.3818),\n",
       "  ('compositionality', 0.3905),\n",
       "  ('rnns', 0.4928)],\n",
       " [('structured long short', 0.4437),\n",
       "  ('memory networks', 0.5727),\n",
       "  ('term memory', 0.5791),\n",
       "  ('semantic representations', 0.6362),\n",
       "  ('long short term memory', 0.7251)],\n",
       " [('lstms', 0.4803),\n",
       "  ('lstm', 0.5269),\n",
       "  ('strong lstm baselines', 0.5717),\n",
       "  ('sentiment treebank', 0.5848),\n",
       "  ('stanford sentiment treebank', 0.6119)],\n",
       " [('attention', 0.3861),\n",
       "  ('sentiment analysis', 0.4519),\n",
       "  ('level sentiment analysis', 0.5142),\n",
       "  ('attention network', 0.5554),\n",
       "  ('aware bidirectional attention network', 0.6395)],\n",
       " [('networks', 0.2131),\n",
       "  ('neural networks', 0.2852),\n",
       "  ('emotion', 0.3868),\n",
       "  ('emotion recognition', 0.5964),\n",
       "  ('modal emotion recognition on iemocap', 0.9245)],\n",
       " [('emotion', 0.5267),\n",
       "  ('sentiment', 0.5441),\n",
       "  ('emotion recognition', 0.5679),\n",
       "  ('positive sentiment', 0.6121),\n",
       "  ('negative sentiment', 0.6305)],\n",
       " [('emotion', 0.3361),\n",
       "  ('eeg', 0.4698),\n",
       "  ('emotion recognition', 0.4762),\n",
       "  ('hemispheric discrepancy model', 0.5624),\n",
       "  ('eeg emotion recognition', 0.7329)],\n",
       " [('eeg', 0.4467),\n",
       "  ('hemispheres', 0.4467),\n",
       "  ('hemispheric discrepancy model', 0.5408),\n",
       "  ('electroencephalograph', 0.5695),\n",
       "  ('eeg emotion recognition', 0.6236)],\n",
       " [('pattern recognition research communities', 0.389),\n",
       "  ('emotion', 0.4303),\n",
       "  ('emotions', 0.4538),\n",
       "  ('human emotions', 0.5722),\n",
       "  ('emotion recognition', 0.6131)],\n",
       " [('modeling', 0.1529),\n",
       "  ('sentence', 0.298),\n",
       "  ('convolution', 0.2984),\n",
       "  ('tree', 0.4406),\n",
       "  ('discriminative neural sentence modeling', 0.7494)],\n",
       " [('aspect', 0.4453),\n",
       "  ('bert', 0.4543),\n",
       "  ('based sentiment analysis', 0.4645),\n",
       "  ('sentiment analysis', 0.4945),\n",
       "  ('aspect based sentiment analysis', 0.6911)],\n",
       " [('absa', 0.4777),\n",
       "  ('aspect', 0.4813),\n",
       "  ('based sentiment analysis', 0.5557),\n",
       "  ('sentiment analysis', 0.6031),\n",
       "  ('aspect based sentiment analysis', 0.7809)],\n",
       " [('attention', 0.3564),\n",
       "  ('sentiment classification', 0.4896),\n",
       "  ('level sentiment classification', 0.5284),\n",
       "  ('attention network', 0.5366),\n",
       "  ('aspect level sentiment classification', 0.6714)],\n",
       " [('explicit aspect mentions', 0.5332),\n",
       "  ('aspect term', 0.5665),\n",
       "  ('sentiment orientation', 0.5766),\n",
       "  ('aspect level sentiment classification', 0.7463),\n",
       "  ('aspect term extraction', 0.7743)],\n",
       " [('sentiment', 0.3418),\n",
       "  ('attention', 0.3533),\n",
       "  ('sentiment analysis', 0.4528),\n",
       "  ('level sentiment analysis', 0.5428),\n",
       "  ('hierarchical attention based position', 0.5845)],\n",
       " [('aspects', 0.528),\n",
       "  ('aspect', 0.5334),\n",
       "  ('sentiment classification', 0.6479),\n",
       "  ('level sentiment classification', 0.6752),\n",
       "  ('aspect level sentiment classification', 0.8722)],\n",
       " [('target', 0.3467),\n",
       "  ('classification', 0.3612),\n",
       "  ('sentiment', 0.4281),\n",
       "  ('transformation networks', 0.5267),\n",
       "  ('sentiment classification', 0.6427)],\n",
       " [('sentiment', 0.3663),\n",
       "  ('lstm', 0.5361),\n",
       "  ('sentiment classification', 0.5629),\n",
       "  ('level sentiment classification', 0.5766),\n",
       "  ('aspect level sentiment classification', 0.7478)],\n",
       " [('sentiment', 0.4176),\n",
       "  ('neural networks', 0.4214),\n",
       "  ('rnns', 0.5148),\n",
       "  ('recurrent neural networks', 0.523),\n",
       "  ('sentiment analysis', 0.5326)],\n",
       " [('conversations', 0.3262),\n",
       "  ('emotion', 0.3519),\n",
       "  ('enriched transformer', 0.3994),\n",
       "  ('textual conversations', 0.4646),\n",
       "  ('emotion detection', 0.4803)],\n",
       " [('social networks', 0.3095),\n",
       "  ('conversations', 0.3839),\n",
       "  ('emotions', 0.4723),\n",
       "  ('textual conversations', 0.5484),\n",
       "  ('opinion mining', 0.595)],\n",
       " [('conversations', 0.4327),\n",
       "  ('emotion', 0.4638),\n",
       "  ('emotions', 0.4822),\n",
       "  ('conversational context', 0.4975),\n",
       "  ('textual conversations', 0.6133)],\n",
       " [('learning', 0.276),\n",
       "  ('multi', 0.2774),\n",
       "  ('emotion', 0.4556),\n",
       "  ('emo2 vec', 0.526),\n",
       "  ('generalized emotion representation', 0.6738)],\n",
       " [('similarity', 0.3631),\n",
       "  ('sentiment', 0.3763),\n",
       "  ('embeddings', 0.4506),\n",
       "  ('document embeddings', 0.5075),\n",
       "  ('sentiment classification', 0.6436)],\n",
       " [('polarity classification', 0.4631),\n",
       "  ('aspect term', 0.5198),\n",
       "  ('aspect term extraction highlights', 0.6624),\n",
       "  ('aspect term extraction', 0.6995),\n",
       "  ('aspect polarity classification', 0.7182)],\n",
       " [('polarity', 0.4156),\n",
       "  ('aspect', 0.5772),\n",
       "  ('aspect term', 0.6861),\n",
       "  ('aspect term polarity', 0.7731),\n",
       "  ('aspect term extraction', 0.799)],\n",
       " [('aspect', 0.3913),\n",
       "  ('aspect term', 0.4609),\n",
       "  ('chinese review datasets', 0.4893),\n",
       "  ('aspect polarity classification', 0.6634),\n",
       "  ('aspect term extraction', 0.7134)],\n",
       " [('aspects', 0.533),\n",
       "  ('based sentiment analysis', 0.5776),\n",
       "  ('traditional sentiment analysis', 0.6133),\n",
       "  ('sentiment analysis', 0.6286),\n",
       "  ('aspect based sentiment analysis', 0.8084)],\n",
       " [('problem', 0.1916),\n",
       "  ('task', 0.4556),\n",
       "  ('classification problem', 0.5209),\n",
       "  ('classification', 0.5278),\n",
       "  ('apc task', 0.8029)],\n",
       " [('apc problems', 0.4235),\n",
       "  ('deep learning', 0.4537),\n",
       "  ('lstm', 0.4837),\n",
       "  ('apc tasks', 0.5374),\n",
       "  ('long short term memory', 0.5452)],\n",
       " [('sentiment', 0.4432),\n",
       "  ('compositionality', 0.4757),\n",
       "  ('recursive deep models', 0.5827),\n",
       "  ('semantic compositionality', 0.6353),\n",
       "  ('sentiment treebank', 0.7236)],\n",
       " [('richer supervised training', 0.4119),\n",
       "  ('sentiment', 0.4473),\n",
       "  ('composition', 0.4481),\n",
       "  ('sentiment detection', 0.5581),\n",
       "  ('compositionality', 0.575)],\n",
       " [('hand', 0.271),\n",
       "  ('learning', 0.2892),\n",
       "  ('sentiment', 0.4001),\n",
       "  ('sentiment analysis', 0.4413),\n",
       "  ('deep sentiment analysis', 0.683)],\n",
       " [('sentiment', 0.4808),\n",
       "  ('deep neural architectures', 0.4872),\n",
       "  ('polarity classification', 0.5295),\n",
       "  ('sentiment polarity', 0.6036),\n",
       "  ('supervised sentiment polarity classification', 0.7092)],\n",
       " [('sentiment', 0.4447), ('arabic', 0.5791)],\n",
       " [('natural language processing', 0.465),\n",
       "  ('sentiment', 0.4655),\n",
       "  ('natural language processing applications', 0.536),\n",
       "  ('useful natural language processing applications', 0.5535),\n",
       "  ('sentiment analysis', 0.6518)],\n",
       " [('sentences', 0.3345),\n",
       "  ('tasks', 0.3767),\n",
       "  ('sa', 0.3943),\n",
       "  ('level tasks', 0.4044),\n",
       "  ('absa', 0.4687)],\n",
       " [('modeling', 0.2175),\n",
       "  ('sentence', 0.3361),\n",
       "  ('lstm', 0.5833),\n",
       "  ('improved sentence modeling', 0.6906),\n",
       "  ('suffix bidirectional lstm', 0.8166)],\n",
       " [('sequential data', 0.4435),\n",
       "  ('recurrent', 0.4442),\n",
       "  ('natural language processing', 0.4896),\n",
       "  ('textual data', 0.5325),\n",
       "  ('recurrent neural networks', 0.6408)],\n",
       " [('results', 0.1632),\n",
       "  ('classification', 0.3118),\n",
       "  ('sentiment', 0.4129),\n",
       "  ('question classification', 0.4867),\n",
       "  ('sentiment classification', 0.6078)],\n",
       " [('neural networks', 0.4557),\n",
       "  ('recurrent', 0.4805),\n",
       "  ('rnn', 0.5394),\n",
       "  ('sequential data', 0.6505),\n",
       "  ('recurrent neural networks', 0.6857)],\n",
       " [('emotion', 0.4211),\n",
       "  ('ambiguity resolution', 0.4616),\n",
       "  ('emotion recognition', 0.5689),\n",
       "  ('speech emotion recognition', 0.6859),\n",
       "  ('multimodal speech emotion recognition', 0.8784)],\n",
       " [('task', 0.1924),\n",
       "  ('nontrivial task', 0.3574),\n",
       "  ('ambiguous definition', 0.3689),\n",
       "  ('speech', 0.4512),\n",
       "  ('emotion', 0.5371)],\n",
       " [('emotion', 0.3627),\n",
       "  ('deep learning', 0.4039),\n",
       "  ('deep learning algorithms', 0.4275),\n",
       "  ('emotion recognition', 0.5763),\n",
       "  ('speech emotion recognition', 0.7035)],\n",
       " [('features', 0.4137),\n",
       "  ('deep learning', 0.5035),\n",
       "  ('deep learning models', 0.5358),\n",
       "  ('reliant deep learning models', 0.5894),\n",
       "  ('lighter machine learning models', 0.7885)],\n",
       " [('based sentiment analysis', 0.4509),\n",
       "  ('sentiment analysis', 0.4593),\n",
       "  ('targeted aspect', 0.4651),\n",
       "  ('recurrent entity networks', 0.6158),\n",
       "  ('aspect based sentiment analysis', 0.6515)],\n",
       " [('sentiment', 0.5),\n",
       "  ('targeted aspect', 0.5458),\n",
       "  ('based sentiment analysis', 0.5468),\n",
       "  ('sentiment analysis', 0.5606),\n",
       "  ('aspect based sentiment analysis', 0.7239)],\n",
       " [('classification', 0.3471),\n",
       "  ('sentiment', 0.3759),\n",
       "  ('length vector', 0.4015),\n",
       "  ('level sentiment classification', 0.578),\n",
       "  ('sentiment classification', 0.5971)],\n",
       " [('systems', 0.3197),\n",
       "  ('critical role', 0.332),\n",
       "  ('learning', 0.4744),\n",
       "  ('many modern machine learning systems', 0.603),\n",
       "  ('representation learning', 0.6217)],\n",
       " [('sentiment', 0.3167),\n",
       "  ('joint neural model', 0.3846),\n",
       "  ('sentiment analysis', 0.4355),\n",
       "  ('parsing', 0.4718),\n",
       "  ('sentence level discourse parsing', 0.7673)],\n",
       " [('aspect', 0.4805),\n",
       "  ('urban neighbourhoods', 0.482),\n",
       "  ('targeted aspect', 0.5369),\n",
       "  ('aspect based sentiment analysis', 0.6984),\n",
       "  ('targeted aspect based sentiment analysis dataset', 0.8363)],\n",
       " [('aspect', 0.5096),\n",
       "  ('sentiment analysis', 0.5873),\n",
       "  ('based sentiment analysis', 0.5977),\n",
       "  ('targeted aspect', 0.613),\n",
       "  ('aspect based sentiment analysis', 0.8386)],\n",
       " [('certain target entity', 0.3807),\n",
       "  ('opinion polarities', 0.4545),\n",
       "  ('sentiment', 0.4957),\n",
       "  ('sentiment analysis', 0.5869),\n",
       "  ('targeted sentiment analysis', 0.8218)],\n",
       " [('sentiment', 0.5306),\n",
       "  ('sentiment polarity', 0.6019),\n",
       "  ('level sentiment classification', 0.6488),\n",
       "  ('sentiment classification', 0.673),\n",
       "  ('aspect level sentiment classification', 0.8743)],\n",
       " [('context', 0.3385),\n",
       "  ('videos', 0.3884),\n",
       "  ('sentiment', 0.4583),\n",
       "  ('sentiment analysis', 0.507),\n",
       "  ('dependent sentiment analysis', 0.5828)],\n",
       " [('research', 0.272),\n",
       "  ('sentiments', 0.4547),\n",
       "  ('sentiment', 0.4741),\n",
       "  ('sentiment analysis', 0.5585),\n",
       "  ('multimodal sentiment analysis', 0.8458)],\n",
       " [('analysis', 0.2024),\n",
       "  ('approaches', 0.2025),\n",
       "  ('sentiment', 0.4407),\n",
       "  ('sentiment analysis', 0.5547),\n",
       "  ('multimodal sentiment analysis', 0.9135)],\n",
       " [('learning', 0.2525),\n",
       "  ('sentence', 0.3272),\n",
       "  ('embeddings', 0.4953),\n",
       "  ('sentence embeddings', 0.6908),\n",
       "  ('semantic sentence embeddings', 0.8046)],\n",
       " [('paper', 0.0973),\n",
       "  ('level', 0.1662),\n",
       "  ('sentence', 0.3195),\n",
       "  ('level embeddings', 0.636),\n",
       "  ('embeddings', 0.6392)],\n",
       " [('deep generative framework', 0.4995),\n",
       "  ('paraphrase', 0.592),\n",
       "  ('paraphrase generation', 0.8594)],\n",
       " [('problem', 0.0871), ('paper', 0.1512), ('paraphrases', 0.7236)],\n",
       " [('semantics', 0.4371),\n",
       "  ('knowledge base question', 0.495),\n",
       "  ('gated graph neural networks', 0.506),\n",
       "  ('knowledge base', 0.5293),\n",
       "  ('modeling semantics', 0.5641)],\n",
       " [('qa', 0.4771),\n",
       "  ('natural language processing', 0.49),\n",
       "  ('important natural language processing problem', 0.5387),\n",
       "  ('knowledge base', 0.5985),\n",
       "  ('knowledge base question', 0.6171)],\n",
       " [('sentence', 0.3272),\n",
       "  ('sentences', 0.4736),\n",
       "  ('qa', 0.4861),\n",
       "  ('qa model', 0.5287),\n",
       "  ('simple sentence selector', 0.6751)],\n",
       " [('kb', 0.3933),\n",
       "  ('qa', 0.4766),\n",
       "  ('kb qa', 0.5952),\n",
       "  ('parsing', 0.612),\n",
       "  ('semantic parsing', 0.7215)],\n",
       " [('single sentence', 0.3999),\n",
       "  ('queries', 0.436),\n",
       "  ('comprehension', 0.5149),\n",
       "  ('reading comprehension', 0.6903),\n",
       "  ('most reading comprehension methods', 0.7667)],\n",
       " [('evidence', 0.3467),\n",
       "  ('attention', 0.375),\n",
       "  ('textual evidence', 0.519),\n",
       "  ('comprehension', 0.5628),\n",
       "  ('reading comprehension', 0.6949)],\n",
       " [('children', 0.2963),\n",
       "  ('rc', 0.3215),\n",
       "  ('artificial agents', 0.3556),\n",
       "  ('learning', 0.3607),\n",
       "  ('rc ability', 0.4036)],\n",
       " [('match', 0.2763),\n",
       "  ('machine', 0.3093),\n",
       "  ('comprehension', 0.4892),\n",
       "  ('lstm', 0.5577),\n",
       "  ('machine comprehension', 0.706)],\n",
       " [('natural language', 0.3323),\n",
       "  ('artificial intelligence', 0.3686),\n",
       "  ('mc', 0.4617),\n",
       "  ('comprehension', 0.472),\n",
       "  ('machine comprehension', 0.6446)],\n",
       " [('task', 0.3828),\n",
       "  ('mc', 0.3971),\n",
       "  ('insufficient lexical understanding', 0.3984),\n",
       "  ('incorrect answer extraction', 0.4585),\n",
       "  ('mc task', 0.626)],\n",
       " [('models', 0.267),\n",
       "  ('significant performance improvements', 0.2799),\n",
       "  ('documents', 0.2937),\n",
       "  ('qa', 0.3523),\n",
       "  ('neural models', 0.4253)],\n",
       " [('text', 0.3394),\n",
       "  ('visual question', 0.3978),\n",
       "  ('attention', 0.5412),\n",
       "  ('focal visual', 0.5586),\n",
       "  ('text attention', 0.6126)],\n",
       " [('natural language', 0.4036),\n",
       "  ('answer questions', 0.405),\n",
       "  ('computer vision', 0.4221),\n",
       "  ('visual question', 0.4715),\n",
       "  ('vqa', 0.5177)],\n",
       " [('problem', 0.1108),\n",
       "  ('paper', 0.1569),\n",
       "  ('image', 0.358),\n",
       "  ('single image', 0.4852),\n",
       "  ('vqa', 0.5332)],\n",
       " [('answer', 0.2267),\n",
       "  ('answer re', 0.2346),\n",
       "  ('evidence', 0.3479),\n",
       "  ('ranking', 0.3983),\n",
       "  ('evidence aggregation', 0.5336)],\n",
       " [('knowledge', 0.331),\n",
       "  ('questions', 0.3623),\n",
       "  ('qa', 0.4608),\n",
       "  ('answer questions', 0.4679),\n",
       "  ('domain knowledge sources', 0.511)],\n",
       " [('domain', 0.1807),\n",
       "  ('squad', 0.2898),\n",
       "  ('qa', 0.4114),\n",
       "  ('datasets', 0.4945),\n",
       "  ('domain qa datasets', 0.7149)],\n",
       " [('classification', 0.3349),\n",
       "  ('intent', 0.3643),\n",
       "  ('scientific publications', 0.4866),\n",
       "  ('citation', 0.5451),\n",
       "  ('citation intent classification', 0.8657)],\n",
       " [('machine reading', 0.3947),\n",
       "  ('individual publications', 0.4279),\n",
       "  ('scientific literature', 0.5086),\n",
       "  ('scientific papers', 0.5318),\n",
       "  ('citation', 0.5506)],\n",
       " [('classification', 0.3389),\n",
       "  ('intent', 0.4236),\n",
       "  ('citation', 0.5003),\n",
       "  ('citation context', 0.5847),\n",
       "  ('citation intent classification', 0.9053)],\n",
       " [('neural networks', 0.4105),\n",
       "  ('hierarchical neural networks', 0.5409),\n",
       "  ('sentence classification', 0.6045),\n",
       "  ('medical scientific abstracts', 0.6397),\n",
       "  ('sequential sentence classification', 0.6875)],\n",
       " [('classification', 0.4513),\n",
       "  ('structured prediction', 0.5909),\n",
       "  ('traditional sentence classification approaches', 0.7288),\n",
       "  ('sentence classification', 0.7457),\n",
       "  ('sequential sentence classification', 0.7812)],\n",
       " [('sentence', 0.3672),\n",
       "  ('classification', 0.371),\n",
       "  ('translations', 0.5428),\n",
       "  ('additional contexts', 0.5818),\n",
       "  ('sentence classification', 0.6831)],\n",
       " [('language', 0.3697),\n",
       "  ('sentence', 0.3746),\n",
       "  ('evaluator', 0.5288),\n",
       "  ('language model', 0.5394),\n",
       "  ('sentence compression', 0.7355)],\n",
       " [('deletion', 0.3004),\n",
       "  ('sentence', 0.3469),\n",
       "  ('lstms', 0.5964),\n",
       "  ('sentence compression', 0.7606)],\n",
       " [('deletion', 0.3017),\n",
       "  ('language', 0.3032),\n",
       "  ('evaluation operations', 0.4145),\n",
       "  ('evaluator', 0.4586),\n",
       "  ('sentence compression', 0.6917)],\n",
       " [('nlp', 0.4763),\n",
       "  ('paraphrase', 0.5321),\n",
       "  ('standard nlp task', 0.5357),\n",
       "  ('shorter paraphrase', 0.6067),\n",
       "  ('sentence compression', 0.8144)],\n",
       " [('sentence', 0.3102),\n",
       "  ('learning', 0.3484),\n",
       "  ('gaze', 0.5301),\n",
       "  ('sentence compression', 0.5861)],\n",
       " [('word', 0.2454),\n",
       "  ('representations', 0.2531),\n",
       "  ('text', 0.3039),\n",
       "  ('contextualized word representations', 0.5674),\n",
       "  ('prosodic prominence', 0.7227)],\n",
       " [('text', 0.3018),\n",
       "  ('natural language', 0.3747),\n",
       "  ('natural language processing', 0.4625),\n",
       "  ('new natural language processing dataset', 0.5492),\n",
       "  ('prosodic prominence', 0.684)],\n",
       " [('emphasis', 0.3227),\n",
       "  ('speaker', 0.3249),\n",
       "  ('text', 0.4016),\n",
       "  ('sequence labeling task', 0.5748),\n",
       "  ('prosody prediction', 0.7406)],\n",
       " [('dataset', 0.3241),\n",
       "  ('sql task', 0.4355),\n",
       "  ('parsing', 0.4379),\n",
       "  ('semantic parsing', 0.553),\n",
       "  ('domain semantic parsing', 0.6292)],\n",
       " [('natural language', 0.5271),\n",
       "  ('nlp', 0.549),\n",
       "  ('natural language processing', 0.6652),\n",
       "  ('parsing', 0.672),\n",
       "  ('semantic parsing', 0.8104)],\n",
       " [('sp', 0.3298), ('shortcomings', 0.4935), ('datasets', 0.6014)],\n",
       " [('transition', 0.2947),\n",
       "  ('parsing', 0.5078),\n",
       "  ('semantic parsing', 0.5622),\n",
       "  ('neural abstract syntax parser', 0.8358)],\n",
       " [('coarse', 0.2052),\n",
       "  ('parsing', 0.5508),\n",
       "  ('fine decoding', 0.5586),\n",
       "  ('semantic parsing', 0.64),\n",
       "  ('neural semantic parsing', 0.82)],\n",
       " [('natural language', 0.5168),\n",
       "  ('natural language utterances', 0.5472),\n",
       "  ('parsing', 0.6563),\n",
       "  ('structured meaning representations', 0.7454),\n",
       "  ('semantic parsing', 0.795)],\n",
       " [('learning', 0.3275),\n",
       "  ('negbert', 0.372),\n",
       "  ('scope resolution', 0.3751),\n",
       "  ('transfer learning approach', 0.5053),\n",
       "  ('negation detection', 0.6424)],\n",
       " [('discriminative model', 0.4342),\n",
       "  ('gan', 0.5696),\n",
       "  ('generative models', 0.6784),\n",
       "  ('generative model', 0.6789),\n",
       "  ('generative adversarial net', 0.7429)],\n",
       " [('goal', 0.088),\n",
       "  ('sequences', 0.4032),\n",
       "  ('limitations', 0.5069),\n",
       "  ('generating sequences', 0.5503),\n",
       "  ('discrete tokens', 0.6281)],\n",
       " [('real one', 0.253),\n",
       "  ('data', 0.3082),\n",
       "  ('learning', 0.3731),\n",
       "  ('unsupervised learning', 0.5516),\n",
       "  ('sequential synthetic data', 0.7883)],\n",
       " [('training', 0.2474),\n",
       "  ('skip', 0.377),\n",
       "  ('text', 0.3919),\n",
       "  ('adversarial training', 0.5176)],\n",
       " [('text', 0.3649),\n",
       "  ('embeddings', 0.4389),\n",
       "  ('word embeddings', 0.4978),\n",
       "  ('gans', 0.5631),\n",
       "  ('text generation', 0.6687)],\n",
       " [('natural language', 0.472),\n",
       "  ('machine translation', 0.4961),\n",
       "  ('natural language text', 0.5568),\n",
       "  ('text generation', 0.6773),\n",
       "  ('natural language text generation', 0.7603)],\n",
       " [('ranking', 0.3453),\n",
       "  ('language', 0.411),\n",
       "  ('adversarial ranking', 0.6421),\n",
       "  ('language generation', 0.7394)],\n",
       " [('training', 0.2527),\n",
       "  ('text', 0.3973),\n",
       "  ('leaked information', 0.4801),\n",
       "  ('adversarial training', 0.5611),\n",
       "  ('text generation', 0.6537)],\n",
       " [('translation', 0.2952),\n",
       "  ('text', 0.4798),\n",
       "  ('dialogue systems', 0.4876),\n",
       "  ('machine translation', 0.5424),\n",
       "  ('meaningful text', 0.5878)],\n",
       " [('text', 0.4041),\n",
       "  ('dilated convolutions', 0.5137),\n",
       "  ('text modeling', 0.528),\n",
       "  ('variational autoencoders', 0.6632),\n",
       "  ('improved variational autoencoders', 0.6882)],\n",
       " [('text modeling', 0.455),\n",
       "  ('lstm decoders', 0.5564),\n",
       "  ('simpler lstm language models', 0.5898),\n",
       "  ('generative text modeling', 0.612),\n",
       "  ('variational autoencoders', 0.6634)],\n",
       " [('encoder matching model', 0.3627),\n",
       "  ('utterance', 0.4039),\n",
       "  ('level semantic dependency', 0.4522),\n",
       "  ('learning utterance', 0.5957),\n",
       "  ('dialogue generation', 0.7221)],\n",
       " [('technical support agents', 0.3855),\n",
       "  ('chatbots', 0.566),\n",
       "  ('domain chatbots', 0.5855),\n",
       "  ('dialogue generation', 0.708),\n",
       "  ('automatic dialogue generation task', 0.8005)],\n",
       " [('word', 0.1738),\n",
       "  ('inputs', 0.1941),\n",
       "  ('flexible task', 0.2585),\n",
       "  ('responses', 0.3196),\n",
       "  ('conversation generation', 0.7758)],\n",
       " [('task', 0.2303),\n",
       "  ('nsurl', 0.3264),\n",
       "  ('similarity', 0.368),\n",
       "  ('arabic', 0.44),\n",
       "  ('semantic question similarity', 0.6709)],\n",
       " [('text', 0.2692),\n",
       "  ('task', 0.2885),\n",
       "  ('similarity', 0.4433),\n",
       "  ('nsurl', 0.4922),\n",
       "  ('semantic text question similarity task', 0.7674)],\n",
       " [('problems', 0.2182),\n",
       "  ('text', 0.3824),\n",
       "  ('sts', 0.3975),\n",
       "  ('similarity', 0.523),\n",
       "  ('semantic text similarity', 0.7377)],\n",
       " [('sentence', 0.3436),\n",
       "  ('sts', 0.41),\n",
       "  ('paraphrase', 0.5258),\n",
       "  ('paraphrase identification', 0.6441),\n",
       "  ('paraphrase identification task', 0.6648)],\n",
       " [('data annotation team', 0.3241),\n",
       "  ('similarity', 0.4225),\n",
       "  ('arabic', 0.4484),\n",
       "  ('arabic language', 0.4803),\n",
       "  ('semantic question similarity', 0.7154)],\n",
       " [('compare', 0.2129),\n",
       "  ('same meaning', 0.2149),\n",
       "  ('questions', 0.2934),\n",
       "  ('sts', 0.4405),\n",
       "  ('sqs', 0.6016)],\n",
       " [('query', 0.3201), ('document', 0.3418), ('document expansion', 0.6893)],\n",
       " [('passage', 0.4293),\n",
       "  ('ranking', 0.4342),\n",
       "  ('passage re', 0.4441),\n",
       "  ('bert', 0.5591)],\n",
       " [('passage', 0.2683),\n",
       "  ('query', 0.275),\n",
       "  ('passage re', 0.3171),\n",
       "  ('bert', 0.4081),\n",
       "  ('ranking', 0.4109)],\n",
       " [('question', 0.2203),\n",
       "  ('text', 0.3326),\n",
       "  ('neural question', 0.3903),\n",
       "  ('question generation', 0.7746),\n",
       "  ('neural question generation', 0.8978)],\n",
       " [('questions', 0.3891),\n",
       "  ('text passage', 0.3971),\n",
       "  ('automatic question', 0.646),\n",
       "  ('question generation', 0.8185),\n",
       "  ('automatic question generation', 0.8752)],\n",
       " [('natural language', 0.4371),\n",
       "  ('natural language text', 0.4621),\n",
       "  ('automatic question', 0.6913),\n",
       "  ('question generation', 0.7548),\n",
       "  ('automatic question generation', 0.8476)],\n",
       " [('corpus', 0.374),\n",
       "  ('answer pairs', 0.3887),\n",
       "  ('reverse task', 0.4009),\n",
       "  ('large scale corpus', 0.4162),\n",
       "  ('question generation', 0.7024)],\n",
       " [('question', 0.122),\n",
       "  ('visual question', 0.3324),\n",
       "  ('question generation', 0.5737),\n",
       "  ('multimodal differential network', 0.6378),\n",
       "  ('visual question generation', 0.7859)],\n",
       " [('image', 0.3304),\n",
       "  ('natural questions', 0.4044),\n",
       "  ('language modality', 0.4141),\n",
       "  ('semantic task', 0.4413),\n",
       "  ('multimodal representations', 0.6392)],\n",
       " [('au', 0.321),\n",
       "  ('challenging task', 0.3767),\n",
       "  ('questions', 0.4447),\n",
       "  ('thors', 0.4683),\n",
       "  ('natural questions', 0.5438)],\n",
       " [('tagging', 0.4541),\n",
       "  ('adversarial training', 0.4566),\n",
       "  ('multilingual part', 0.539),\n",
       "  ('speech tagging', 0.6525),\n",
       "  ('robust multilingual part', 0.6538)],\n",
       " [('paper', 0.1997),\n",
       "  ('model', 0.2916),\n",
       "  ('pos', 0.3846),\n",
       "  ('tagging', 0.5748),\n",
       "  ('neural pos tagging model', 0.9276)],\n",
       " [('words', 0.2856),\n",
       "  ('learning', 0.3198),\n",
       "  ('sequence', 0.3336),\n",
       "  ('better internal structure', 0.4684)],\n",
       " [('powerful model', 0.1634),\n",
       "  ('model', 0.1643),\n",
       "  ('sequence', 0.2862),\n",
       "  ('statistical sequence labeling', 0.7136)],\n",
       " [('transfer', 0.3048),\n",
       "  ('recurrent', 0.3895),\n",
       "  ('tagging', 0.4509),\n",
       "  ('recurrent networks', 0.5532),\n",
       "  ('sequence tagging', 0.659)],\n",
       " [('multilingual part', 0.4878),\n",
       "  ('term memory', 0.5527),\n",
       "  ('term memory models', 0.5872),\n",
       "  ('long short term memory', 0.5924),\n",
       "  ('speech tagging', 0.6952)],\n",
       " [('unicode', 0.3677),\n",
       "  ('embeddings', 0.3858),\n",
       "  ('tagging', 0.4093),\n",
       "  ('lstms', 0.431),\n",
       "  ('byte embeddings', 0.4339)],\n",
       " [('context', 0.2451),\n",
       "  ('token', 0.2643),\n",
       "  ('bilstm model', 0.3101),\n",
       "  ('tagging', 0.4674),\n",
       "  ('morphosyntactic tagging', 0.7601)],\n",
       " [('cnns', 0.3296),\n",
       "  ('sequence', 0.3505),\n",
       "  ('lstm', 0.507),\n",
       "  ('directional lstm', 0.5235),\n",
       "  ('end sequence labeling', 0.7001)],\n",
       " [('features', 0.2521),\n",
       "  ('handcrafted features', 0.317),\n",
       "  ('sequence', 0.3498),\n",
       "  ('taskspecific knowledge', 0.4301),\n",
       "  ('art sequence labeling systems', 0.6593)],\n",
       " [('deep language understanding', 0.4534),\n",
       "  ('natural language processing community', 0.4751),\n",
       "  ('entity recognition', 0.5242),\n",
       "  ('natural language processing', 0.5276),\n",
       "  ('linguistic sequence labeling', 0.656)],\n",
       " [('pos', 0.2828),\n",
       "  ('dependency', 0.4088),\n",
       "  ('tagging', 0.4373),\n",
       "  ('parsing', 0.5274),\n",
       "  ('joint pos tagging', 0.6084)],\n",
       " [('text', 0.323),\n",
       "  ('semantics', 0.479),\n",
       "  ('comprehension', 0.5748),\n",
       "  ('explicit contextual semantics', 0.7618),\n",
       "  ('text comprehension', 0.7744)],\n",
       " [('progress', 0.2892),\n",
       "  ('machine', 0.2989),\n",
       "  ('document', 0.3105),\n",
       "  ('answer questions', 0.3763),\n",
       "  ('machine reading', 0.6998)],\n",
       " [('machine', 0.2238),\n",
       "  ('context', 0.4319),\n",
       "  ('comprehension', 0.5592),\n",
       "  ('perspective context matching', 0.6397),\n",
       "  ('machine comprehension', 0.7039)],\n",
       " [('deep learning', 0.3838),\n",
       "  ('deep learning models', 0.4191),\n",
       "  ('comprehension', 0.4216),\n",
       "  ('machine comprehension', 0.5709),\n",
       "  ('previous machine comprehension', 0.6369)],\n",
       " [('inference', 0.3248),\n",
       "  ('natural language', 0.3315),\n",
       "  ('attention', 0.4203),\n",
       "  ('natural language inference', 0.5404),\n",
       "  ('attention network', 0.5857)],\n",
       " [('human', 0.2656),\n",
       "  ('reasoning', 0.5132),\n",
       "  ('artificial intelligence', 0.5392),\n",
       "  ('inference', 0.5465)],\n",
       " [('inference', 0.3321),\n",
       "  ('natural language', 0.4199),\n",
       "  ('deep learning', 0.4206),\n",
       "  ('nli', 0.4268),\n",
       "  ('natural language inference', 0.6195)],\n",
       " [('performance', 0.2576),\n",
       "  ('data', 0.2932),\n",
       "  ('nli', 0.5363),\n",
       "  ('snli data', 0.7144),\n",
       "  ('nli data', 0.7522)],\n",
       " [('clinical case reports', 0.4366),\n",
       "  ('comprehension', 0.4987),\n",
       "  ('machine reading', 0.5712),\n",
       "  ('reading comprehension', 0.6453),\n",
       "  ('machine reading comprehension', 0.7292)],\n",
       " [('text', 0.3176),\n",
       "  ('comprehension', 0.4411),\n",
       "  ('correct answer span', 0.4785),\n",
       "  ('reading comprehension', 0.6042),\n",
       "  ('end reading comprehension', 0.6364)],\n",
       " [('task', 0.2059),\n",
       "  ('document', 0.2407),\n",
       "  ('qa', 0.246),\n",
       "  ('rc', 0.4302),\n",
       "  ('answer span prediction style question', 0.465)],\n",
       " [('community question', 0.3415),\n",
       "  ('task', 0.3496),\n",
       "  ('semeval', 0.3526),\n",
       "  ('kelp system', 0.4322),\n",
       "  ('qa', 0.4842)],\n",
       " [('good answers', 0.2369),\n",
       "  ('task', 0.3039),\n",
       "  ('answers', 0.3335),\n",
       "  ('participants', 0.3552),\n",
       "  ('qa', 0.559)],\n",
       " [('computer vision', 0.3683),\n",
       "  ('natural language processing', 0.3778),\n",
       "  ('attention', 0.4045),\n",
       "  ('attention mechanisms', 0.4572),\n",
       "  ('neural networks', 0.5068)],\n",
       " [('attention mechanisms', 0.3764),\n",
       "  ('deep neural networks', 0.3851),\n",
       "  ('attention', 0.3914),\n",
       "  ('sequence compression', 0.527),\n",
       "  ('context fusion', 0.602)],\n",
       " [('learning', 0.374),\n",
       "  ('task', 0.4032),\n",
       "  ('tree', 0.4626),\n",
       "  ('compose task', 0.5563),\n",
       "  ('specific tree structures', 0.567)],\n",
       " [('memory', 0.457),\n",
       "  ('term memory', 0.5105),\n",
       "  ('term memory architecture', 0.5211),\n",
       "  ('lstm', 0.5758),\n",
       "  ('long short term memory', 0.6519)],\n",
       " [('natural language', 0.3631),\n",
       "  ('sentences', 0.381),\n",
       "  ('rte', 0.5055),\n",
       "  ('entailment', 0.6006),\n",
       "  ('textual entailment', 0.6904)],\n",
       " [('nlp', 0.4864),\n",
       "  ('many natural language processing', 0.5445),\n",
       "  ('information extraction', 0.5539),\n",
       "  ('accurate rte systems', 0.579),\n",
       "  ('natural language processing', 0.5836)],\n",
       " [('supervised learning', 0.3673),\n",
       "  ('inference', 0.3759),\n",
       "  ('natural language', 0.4011),\n",
       "  ('natural language inference', 0.6563),\n",
       "  ('universal sentence representations', 0.8033)],\n",
       " [('identification', 0.1779),\n",
       "  ('noisy pretraining', 0.2599),\n",
       "  ('questions', 0.3656),\n",
       "  ('paraphrase', 0.5275),\n",
       "  ('paraphrase identification', 0.7138)],\n",
       " [('identification', 0.24),\n",
       "  ('solution', 0.2404),\n",
       "  ('questions', 0.4305),\n",
       "  ('paraphrase', 0.5573),\n",
       "  ('paraphrase identification', 0.7982)],\n",
       " [('nlp', 0.478),\n",
       "  ('useful nlp application', 0.5365),\n",
       "  ('paraphrase', 0.6127),\n",
       "  ('paraphrase identification', 0.8462),\n",
       "  ('question paraphrase identification', 0.8709)],\n",
       " [('natural language', 0.4078),\n",
       "  ('natural language processing field', 0.4189),\n",
       "  ('mc', 0.4711),\n",
       "  ('comprehension', 0.5644),\n",
       "  ('machine comprehension', 0.721)],\n",
       " [('medical domain', 0.3768),\n",
       "  ('new dataset', 0.3872),\n",
       "  ('dataset', 0.4002),\n",
       "  ('comprehension', 0.5055),\n",
       "  ('machine comprehension', 0.6913)],\n",
       " [('memory', 0.6658), ('neural stored', 0.7492), ('program memory', 0.7851)],\n",
       " [('weights', 0.352),\n",
       "  ('new memory', 0.4916),\n",
       "  ('memory', 0.509),\n",
       "  ('modern computer architectures', 0.5296),\n",
       "  ('program memory', 0.631)],\n",
       " [('networks', 0.2407),\n",
       "  ('conference paper', 0.2744),\n",
       "  ('query', 0.3361),\n",
       "  ('reduction networks', 0.4032),\n",
       "  ('iclr', 0.4898)],\n",
       " [('evidence', 0.2407),\n",
       "  ('single document', 0.2443),\n",
       "  ('significant progress', 0.2471),\n",
       "  ('models', 0.2779),\n",
       "  ('neural models', 0.4618)],\n",
       " [('topic', 0.3684),\n",
       "  ('popular topic', 0.3758),\n",
       "  ('natural language', 0.4678),\n",
       "  ('natural language processing', 0.5118),\n",
       "  ('qa', 0.5847)],\n",
       " [('inference', 0.3966),\n",
       "  ('interaction space', 0.4269),\n",
       "  ('natural language', 0.4654),\n",
       "  ('iclr', 0.4905),\n",
       "  ('natural language inference', 0.6482)],\n",
       " [('learning', 0.3022),\n",
       "  ('inference', 0.4787),\n",
       "  ('natural language', 0.5006),\n",
       "  ('corpus', 0.5204),\n",
       "  ('natural language inference', 0.7912)],\n",
       " [('inference', 0.4619),\n",
       "  ('nli', 0.5206),\n",
       "  ('natural language', 0.5241),\n",
       "  ('entailment', 0.5557),\n",
       "  ('natural language inference', 0.6729)],\n",
       " [('comprehension', 0.4286),\n",
       "  ('neural networks', 0.4509),\n",
       "  ('machine reading', 0.5794),\n",
       "  ('reading comprehension', 0.5858),\n",
       "  ('machine reading comprehension', 0.6565)],\n",
       " [('simple', 0.2525), ('qa', 0.4243), ('neural qa', 0.7828)],\n",
       " [('entity', 0.2864),\n",
       "  ('entities', 0.2982),\n",
       "  ('correct entity', 0.3196),\n",
       "  ('query', 0.333),\n",
       "  ('natural language', 0.3721)],\n",
       " [('simple', 0.1104),\n",
       "  ('features', 0.2757),\n",
       "  ('text', 0.3789),\n",
       "  ('effective text matching', 0.8462)],\n",
       " [('recurrent', 0.4032),\n",
       "  ('knowledge', 0.4424),\n",
       "  ('neural networks', 0.448),\n",
       "  ('memory', 0.4489),\n",
       "  ('recurrent neural networks', 0.6617)],\n",
       " [('recurrent', 0.434),\n",
       "  ('neural networks', 0.4876),\n",
       "  ('term dependencies', 0.5125),\n",
       "  ('long term dependencies', 0.6773),\n",
       "  ('recurrent neural networks', 0.6921)],\n",
       " [('systems', 0.203),\n",
       "  ('dynamic integration', 0.2787),\n",
       "  ('nlu', 0.3725),\n",
       "  ('knowledge', 0.3933),\n",
       "  ('background knowledge', 0.5578)],\n",
       " [('background knowledge', 0.4508),\n",
       "  ('language understanding', 0.4793),\n",
       "  ('natural language understanding', 0.5182),\n",
       "  ('training corpora', 0.527),\n",
       "  ('most neural natural language understanding', 0.6364)],\n",
       " [('approach', 0.1767),\n",
       "  ('question', 0.1787),\n",
       "  ('discrete hard em approach', 0.493),\n",
       "  ('weakly supervised question', 0.6225)],\n",
       " [('questions', 0.2895),\n",
       "  ('challenge', 0.4338),\n",
       "  ('answer questions', 0.4357),\n",
       "  ('documents', 0.4648),\n",
       "  ('unsolved challenge', 0.569)],\n",
       " [('memory', 0.4051),\n",
       "  ('term memory', 0.5463),\n",
       "  ('machine reading', 0.6424),\n",
       "  ('memory networks', 0.6818),\n",
       "  ('long short term memory', 0.7115)],\n",
       " [('tasks', 0.2722),\n",
       "  ('language', 0.3105),\n",
       "  ('sentence', 0.3962),\n",
       "  ('natural language', 0.5882),\n",
       "  ('natural language sentence matching', 0.8042)],\n",
       " [('sentence', 0.3948),\n",
       "  ('sentences', 0.4944),\n",
       "  ('natural language', 0.5495),\n",
       "  ('nlsm', 0.5755),\n",
       "  ('natural language sentence matching', 0.7361)],\n",
       " [('sentences', 0.4496),\n",
       "  ('paraphrase', 0.5255),\n",
       "  ('nlsm', 0.534),\n",
       "  ('paraphrase identification', 0.6773),\n",
       "  ('paraphrase identification task', 0.7011)],\n",
       " [('simple', 0.2814),\n",
       "  ('networks', 0.3287),\n",
       "  ('large scale', 0.3582),\n",
       "  ('memory', 0.3935),\n",
       "  ('memory networks', 0.6154)],\n",
       " [('possible questions', 0.2332),\n",
       "  ('training', 0.3407),\n",
       "  ('questions', 0.3671),\n",
       "  ('large scale', 0.3709),\n",
       "  ('training sources', 0.496)],\n",
       " [('simple', 0.2682),\n",
       "  ('transfer', 0.2743),\n",
       "  ('reasoning', 0.3529),\n",
       "  ('learning', 0.3964),\n",
       "  ('multitask', 0.5793)],\n",
       " [('kb', 0.3443),\n",
       "  ('single fact', 0.3925),\n",
       "  ('multiple facts', 0.42),\n",
       "  ('reasoning', 0.4342),\n",
       "  ('higher reasoning capabilities', 0.5498)],\n",
       " [('comprehension', 0.4449),\n",
       "  ('machine reading', 0.5099),\n",
       "  ('reading comprehension', 0.5979),\n",
       "  ('machine reading comprehension', 0.7041),\n",
       "  ('passage machine reading comprehension', 0.7766)],\n",
       " [('mrc', 0.4502),\n",
       "  ('comprehension', 0.4507),\n",
       "  ('reading comprehension', 0.6214),\n",
       "  ('machine reading', 0.6251),\n",
       "  ('machine reading comprehension', 0.7363)],\n",
       " [('accuracy', 0.3508),\n",
       "  ('questions', 0.3775),\n",
       "  ('mrc', 0.441),\n",
       "  ('mrc models', 0.547),\n",
       "  ('long questions', 0.5522)],\n",
       " [('sentence', 0.2876),\n",
       "  ('representations', 0.4223),\n",
       "  ('dynamic meta', 0.4294),\n",
       "  ('embeddings', 0.518),\n",
       "  ('improved sentence representations', 0.7815)],\n",
       " [('task', 0.357),\n",
       "  ('supervised learning', 0.3979),\n",
       "  ('dynamic meta', 0.4116),\n",
       "  ('representations', 0.4302),\n",
       "  ('embeddings', 0.4907)],\n",
       " [('sequential tasks', 0.4702),\n",
       "  ('rnn', 0.4786),\n",
       "  ('unitary evolution matrices', 0.507),\n",
       "  ('associative memory', 0.5176),\n",
       "  ('recurrent neural networks', 0.6154)],\n",
       " [('limited capacity', 0.3483),\n",
       "  ('term memory', 0.3869),\n",
       "  ('memory', 0.447),\n",
       "  ('rnn', 0.5921)],\n",
       " [('multi', 0.2038),\n",
       "  ('hop question', 0.2583),\n",
       "  ('tasks', 0.2697),\n",
       "  ('generative multi', 0.4309),\n",
       "  ('commonsense', 0.4332)],\n",
       " [('comprehension', 0.3949),\n",
       "  ('qa', 0.441),\n",
       "  ('reading comprehension', 0.5405),\n",
       "  ('extractive qa', 0.6301),\n",
       "  ('comprehension qa tasks', 0.7013)],\n",
       " [('comprehension', 0.4733),\n",
       "  ('machine reading', 0.5408),\n",
       "  ('qa', 0.55),\n",
       "  ('reading comprehension', 0.6055),\n",
       "  ('machine reading comprehension', 0.7114)],\n",
       " [('evidence', 0.3502),\n",
       "  ('mrc', 0.3665),\n",
       "  ('reasoning', 0.3991),\n",
       "  ('qa', 0.4473),\n",
       "  ('babi dataset', 0.4993)],\n",
       " [('model', 0.242),\n",
       "  ('sentence', 0.3392),\n",
       "  ('fast unified model', 0.4378),\n",
       "  ('sentence understanding', 0.5336),\n",
       "  ('parsing', 0.6921)],\n",
       " [('information', 0.4116), ('attention', 0.5274)],\n",
       " [('artificial intelligence', 0.3545),\n",
       "  ('artificial intelligence community', 0.3937),\n",
       "  ('natural language', 0.4552),\n",
       "  ('queries', 0.4555),\n",
       "  ('qa', 0.5181)],\n",
       " [('language', 0.2929),\n",
       "  ('text', 0.4331),\n",
       "  ('natural language', 0.5161),\n",
       "  ('natural language processing', 0.6114),\n",
       "  ('unstructured text', 0.7666)],\n",
       " [('sentence', 0.3227),\n",
       "  ('nli', 0.3778),\n",
       "  ('embeddings', 0.5167),\n",
       "  ('sentence embeddings', 0.7103)],\n",
       " [('sentence', 0.4012),\n",
       "  ('representations', 0.4216),\n",
       "  ('level representations', 0.4954),\n",
       "  ('nlp', 0.5249),\n",
       "  ('various nlp tasks', 0.7298)],\n",
       " [('inference', 0.2987),\n",
       "  ('dataset', 0.3716),\n",
       "  ('commonsense', 0.4614),\n",
       "  ('scale adversarial dataset', 0.551),\n",
       "  ('grounded commonsense inference', 0.6857)],\n",
       " [('reasoning', 0.2969),\n",
       "  ('rc', 0.3425),\n",
       "  ('information retrieval', 0.4284),\n",
       "  ('comprehension', 0.5378),\n",
       "  ('reading comprehension', 0.72)],\n",
       " [('order', 0.3494),\n",
       "  ('language', 0.421),\n",
       "  ('images', 0.4418),\n",
       "  ('embeddings', 0.6926)],\n",
       " [('images', 0.3176),\n",
       "  ('sentences', 0.3982),\n",
       "  ('entailment', 0.4639),\n",
       "  ('textual entailment', 0.5276),\n",
       "  ('semantic hierarchy', 0.5337)],\n",
       " [('images', 0.3182),\n",
       "  ('language', 0.3315),\n",
       "  ('partial order', 0.488),\n",
       "  ('relations', 0.516),\n",
       "  ('visualsemantic hierarchy', 0.7188)],\n",
       " [('machine', 0.2857),\n",
       "  ('flow', 0.3387),\n",
       "  ('comprehension', 0.4451),\n",
       "  ('machine comprehension', 0.5615),\n",
       "  ('conversational machine comprehension', 0.7164)],\n",
       " [('machine', 0.2432),\n",
       "  ('comprehension', 0.4087),\n",
       "  ('dialogs', 0.5378),\n",
       "  ('machine comprehension', 0.5751),\n",
       "  ('conversational machine comprehension', 0.789)],\n",
       " [('domain', 0.256),\n",
       "  ('sentence', 0.2599),\n",
       "  ('shortcut', 0.3225),\n",
       "  ('inference', 0.3916),\n",
       "  ('sentence encoders', 0.5838)],\n",
       " [('encoder', 0.3417),\n",
       "  ('natural language', 0.4176),\n",
       "  ('inference', 0.4203),\n",
       "  ('simple sequential sentence encoder', 0.6222),\n",
       "  ('natural language inference', 0.6849)],\n",
       " [('networks', 0.435),\n",
       "  ('recurrent', 0.523),\n",
       "  ('recurrent relational networks', 1.0)],\n",
       " [('general purpose module', 0.3527),\n",
       "  ('graph', 0.4011),\n",
       "  ('recurrent', 0.4153),\n",
       "  ('graph representation', 0.5501),\n",
       "  ('recurrent relational network', 0.7806)],\n",
       " [('representations', 0.3769),\n",
       "  ('iclr', 0.4229),\n",
       "  ('sen', 0.437),\n",
       "  ('task learning', 0.4914),\n",
       "  ('tence representations', 0.5637)],\n",
       " [('unsupervised manner', 0.3203),\n",
       "  ('natural language', 0.3996),\n",
       "  ('nlp', 0.4549),\n",
       "  ('vector representations', 0.4894),\n",
       "  ('natural language processing', 0.5359)],\n",
       " [('sequences', 0.3501),\n",
       "  ('words', 0.3905),\n",
       "  ('learning', 0.4146),\n",
       "  ('representations', 0.4317),\n",
       "  ('sentences', 0.4791)],\n",
       " [('learning', 0.3326),\n",
       "  ('sentence', 0.3338),\n",
       "  ('general purpose', 0.3802),\n",
       "  ('representations', 0.4491),\n",
       "  ('purpose sentence representations', 0.7946)],\n",
       " [('question', 0.1437),\n",
       "  ('embeddings', 0.5253),\n",
       "  ('subgraph embeddings', 0.683)],\n",
       " [('mc', 0.3284),\n",
       "  ('texts', 0.345),\n",
       "  ('qa', 0.4451),\n",
       "  ('comprehension', 0.5147),\n",
       "  ('machine comprehension', 0.7003)],\n",
       " [('representations', 0.2882),\n",
       "  ('span', 0.3418),\n",
       "  ('recurrent', 0.361),\n",
       "  ('extractive question', 0.4377),\n",
       "  ('learning recurrent span representations', 0.6405)],\n",
       " [('spans', 0.3824),\n",
       "  ('recurrent', 0.3883),\n",
       "  ('evidence document', 0.3945),\n",
       "  ('recurrent network', 0.539),\n",
       "  ('answer extraction task', 0.6918)],\n",
       " [('story', 0.3096),\n",
       "  ('next', 0.3156),\n",
       "  ('comprehension', 0.4472),\n",
       "  ('story comprehension', 0.7379)],\n",
       " [('comprehension', 0.4141),\n",
       "  ('language understanding', 0.4195),\n",
       "  ('natural language understanding', 0.5028),\n",
       "  ('story comprehension', 0.6787),\n",
       "  ('automatic story comprehension', 0.781)],\n",
       " [('reasons', 0.1156),\n",
       "  ('task', 0.2108),\n",
       "  ('stories', 0.352),\n",
       "  ('challenging task', 0.3672),\n",
       "  ('computational linguists', 0.5882)],\n",
       " [('ability', 0.2306),\n",
       "  ('story', 0.2326),\n",
       "  ('task', 0.235),\n",
       "  ('language', 0.376),\n",
       "  ('language generation', 0.5974)],\n",
       " [('answer', 0.2255),\n",
       "  ('compare', 0.254),\n",
       "  ('aggregate model', 0.3473),\n",
       "  ('latent clustering', 0.4721),\n",
       "  ('answer selection', 0.7074)],\n",
       " [('task', 0.3086),\n",
       "  ('sentence', 0.3276),\n",
       "  ('natural language', 0.4406),\n",
       "  ('natural language processing', 0.5387),\n",
       "  ('answer selection', 0.7501)],\n",
       " [('question', 0.1617),\n",
       "  ('primary objective', 0.3022),\n",
       "  ('artificial intelligence', 0.4686),\n",
       "  ('automatic question', 0.626),\n",
       "  ('qa', 0.6269)],\n",
       " [('coarse', 0.2617),\n",
       "  ('evidence', 0.3545),\n",
       "  ('evidence question', 0.3583),\n",
       "  ('grain fine', 0.379),\n",
       "  ('grain coattention net', 0.5262)],\n",
       " [('single document', 0.2147),\n",
       "  ('document', 0.2221),\n",
       "  ('reasoning', 0.2579),\n",
       "  ('datasets', 0.2603),\n",
       "  ('neural question', 0.2958)],\n",
       " [('text', 0.366),\n",
       "  ('machines', 0.4476),\n",
       "  ('answer questions', 0.466),\n",
       "  ('artificial intelligence', 0.5321),\n",
       "  ('teaching machines', 0.6512)],\n",
       " [('reading comprehension', 0.5682),\n",
       "  ('language understanding', 0.6045),\n",
       "  ('machine reading comprehension', 0.6166),\n",
       "  ('many natural language understanding', 0.6217),\n",
       "  ('natural language understanding', 0.68)],\n",
       " [('mrc', 0.3406),\n",
       "  ('hypothesis', 0.4369),\n",
       "  ('language', 0.4467),\n",
       "  ('language understanding', 0.5924)],\n",
       " [('effective multi', 0.3269),\n",
       "  ('paragraph', 0.4178),\n",
       "  ('comprehension', 0.566),\n",
       "  ('reading comprehension', 0.77),\n",
       "  ('paragraph reading comprehension', 0.8348)],\n",
       " [('models', 0.2741),\n",
       "  ('documents', 0.2859),\n",
       "  ('paragraph', 0.3494),\n",
       "  ('entire documents', 0.3762),\n",
       "  ('neural paragraph', 0.5524)],\n",
       " [('key part', 0.2401),\n",
       "  ('solution', 0.2547),\n",
       "  ('questions', 0.3403),\n",
       "  ('models', 0.3708),\n",
       "  ('neural models', 0.5935)],\n",
       " [('simple', 0.2654),\n",
       "  ('simple web', 0.37),\n",
       "  ('parsing', 0.5836),\n",
       "  ('question answering model', 0.6176),\n",
       "  ('semantic parsing', 0.7053)],\n",
       " [('natural language', 0.3201),\n",
       "  ('natural language inference', 0.4051),\n",
       "  ('attention', 0.481),\n",
       "  ('machine translation', 0.4969),\n",
       "  ('attention mechanisms', 0.5606)],\n",
       " [('learning', 0.313),\n",
       "  ('sentence', 0.3436),\n",
       "  ('deep learning', 0.4503),\n",
       "  ('sentence selection', 0.6221),\n",
       "  ('answer sentence selection', 0.8022)],\n",
       " [('main tasks', 0.3426),\n",
       "  ('research', 0.3448),\n",
       "  ('research interest', 0.3602),\n",
       "  ('tasks', 0.3865),\n",
       "  ('qa', 0.5754)],\n",
       " [('reading comprehension', 0.4348),\n",
       "  ('machine reading', 0.492),\n",
       "  ('answer sentence candidates', 0.6014),\n",
       "  ('sentence selection', 0.6231),\n",
       "  ('answer sentence selection', 0.7514)],\n",
       " [('qa', 0.3312),\n",
       "  ('initial qa system', 0.3654),\n",
       "  ('search engine', 0.4044),\n",
       "  ('as2', 0.5904),\n",
       "  ('as2 model', 0.6107)],\n",
       " [('memory', 0.4186),\n",
       "  ('rnn', 0.4666),\n",
       "  ('rnns', 0.5319),\n",
       "  ('unitary rnns', 0.5617),\n",
       "  ('novel recurrent neural network', 0.6062)],\n",
       " [('lstms', 0.5465),\n",
       "  ('gating units', 0.5645),\n",
       "  ('gated recurrent units', 0.6163),\n",
       "  ('long short term memory', 0.6431),\n",
       "  ('recurrent neural networks', 0.6545)],\n",
       " [('units', 0.3582),\n",
       "  ('recurrent', 0.4042),\n",
       "  ('neural networks', 0.4842),\n",
       "  ('gating units', 0.5816),\n",
       "  ('recurrent neural networks', 0.6517)],\n",
       " [('gradients', 0.2278),\n",
       "  ('learning', 0.2531),\n",
       "  ('main advantage', 0.3042),\n",
       "  ('rnns', 0.5706),\n",
       "  ('conventional rnns', 0.6475)],\n",
       " [('question', 0.2173),\n",
       "  ('answer', 0.2636),\n",
       "  ('product', 0.3031),\n",
       "  ('commerce question', 0.3252),\n",
       "  ('aware answer generation', 0.6805)],\n",
       " [('explosive popularity', 0.2349),\n",
       "  ('popularity', 0.2486),\n",
       "  ('qa', 0.4942),\n",
       "  ('comprehension', 0.4961),\n",
       "  ('reading comprehension', 0.6413)],\n",
       " [('textual entailment', 0.5636),\n",
       "  ('reading comprehension', 0.692),\n",
       "  ('text comprehension', 0.7186),\n",
       "  ('machine reading comprehension', 0.7341),\n",
       "  ('core text comprehension', 0.7703)],\n",
       " [('multi', 0.225),\n",
       "  ('comprehension', 0.5449),\n",
       "  ('reading comprehension', 0.6947),\n",
       "  ('generative reading comprehension', 0.9232),\n",
       "  ('style generative reading comprehension', 0.9282)],\n",
       " [('comprehension', 0.4583),\n",
       "  ('language generation', 0.4604),\n",
       "  ('natural language generation', 0.5177),\n",
       "  ('reading comprehension', 0.5939),\n",
       "  ('generative reading comprehension', 0.7775)],\n",
       " [('model', 0.2863),\n",
       "  ('masque', 0.3011),\n",
       "  ('rc', 0.3326),\n",
       "  ('passage', 0.3801),\n",
       "  ('generative model', 0.504)],\n",
       " [('documents', 0.4113), ('representations', 0.4945), ('sentences', 0.4954)],\n",
       " [('pair', 0.283),\n",
       "  ('sentence', 0.3114),\n",
       "  ('interaction', 0.3677),\n",
       "  ('lstms', 0.5139),\n",
       "  ('sentence pair', 0.5595)],\n",
       " [('networks', 0.273),\n",
       "  ('neural networks', 0.3865),\n",
       "  ('interactions', 0.4132),\n",
       "  ('deep neural networks', 0.4185),\n",
       "  ('sentences', 0.4583)],\n",
       " [('text', 0.3523),\n",
       "  ('relevance', 0.3576),\n",
       "  ('similarity', 0.4391),\n",
       "  ('sentence pair', 0.5302),\n",
       "  ('semantic matching', 0.6778)],\n",
       " [('datasets', 0.3795),\n",
       "  ('critical ai capability', 0.4509),\n",
       "  ('commonsense', 0.5904),\n",
       "  ('test commonsense', 0.666),\n",
       "  ('commonsense reasoning', 0.7214)],\n",
       " [('reasoning', 0.3169),\n",
       "  ('datasets', 0.4765),\n",
       "  ('large datasets', 0.5067),\n",
       "  ('commonsense', 0.5142),\n",
       "  ('commonsense reasoning', 0.6625)],\n",
       " [('swag', 0.3375),\n",
       "  ('multiple choice sentence completion', 0.4347),\n",
       "  ('commonsense question', 0.51),\n",
       "  ('commonsense', 0.5296),\n",
       "  ('commonsense dataset adversarially', 0.6498)],\n",
       " [('comprehension', 0.3826),\n",
       "  ('reader', 0.4113),\n",
       "  ('dynamic chunk reader', 0.5459),\n",
       "  ('reading comprehension', 0.5614),\n",
       "  ('neural reading comprehension', 0.6429)],\n",
       " [('text', 0.3463),\n",
       "  ('related document', 0.3465),\n",
       "  ('comprehension', 0.4917),\n",
       "  ('rcqa', 0.5615),\n",
       "  ('reading comprehension', 0.6091)],\n",
       " [('questions', 0.3428),\n",
       "  ('entities', 0.3453),\n",
       "  ('world qa scenario', 0.4154),\n",
       "  ('rcqa', 0.4282),\n",
       "  ('qa', 0.4357)],\n",
       " [('multi', 0.1452),\n",
       "  ('documents', 0.2749),\n",
       "  ('datasets', 0.2759),\n",
       "  ('comprehension', 0.4574),\n",
       "  ('reading comprehension', 0.6507)],\n",
       " [('question', 0.2112),\n",
       "  ('multiple', 0.3262),\n",
       "  ('facts', 0.3888),\n",
       "  ('reasoning', 0.5487),\n",
       "  ('multiple facts', 0.5851)],\n",
       " [('co', 0.1112),\n",
       "  ('information', 0.2988),\n",
       "  ('sentence', 0.3329),\n",
       "  ('recurrent', 0.3984),\n",
       "  ('semantic sentence matching', 0.6938)],\n",
       " [('paraphrase', 0.4003),\n",
       "  ('natural language', 0.4626),\n",
       "  ('paraphrase identification', 0.5413),\n",
       "  ('natural language inference', 0.6208),\n",
       "  ('various natural language tasks', 0.6307)],\n",
       " [('language model', 0.5682),\n",
       "  ('machine reading comprehension', 0.5696),\n",
       "  ('natural language inference tasks', 0.6246),\n",
       "  ('language model training', 0.6263),\n",
       "  ('language representations', 0.6711)],\n",
       " [('language understanding', 0.4981),\n",
       "  ('language representations', 0.5162),\n",
       "  ('natural language understanding', 0.5178),\n",
       "  ('universal language representations', 0.6701),\n",
       "  ('deep contextual language model', 0.697)],\n",
       " [('multi', 0.2142),\n",
       "  ('reasoning', 0.2889),\n",
       "  ('graph', 0.3732),\n",
       "  ('dynamically fused graph network', 0.7357)],\n",
       " [('question', 0.1204),\n",
       "  ('recent years', 0.1517),\n",
       "  ('text', 0.3237),\n",
       "  ('tbqa', 0.4588)],\n",
       " [('natural language', 0.3745),\n",
       "  ('qa', 0.4242),\n",
       "  ('news qa', 0.4635),\n",
       "  ('comprehension', 0.5241),\n",
       "  ('reading comprehension', 0.6288)],\n",
       " [('question', 0.1679),\n",
       "  ('models', 0.2485),\n",
       "  ('open', 0.2878),\n",
       "  ('weakly supervised embedding models', 0.6675)],\n",
       " [('domain', 0.3513),\n",
       "  ('questions', 0.3561),\n",
       "  ('domain question', 0.3667),\n",
       "  ('building systems', 0.3969),\n",
       "  ('answer questions', 0.4402)],\n",
       " [('representations', 0.3963),\n",
       "  ('language understanding', 0.4269),\n",
       "  ('natural language', 0.4484),\n",
       "  ('natural language understanding', 0.4649),\n",
       "  ('rare words', 0.4869)],\n",
       " [('word', 0.3011),\n",
       "  ('learning', 0.3359),\n",
       "  ('embeddings', 0.6183),\n",
       "  ('word embeddings', 0.7953),\n",
       "  ('compute word embeddings', 0.8812)],\n",
       " [('directional self', 0.3771),\n",
       "  ('language understanding', 0.4259),\n",
       "  ('attention', 0.4309),\n",
       "  ('rnn', 0.4715),\n",
       "  ('attention network', 0.6111)],\n",
       " [('style question', 0.3599),\n",
       "  ('natural language processing', 0.3782),\n",
       "  ('natural language', 0.4189),\n",
       "  ('comprehension', 0.4607),\n",
       "  ('machine comprehension', 0.6616)],\n",
       " [('text', 0.4047),\n",
       "  ('natural language', 0.5108),\n",
       "  ('natural language processing', 0.5461),\n",
       "  ('comprehension', 0.5658),\n",
       "  ('machine comprehension', 0.773)],\n",
       " [('text', 0.356),\n",
       "  ('inference', 0.4183),\n",
       "  ('text processing phil blunsom', 0.6002),\n",
       "  ('neural variational inference', 0.7273)],\n",
       " [('neural question', 0.3076),\n",
       "  ('learning', 0.3089),\n",
       "  ('efficient neural question', 0.4742),\n",
       "  ('representation learning', 0.4835),\n",
       "  ('hyperbolic representation learning', 0.7027)],\n",
       " [('deep neural networks', 0.3317),\n",
       "  ('word', 0.3433),\n",
       "  ('similarity', 0.4636),\n",
       "  ('semantic similarity measurement', 0.6331),\n",
       "  ('pairwise word interaction modeling', 0.7154)],\n",
       " [('sentences', 0.3831),\n",
       "  ('semantics', 0.4182),\n",
       "  ('input sentences', 0.462),\n",
       "  ('similarity', 0.5566),\n",
       "  ('textual similarity measurement', 0.8416)],\n",
       " [('language research', 0.4329),\n",
       "  ('many language processing tasks', 0.4351),\n",
       "  ('similarity', 0.4568),\n",
       "  ('paraphrase generation', 0.5615),\n",
       "  ('semantic textual similarity', 0.744)],\n",
       " [('handcrafted features', 0.4178),\n",
       "  ('few handcrafted features', 0.4234),\n",
       "  ('topics', 0.4353),\n",
       "  ('answer questions', 0.5042),\n",
       "  ('knowledge base', 0.5066)],\n",
       " [('machines', 0.3692),\n",
       "  ('answer questions', 0.4486),\n",
       "  ('natural language', 0.4849),\n",
       "  ('artificial intelligence', 0.4901),\n",
       "  ('teaching machines', 0.5562)],\n",
       " [('query', 0.3518),\n",
       "  ('natural language', 0.4307),\n",
       "  ('open qa', 0.4481),\n",
       "  ('such databases', 0.487),\n",
       "  ('knowledge bases', 0.5455)],\n",
       " [('qa', 0.3571),\n",
       "  ('structured format', 0.3621),\n",
       "  ('kbs', 0.453),\n",
       "  ('open qa', 0.4629),\n",
       "  ('freebase', 0.5128)],\n",
       " [('global self', 0.3026),\n",
       "  ('convolution', 0.4243),\n",
       "  ('attention', 0.4787),\n",
       "  ('reading compre', 0.4824),\n",
       "  ('local convolution', 0.5417)],\n",
       " [('neural networks', 0.4192),\n",
       "  ('rnns', 0.4648),\n",
       "  ('machine reading', 0.5302),\n",
       "  ('end machine reading', 0.5451),\n",
       "  ('recurrent neural networks', 0.5695)],\n",
       " [('tasks', 0.3447),\n",
       "  ('comprehension', 0.5004),\n",
       "  ('machine reading', 0.5921),\n",
       "  ('reading comprehension', 0.6227),\n",
       "  ('machine reading comprehension', 0.7633)],\n",
       " [('self', 0.2866),\n",
       "  ('networks', 0.3076),\n",
       "  ('matching networks', 0.3766),\n",
       "  ('comprehension', 0.4614),\n",
       "  ('reading comprehension', 0.6245)],\n",
       " [('questions', 0.3437),\n",
       "  ('answer questions', 0.3797),\n",
       "  ('comprehension', 0.4338),\n",
       "  ('comprehension style question', 0.5376),\n",
       "  ('reading comprehension', 0.5727)],\n",
       " [('sequence', 0.301),\n",
       "  ('denoising sequence', 0.3189),\n",
       "  ('natural language', 0.3578),\n",
       "  ('language generation', 0.5514),\n",
       "  ('natural language generation', 0.6035)],\n",
       " [('bart', 0.168),\n",
       "  ('models', 0.3266),\n",
       "  ('denoising', 0.3311),\n",
       "  ('sequence', 0.4097),\n",
       "  ('sequence models', 0.573)],\n",
       " [('question', 0.1748),\n",
       "  ('answer', 0.2245),\n",
       "  ('distant supervision', 0.4593),\n",
       "  ('answer justification', 0.6379)],\n",
       " [('ml', 0.3899),\n",
       "  ('learning', 0.3978),\n",
       "  ('model', 0.4149),\n",
       "  ('models', 0.4947),\n",
       "  ('interpretable machine learning', 0.7637)],\n",
       " [('conference paper', 0.363),\n",
       "  ('words', 0.3674),\n",
       "  ('iclr', 0.4647),\n",
       "  ('comprehension', 0.4775),\n",
       "  ('reading comprehension', 0.6413)],\n",
       " [('transfer', 0.2826),\n",
       "  ('shot cross', 0.3225),\n",
       "  ('embeddings', 0.419),\n",
       "  ('lingual transfer', 0.546),\n",
       "  ('sentence embeddings', 0.5561)],\n",
       " [('sentence', 0.245),\n",
       "  ('different scripts', 0.3265),\n",
       "  ('representations', 0.3353),\n",
       "  ('languages', 0.4577),\n",
       "  ('joint multilingual sentence representations', 0.8126)],\n",
       " [('recurrent', 0.4516),\n",
       "  ('summarization', 0.4971),\n",
       "  ('text summarization', 0.5426),\n",
       "  ('abstractive text summarization', 0.7013),\n",
       "  ('deep recurrent generative decoder', 0.7148)],\n",
       " [('pointergenerator style models', 0.42),\n",
       "  ('summarization', 0.4941),\n",
       "  ('abstractive summarization', 0.6551),\n",
       "  ('neural abstractive summarization', 0.8103),\n",
       "  ('neural abstractive summarization models', 0.8433)],\n",
       " [('reader', 0.3205),\n",
       "  ('better summary', 0.4531),\n",
       "  ('summary', 0.4599),\n",
       "  ('reader comments', 0.4999),\n",
       "  ('aware abstractive summary generation', 0.8502)],\n",
       " [('summarization', 0.5159),\n",
       "  ('entailment generation', 0.5182),\n",
       "  ('question generation', 0.5482),\n",
       "  ('summarization model', 0.5769),\n",
       "  ('abstractive summarization', 0.5823)],\n",
       " [('document', 0.2591),\n",
       "  ('models', 0.2722),\n",
       "  ('attention', 0.4693),\n",
       "  ('summarization', 0.5759),\n",
       "  ('fine attention models', 0.7163)],\n",
       " [('entailment', 0.3431),\n",
       "  ('task', 0.3544),\n",
       "  ('summarization', 0.4532),\n",
       "  ('question generation', 0.4928),\n",
       "  ('task summarization', 0.687)],\n",
       " [('relevant auxiliary tasks', 0.4188),\n",
       "  ('task learning', 0.4387),\n",
       "  ('summarization', 0.4913),\n",
       "  ('text summarization', 0.5397),\n",
       "  ('abstractive text summarization', 0.6542)],\n",
       " [('summarization', 0.6696), ('abstractive summarization', 0.8713)],\n",
       " [('natural language', 0.4668),\n",
       "  ('longer text', 0.4825),\n",
       "  ('summarization', 0.6726),\n",
       "  ('natural language summaries', 0.7071),\n",
       "  ('text summarization', 0.7788)],\n",
       " [('content', 0.2965),\n",
       "  ('sequence', 0.36),\n",
       "  ('mixture content selection', 0.6337),\n",
       "  ('sequence generation', 0.6595),\n",
       "  ('diverse sequence generation', 0.8424)],\n",
       " [('target sequences', 0.4678),\n",
       "  ('summarization', 0.4703),\n",
       "  ('many nlp applications', 0.5403),\n",
       "  ('diverse sequences', 0.5734),\n",
       "  ('question generation', 0.6079)],\n",
       " [('sequence', 0.3662),\n",
       "  ('sequences', 0.4227),\n",
       "  ('nlp', 0.5274),\n",
       "  ('source sequence', 0.6002),\n",
       "  ('target sequences', 0.6618)],\n",
       " [('sequence generation', 0.521),\n",
       "  ('machine translation', 0.5307),\n",
       "  ('human translators', 0.548),\n",
       "  ('decoder models', 0.5531),\n",
       "  ('encoder', 0.5563)],\n",
       " [('recurrent', 0.4489),\n",
       "  ('summarization', 0.5431),\n",
       "  ('recurrent neural networks', 0.5782),\n",
       "  ('attentive recurrent neural networks', 0.6281),\n",
       "  ('abstractive sentence summarization', 0.7992)],\n",
       " [('sentence', 0.4539),\n",
       "  ('summary', 0.4767),\n",
       "  ('source sentence', 0.4926),\n",
       "  ('summarization', 0.7167),\n",
       "  ('sentence summarization task', 0.8501)],\n",
       " [('promising results', 0.1639),\n",
       "  ('learning', 0.2553),\n",
       "  ('seq2seq', 0.5114),\n",
       "  ('summarization', 0.5692),\n",
       "  ('seq2seq learning', 0.6639)],\n",
       " [('cutting', 0.0919),\n",
       "  ('generations', 0.2544),\n",
       "  ('summarization', 0.4875),\n",
       "  ('abstractive summarization', 0.6408),\n",
       "  ('neural abstractive summarization', 0.8106)],\n",
       " [('abstractive summarization', 0.4516),\n",
       "  ('language generation', 0.4655),\n",
       "  ('machine translation', 0.481),\n",
       "  ('various natural language generation', 0.5324),\n",
       "  ('natural language generation', 0.5514)],\n",
       " [('retrieve', 0.2288),\n",
       "  ('rewrite', 0.27),\n",
       "  ('rerank', 0.4786),\n",
       "  ('summarization', 0.5417),\n",
       "  ('soft template based neural summarization', 0.8562)],\n",
       " [('intriguing task', 0.3741),\n",
       "  ('shorter version', 0.3788),\n",
       "  ('sentence', 0.4333),\n",
       "  ('summarization', 0.6308),\n",
       "  ('abstractive sentence summarization', 0.8485)],\n",
       " [('variants', 0.1592),\n",
       "  ('sequence', 0.4053),\n",
       "  ('seq2seq', 0.4107),\n",
       "  ('abstractive summarization', 0.6059),\n",
       "  ('summarization', 0.6273)],\n",
       " [('text', 0.4291),\n",
       "  ('passage', 0.4393),\n",
       "  ('condensed version', 0.4716),\n",
       "  ('summarization', 0.6413),\n",
       "  ('text summarization', 0.7278)],\n",
       " [('text', 0.3238),\n",
       "  ('summary', 0.3968),\n",
       "  ('original text document', 0.4359),\n",
       "  ('summarization', 0.6718),\n",
       "  ('automatic summarization', 0.787)],\n",
       " [('context', 0.256),\n",
       "  ('cascade', 0.2866),\n",
       "  ('online social media discussions', 0.4374),\n",
       "  ('sarcasm detection', 0.6814),\n",
       "  ('contextual sarcasm detector', 0.8013)],\n",
       " [('cascade', 0.2992),\n",
       "  ('online discussion forums', 0.4197),\n",
       "  ('sarcasm detection', 0.712),\n",
       "  ('contextual sarcasm detection', 0.8602)],\n",
       " [('level', 0.0703),\n",
       "  ('level analysis', 0.1457),\n",
       "  ('literature', 0.2219),\n",
       "  ('text', 0.2297),\n",
       "  ('sarcasm detection', 0.7491)],\n",
       " [('arguments', 0.3432),\n",
       "  ('predicates', 0.4577),\n",
       "  ('semantic role labeling', 0.7401),\n",
       "  ('neural semantic role labeling', 0.8305)],\n",
       " [('relations', 0.3354),\n",
       "  ('srl', 0.4018),\n",
       "  ('predicateargument relations', 0.5033),\n",
       "  ('semantic role labeling', 0.7222)],\n",
       " [('task', 0.1709),\n",
       "  ('sentence', 0.2748),\n",
       "  ('argument structure', 0.3964),\n",
       "  ('srl', 0.4211)],\n",
       " [('goal', 0.1505),\n",
       "  ('task', 0.2244),\n",
       "  ('parsing', 0.3951),\n",
       "  ('semantic parsing', 0.531),\n",
       "  ('semantic role labeling', 0.7889)],\n",
       " [('language understanding', 0.4281),\n",
       "  ('natural language', 0.4872),\n",
       "  ('natural language understanding', 0.5379),\n",
       "  ('relation extraction', 0.6656),\n",
       "  ('semantic role labeling', 0.703)],\n",
       " [('self', 0.344),\n",
       "  ('attention', 0.4684),\n",
       "  ('semantic role labeling', 0.7276),\n",
       "  ('deep semantic role', 0.7399)],\n",
       " [('language understanding', 0.4387),\n",
       "  ('srl', 0.459),\n",
       "  ('natural language', 0.5182),\n",
       "  ('natural language understanding', 0.5318),\n",
       "  ('semantic role labeling', 0.8046)],\n",
       " [('language', 0.2739),\n",
       "  ('questions', 0.4944),\n",
       "  ('natural language', 0.5423),\n",
       "  ('natural language questions', 0.7589)],\n",
       " [('texts', 0.371),\n",
       "  ('sieve', 0.3749),\n",
       "  ('english texts', 0.3962),\n",
       "  ('relation extraction', 0.5395),\n",
       "  ('causal relation extraction', 0.698)],\n",
       " [('relation', 0.3586),\n",
       "  ('temporal relation', 0.5022),\n",
       "  ('structured learning approach', 0.543),\n",
       "  ('relation extraction', 0.7097),\n",
       "  ('temporal relation extraction', 0.8707)],\n",
       " [('events', 0.5077),\n",
       "  ('language understanding', 0.5651),\n",
       "  ('natural language', 0.5959),\n",
       "  ('temporal relations', 0.5999),\n",
       "  ('natural language understanding', 0.6716)],\n",
       " [('time expression', 0.4202),\n",
       "  ('fundamental tasks', 0.4664),\n",
       "  ('timex', 0.4891),\n",
       "  ('temporal relation', 0.5807),\n",
       "  ('temporal processing', 0.7315)],\n",
       " [('image', 0.2813),\n",
       "  ('phrase', 0.2844),\n",
       "  ('common semantic space', 0.5447),\n",
       "  ('phrase grounding', 0.6605),\n",
       "  ('level multimodal common semantic space', 0.765)],\n",
       " [('learning', 0.3095),\n",
       "  ('phrase', 0.3212),\n",
       "  ('visual modalities', 0.4464),\n",
       "  ('common semantic space', 0.5867),\n",
       "  ('phrase grounding', 0.6693)],\n",
       " [('extraction', 0.3311),\n",
       "  ('relations', 0.41),\n",
       "  ('entity', 0.4309),\n",
       "  ('joint extraction', 0.4523),\n",
       "  ('entity mentions', 0.6388)],\n",
       " [('relations', 0.3178),\n",
       "  ('entities', 0.4295),\n",
       "  ('nlp', 0.4693),\n",
       "  ('structured prediction', 0.6095),\n",
       "  ('structured prediction tasks', 0.6746)],\n",
       " [('extraction', 0.3307),\n",
       "  ('entity', 0.3712),\n",
       "  ('entity mention', 0.5574),\n",
       "  ('sentencelevel', 0.5844),\n",
       "  ('relation extraction', 0.7095)],\n",
       " [('learning', 0.2721),\n",
       "  ('similarity', 0.4271),\n",
       "  ('relation', 0.4424),\n",
       "  ('distributional similarity', 0.5498),\n",
       "  ('relation learning', 0.7885)],\n",
       " [('text', 0.3099),\n",
       "  ('relations', 0.4656),\n",
       "  ('entities', 0.4742),\n",
       "  ('natural language', 0.5195),\n",
       "  ('natural language processing', 0.6505)],\n",
       " [('entities', 0.3911),\n",
       "  ('extraction', 0.3944),\n",
       "  ('target entities', 0.4213),\n",
       "  ('relation', 0.4633),\n",
       "  ('relation extraction', 0.7947)],\n",
       " [('dependency', 0.2734),\n",
       "  ('graph', 0.2801),\n",
       "  ('graph convolution', 0.4557),\n",
       "  ('relation', 0.4655),\n",
       "  ('relation extraction', 0.6958)],\n",
       " [('extraction', 0.3541),\n",
       "  ('entity', 0.3827),\n",
       "  ('relation', 0.4393),\n",
       "  ('semantic relationships', 0.577),\n",
       "  ('relation extraction', 0.773)],\n",
       " [('multiple pairs', 0.3386),\n",
       "  ('relations', 0.3892),\n",
       "  ('mre', 0.3932),\n",
       "  ('entity mentions', 0.4756),\n",
       "  ('multiplerelations extraction', 0.6436)],\n",
       " [('ability', 0.0772),\n",
       "  ('documents', 0.3291),\n",
       "  ('facts', 0.3696),\n",
       "  ('knowledge', 0.3977),\n",
       "  ('knowledge bases', 0.5843)],\n",
       " [('language understanding', 0.5212),\n",
       "  ('natural language', 0.5772),\n",
       "  ('relational facts', 0.5805),\n",
       "  ('knowledge base', 0.663),\n",
       "  ('natural language understanding', 0.6716)],\n",
       " [('information', 0.2406),\n",
       "  ('side information', 0.3563),\n",
       "  ('relation', 0.3817),\n",
       "  ('relation extraction', 0.6165),\n",
       "  ('neural relation extraction', 0.7397)],\n",
       " [('relation', 0.4516),\n",
       "  ('knowledge base', 0.487),\n",
       "  ('unstructured text', 0.4976),\n",
       "  ('relation instances', 0.509),\n",
       "  ('relation extraction', 0.7918)],\n",
       " [('classification', 0.2883),\n",
       "  ('attention', 0.3262),\n",
       "  ('cnns', 0.3864),\n",
       "  ('relation', 0.5189),\n",
       "  ('relation classification', 0.7543)],\n",
       " [('extraction', 0.2465),\n",
       "  ('sentence noise reduction', 0.4342),\n",
       "  ('relation', 0.4717),\n",
       "  ('relation extraction', 0.6805),\n",
       "  ('neural relation extraction', 0.8628)],\n",
       " [('raw texts', 0.4278),\n",
       "  ('marked entities', 0.4499),\n",
       "  ('relation', 0.4704),\n",
       "  ('relations', 0.5228),\n",
       "  ('relation extraction', 0.8267)],\n",
       " [('previous studies', 0.1962),\n",
       "  ('extraction', 0.2606),\n",
       "  ('relation', 0.4284),\n",
       "  ('relation extraction', 0.6523),\n",
       "  ('distant supervised relation extraction', 0.8358)],\n",
       " [('one', 0.1545),\n",
       "  ('multiple', 0.2498),\n",
       "  ('pass', 0.2515),\n",
       "  ('transformers', 0.4294),\n",
       "  ('relations', 0.4474)],\n",
       " [('relations', 0.33),\n",
       "  ('paragraph', 0.3307),\n",
       "  ('entity', 0.4571),\n",
       "  ('input paragraph', 0.4616),\n",
       "  ('multiple entity', 0.5167)],\n",
       " [('multiple', 0.2024),\n",
       "  ('extraction', 0.265),\n",
       "  ('corpus', 0.3907),\n",
       "  ('input corpus', 0.415),\n",
       "  ('multiple entityrelations extraction task', 0.7914)],\n",
       " [('entity', 0.3713),\n",
       "  ('relation', 0.4477),\n",
       "  ('entity mentions', 0.5497),\n",
       "  ('semantic relation', 0.5824),\n",
       "  ('relation extraction', 0.7224)],\n",
       " [('effective solution', 0.2561),\n",
       "  ('applications', 0.2582),\n",
       "  ('entities', 0.307),\n",
       "  ('input paragraphs', 0.4309),\n",
       "  ('mre', 0.5149)],\n",
       " [('extraction', 0.2689),\n",
       "  ('convolutional neural networks', 0.3383),\n",
       "  ('relation', 0.4259),\n",
       "  ('distant supervision', 0.4773),\n",
       "  ('relation extraction', 0.6547)],\n",
       " [('relation', 0.3697),\n",
       "  ('aware representations', 0.4102),\n",
       "  ('knowledge base', 0.5688),\n",
       "  ('relation extraction', 0.7127),\n",
       "  ('knowledge base relation extraction', 0.8362)],\n",
       " [('relations', 0.4682),\n",
       "  ('other relations', 0.4903),\n",
       "  ('target relation', 0.5089),\n",
       "  ('level relation extraction', 0.6503),\n",
       "  ('relation extraction', 0.7055)],\n",
       " [('target entity pair', 0.5215),\n",
       "  ('target relation', 0.5674),\n",
       "  ('relation instance', 0.5798),\n",
       "  ('relation extraction', 0.7127),\n",
       "  ('sentential relation extraction task', 0.8255)]]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "research_problem_model.extract_keywords(docs=train_docs, vectorizer=KeyphraseCountVectorizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ce8b07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python385jvsc74a57bd0cc0b39b73e6949057e82e0fccf6b8b6674bf387641e811617d69795976e90112"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
