{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f82f5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display \n",
    "#The above line turns of irrelevant warnings the were being reported\n",
    "import pandas as pd\n",
    "from keyphrase_vectorizers import KeyphraseCountVectorizer\n",
    "from keybert import KeyBERT\n",
    "from keyphrase_vectorizers import KeyphraseCountVectorizer\n",
    "from helpers import get_preprocessed_data, get_predicted_keyPhrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b7be57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preprocessing\n",
    "#Both the training and test data were cloned into\n",
    "#separate local repositories as training-data and test-data respectively\n",
    "\n",
    "training_data_path = \"../../ncg_task_repo/training-data/*/*/info-units/research-problem.json\"\n",
    "test_data_path = \"../../ncg_task_repo/test-data/*/*/info-units/research-problem.json\"\n",
    "\n",
    "#Create a dict of all the the research problem sentence and respective phrase\n",
    "research_keyPhrase_and_sentence_dict, json_cnts = get_preprocessed_data(training_data_path)\n",
    "\n",
    "test_keyPhrase_and_sentence_dict, test_json_cnts = get_preprocessed_data(test_data_path)\n",
    "\n",
    "train_docs = list(research_keyPhrase_and_sentence_dict.values())\n",
    "\n",
    "train_labels = list(research_keyPhrase_and_sentence_dict.keys())\n",
    "\n",
    "test_docs = list(test_keyPhrase_and_sentence_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21fb4af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init default vectorizer.\n",
    "vectorizer = KeyphraseCountVectorizer()\n",
    "# print(vectorizer.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecb59824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "document_keyphrase_matrix = vectorizer.fit_transform(train_docs).toarray()\n",
    "print(document_keyphrase_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cd39ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyphrases = vectorizer.get_feature_names_out()\n",
    "# print(keyphrases[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "510cceed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init KeyBERT\n",
    "research_problem_model = KeyBERT()\n",
    "# research_problem_model.extract_keywords(docs=train_docs, keyphrase_ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b628593",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display \n",
    "#The above line turns of irrelevant warnings the were being reported\n",
    "\n",
    "keyPhrases = research_problem_model.extract_keywords(docs=train_docs, vectorizer=KeyphraseCountVectorizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "52503776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['facial expression recognition',\n",
       " 'SPEECH EMOTION RECOGNITION',\n",
       " 'Aspect - based Sentiment Analysis',\n",
       " 'aspect extraction']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display four selected train_labels for comparison with their respective predicted phrases\n",
    "train_labels[13:17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9db39ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('convolutional neural networks', 0.5207),\n",
       "  ('deep convolutional neural networks', 0.5593),\n",
       "  ('facial expression recognition', 0.5752),\n",
       "  ('particular smile recognition', 0.6246),\n",
       "  ('smile recognition', 0.6651)],\n",
       " [('audio', 0.3506),\n",
       "  ('emotion', 0.4025),\n",
       "  ('emotion recognition', 0.5697),\n",
       "  ('speech emotion recognition', 0.7241),\n",
       "  ('multimodal speech emotion recognition', 0.9263)],\n",
       " [('rotatory attention', 0.3804),\n",
       "  ('sentiment analysis', 0.4562),\n",
       "  ('based sentiment analysis', 0.4631),\n",
       "  ('right separated neural network', 0.526),\n",
       "  ('aspect based sentiment analysis', 0.6401)],\n",
       " [('based sentiment analysis', 0.5066),\n",
       "  ('sentiment classification', 0.5439),\n",
       "  ('aspect extraction', 0.6875),\n",
       "  ('aspect based sentiment analysis', 0.7675),\n",
       "  ('aspect sentiment classification', 0.7971)]]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display four predicted phrases for comparison with their respective labels above \n",
    "keyPhrases[13:17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474c58e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "95b67d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedDict = {}\n",
    "cols = train_labels[13:17]\n",
    "for indx,list_ in enumerate(keyPhrases[13:17]):\n",
    "    predictedDict[cols[indx]]=list_  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ed4e6cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe of all selected possible predicted keyphrases\n",
    "#and their actual values (labels) as column names\n",
    "DF_selected_possible_predictions =pd.DataFrame(predictedDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fcf4eb57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>facial expression recognition</th>\n",
       "      <th>SPEECH EMOTION RECOGNITION</th>\n",
       "      <th>Aspect - based Sentiment Analysis</th>\n",
       "      <th>aspect extraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(convolutional neural networks, 0.5207)</td>\n",
       "      <td>(audio, 0.3506)</td>\n",
       "      <td>(rotatory attention, 0.3804)</td>\n",
       "      <td>(based sentiment analysis, 0.5066)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(deep convolutional neural networks, 0.5593)</td>\n",
       "      <td>(emotion, 0.4025)</td>\n",
       "      <td>(sentiment analysis, 0.4562)</td>\n",
       "      <td>(sentiment classification, 0.5439)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(facial expression recognition, 0.5752)</td>\n",
       "      <td>(emotion recognition, 0.5697)</td>\n",
       "      <td>(based sentiment analysis, 0.4631)</td>\n",
       "      <td>(aspect extraction, 0.6875)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(particular smile recognition, 0.6246)</td>\n",
       "      <td>(speech emotion recognition, 0.7241)</td>\n",
       "      <td>(right separated neural network, 0.526)</td>\n",
       "      <td>(aspect based sentiment analysis, 0.7675)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(smile recognition, 0.6651)</td>\n",
       "      <td>(multimodal speech emotion recognition, 0.9263)</td>\n",
       "      <td>(aspect based sentiment analysis, 0.6401)</td>\n",
       "      <td>(aspect sentiment classification, 0.7971)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  facial expression recognition  \\\n",
       "0       (convolutional neural networks, 0.5207)   \n",
       "1  (deep convolutional neural networks, 0.5593)   \n",
       "2       (facial expression recognition, 0.5752)   \n",
       "3        (particular smile recognition, 0.6246)   \n",
       "4                   (smile recognition, 0.6651)   \n",
       "\n",
       "                        SPEECH EMOTION RECOGNITION  \\\n",
       "0                                  (audio, 0.3506)   \n",
       "1                                (emotion, 0.4025)   \n",
       "2                    (emotion recognition, 0.5697)   \n",
       "3             (speech emotion recognition, 0.7241)   \n",
       "4  (multimodal speech emotion recognition, 0.9263)   \n",
       "\n",
       "           Aspect - based Sentiment Analysis  \\\n",
       "0               (rotatory attention, 0.3804)   \n",
       "1               (sentiment analysis, 0.4562)   \n",
       "2         (based sentiment analysis, 0.4631)   \n",
       "3    (right separated neural network, 0.526)   \n",
       "4  (aspect based sentiment analysis, 0.6401)   \n",
       "\n",
       "                           aspect extraction  \n",
       "0         (based sentiment analysis, 0.5066)  \n",
       "1         (sentiment classification, 0.5439)  \n",
       "2                (aspect extraction, 0.6875)  \n",
       "3  (aspect based sentiment analysis, 0.7675)  \n",
       "4  (aspect sentiment classification, 0.7971)  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_selected_possible_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e7e17cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "higherCosineS_keyPhrases = get_predicted_keyPhrases(keyPhrases)\n",
    "actual_predicted_df = \\\n",
    "pd.DataFrame(zip(higherCosineS_keyPhrases,train_labels),\n",
    "             columns=[\"Predicted phrase\",\"Actual phrase\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6b0b5fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted phrase</th>\n",
       "      <th>Actual phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>smile recognition</td>\n",
       "      <td>Smile Recognition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>smile recognition</td>\n",
       "      <td>facial expression recognition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>multimodal speech emotion recognition</td>\n",
       "      <td>SPEECH EMOTION RECOGNITION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>aspect based sentiment analysis</td>\n",
       "      <td>Aspect - based Sentiment Analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>aspect sentiment classification</td>\n",
       "      <td>aspect extraction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>attentive rnn</td>\n",
       "      <td>Emotion Detection in Conversations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sentiment classification</td>\n",
       "      <td>Fine - grained Sentiment Classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sentiment classification</td>\n",
       "      <td>Sentiment classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>interactive conversational memory network</td>\n",
       "      <td>Multimodal Emotion Detection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>empathetic machines</td>\n",
       "      <td>Emotion recognition in conversations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>emotional dynamics</td>\n",
       "      <td>Analyzing emotional dynamics in conversations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>modal attention</td>\n",
       "      <td>Multi-modal Sentiment Analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>aspect level sentiment classification</td>\n",
       "      <td>sentiment analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>aspect level sentiment classification</td>\n",
       "      <td>Aspect Level Sentiment Classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sentiment classification</td>\n",
       "      <td>sentiment classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>aspect level sentiment classification identifi...</td>\n",
       "      <td>general sentiment classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>recurrent attention network</td>\n",
       "      <td>Aspect Sentiment Analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>dyadic dialogue videos</td>\n",
       "      <td>Emotion Recognition in Dyadic Dialogue Videos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>dyadic conversations</td>\n",
       "      <td>emotion detection in videos of dyadic conversa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Predicted phrase  \\\n",
       "12                                  smile recognition   \n",
       "13                                  smile recognition   \n",
       "14              multimodal speech emotion recognition   \n",
       "15                    aspect based sentiment analysis   \n",
       "16                    aspect sentiment classification   \n",
       "17                                      attentive rnn   \n",
       "18                           sentiment classification   \n",
       "19                           sentiment classification   \n",
       "20          interactive conversational memory network   \n",
       "21                                empathetic machines   \n",
       "22                                 emotional dynamics   \n",
       "23                                    modal attention   \n",
       "24              aspect level sentiment classification   \n",
       "25              aspect level sentiment classification   \n",
       "26                           sentiment classification   \n",
       "27  aspect level sentiment classification identifi...   \n",
       "28                        recurrent attention network   \n",
       "29                             dyadic dialogue videos   \n",
       "30                               dyadic conversations   \n",
       "\n",
       "                                        Actual phrase  \n",
       "12                                  Smile Recognition  \n",
       "13                      facial expression recognition  \n",
       "14                         SPEECH EMOTION RECOGNITION  \n",
       "15                  Aspect - based Sentiment Analysis  \n",
       "16                                  aspect extraction  \n",
       "17                 Emotion Detection in Conversations  \n",
       "18            Fine - grained Sentiment Classification  \n",
       "19                           Sentiment classification  \n",
       "20                       Multimodal Emotion Detection  \n",
       "21               Emotion recognition in conversations  \n",
       "22      Analyzing emotional dynamics in conversations  \n",
       "23                     Multi-modal Sentiment Analysis  \n",
       "24                                 sentiment analysis  \n",
       "25              Aspect Level Sentiment Classification  \n",
       "26                           sentiment classification  \n",
       "27                   general sentiment classification  \n",
       "28                          Aspect Sentiment Analysis  \n",
       "29      Emotion Recognition in Dyadic Dialogue Videos  \n",
       "30  emotion detection in videos of dyadic conversa...  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display 19 selected predicted phrases and their coresponding actual phrases\n",
    "actual_predicted_df[12:31].head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83309038",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ded85ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['topic identification',\n",
       " 'document embeddings',\n",
       " 'smile recognition',\n",
       " 'smile recognition',\n",
       " 'multimodal speech emotion recognition',\n",
       " 'aspect based sentiment analysis',\n",
       " 'aspect sentiment classification',\n",
       " 'attentive rnn',\n",
       " 'sentiment classification',\n",
       " 'sentiment classification']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the predicted keyPhrases between 10 and 20\n",
    "higherCosineS_keyPhrases[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4036e451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['topic identification',\n",
       " 'L EARNING word and document embeddings',\n",
       " 'Smile Recognition',\n",
       " 'facial expression recognition',\n",
       " 'SPEECH EMOTION RECOGNITION',\n",
       " 'Aspect - based Sentiment Analysis',\n",
       " 'aspect extraction',\n",
       " 'Emotion Detection in Conversations',\n",
       " 'Fine - grained Sentiment Classification',\n",
       " 'Sentiment classification']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Actual key phrases between 10 and 20\n",
    "train_labels[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7b0b2345",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'REFERENCE:\\n\\nhttps://towardsdatascience.com/enhancing-keybert-keyword-extraction-results-with-keyphrasevectorizers-3796fa93f4db\\n\\nhttps://github.com/MaartenGr/KeyBERT#embeddings\\n\\n'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"REFERENCE:\n",
    "\n",
    "https://towardsdatascience.com/enhancing-keybert-keyword-extraction-results-with-keyphrasevectorizers-3796fa93f4db\n",
    "\n",
    "https://github.com/MaartenGr/KeyBERT#embeddings\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b8628c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python385jvsc74a57bd0cc0b39b73e6949057e82e0fccf6b8b6674bf387641e811617d69795976e90112"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
