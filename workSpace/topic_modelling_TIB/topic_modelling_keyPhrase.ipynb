{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f82f5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display \n",
    "#The above line turns of irrelevant warnings the were being reported\n",
    "import pandas as pd\n",
    "from keyphrase_vectorizers import KeyphraseCountVectorizer\n",
    "from keybert import KeyBERT\n",
    "from keyphrase_vectorizers import KeyphraseCountVectorizer\n",
    "from helpers import get_preprocessed_data, get_predicted_keyPhrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b7be57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preprocessing\n",
    "#Both the training and test data were cloned into\n",
    "#separate local repositories as training-data and test-data respectively\n",
    "\n",
    "training_data_path = \"../../ncg_task_repo/training-data/*/*/info-units/research-problem.json\"\n",
    "test_data_path = \"../../ncg_task_repo/test-data/*/*/info-units/research-problem.json\"\n",
    "\n",
    "#Create a dict of all the the research problem sentence and respective phrase\n",
    "research_keyPhrase_and_sentence_dict, json_cnts = get_preprocessed_data(training_data_path)\n",
    "\n",
    "test_keyPhrase_and_sentence_dict, test_json_cnts = get_preprocessed_data(test_data_path)\n",
    "\n",
    "train_docs = list(research_keyPhrase_and_sentence_dict.values())\n",
    "\n",
    "train_labels = list(research_keyPhrase_and_sentence_dict.keys())\n",
    "\n",
    "test_docs = list(test_keyPhrase_and_sentence_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21fb4af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init default vectorizer.\n",
    "vectorizer = KeyphraseCountVectorizer()\n",
    "# print(vectorizer.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecb59824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "document_keyphrase_matrix = vectorizer.fit_transform(train_docs).toarray()\n",
    "print(document_keyphrase_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cd39ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyphrases = vectorizer.get_feature_names_out()\n",
    "# print(keyphrases[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "510cceed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init KeyBERT\n",
    "research_problem_model = KeyBERT()\n",
    "# research_problem_model.extract_keywords(docs=train_docs, keyphrase_ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b628593",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display \n",
    "#The above line turns of irrelevant warnings the were being reported\n",
    "\n",
    "keyPhrases = research_problem_model.extract_keywords(docs=train_docs, vectorizer=KeyphraseCountVectorizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed4e6cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('classifier', 0.3268),\n",
       "  ('embeddings', 0.4373),\n",
       "  ('generative gaussian linear classifier', 0.5455),\n",
       "  ('document embeddings', 0.5737),\n",
       "  ('topic identification', 0.6279)],\n",
       " [('natural language processing', 0.4006),\n",
       "  ('natural language processing applications', 0.4133),\n",
       "  ('information retrieval', 0.4739),\n",
       "  ('embeddings', 0.5086),\n",
       "  ('document embeddings', 0.5796)],\n",
       " [('learning', 0.259),\n",
       "  ('deep learning', 0.4853),\n",
       "  ('smile recognition', 0.767)]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyPhrases[10:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31e496e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['topic identification',\n",
       " 'L EARNING word and document embeddings',\n",
       " 'Smile Recognition']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[10:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d98e6fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "higherCosineS_keyPhrases = get_predicted_keyPhrases(keyPhrases)\n",
    "actual_predicted_df = \\\n",
    "pd.DataFrame(zip(train_labels,higherCosineS_keyPhrases),\n",
    "             columns=[\"Actual phrase\",\"Predicted phrase\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3222bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual phrase</th>\n",
       "      <th>Predicted phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grapheme - to - Phoneme Conversion</td>\n",
       "      <td>grapheme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Grapheme - to - phoneme ( G2P ) conversion</td>\n",
       "      <td>grapheme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Text to Speech</td>\n",
       "      <td>controllable text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neural network based end - to - end text to sp...</td>\n",
       "      <td>end text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Text to speech ( TTS )</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Neural network based TTS</td>\n",
       "      <td>speech quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Text - To - Speech Synthesis</td>\n",
       "      <td>speaker verification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>text - to - speech ( TTS ) synthesis</td>\n",
       "      <td>speech audio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>build a TTS system</td>\n",
       "      <td>tts system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Learning document embeddings</td>\n",
       "      <td>document embeddings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>topic identification</td>\n",
       "      <td>topic identification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>L EARNING word and document embeddings</td>\n",
       "      <td>document embeddings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Smile Recognition</td>\n",
       "      <td>smile recognition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>facial expression recognition</td>\n",
       "      <td>smile recognition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SPEECH EMOTION RECOGNITION</td>\n",
       "      <td>multimodal speech emotion recognition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Aspect - based Sentiment Analysis</td>\n",
       "      <td>aspect based sentiment analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>aspect extraction</td>\n",
       "      <td>aspect sentiment classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Emotion Detection in Conversations</td>\n",
       "      <td>attentive rnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Fine - grained Sentiment Classification</td>\n",
       "      <td>sentiment classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sentiment classification</td>\n",
       "      <td>sentiment classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Multimodal Emotion Detection</td>\n",
       "      <td>interactive conversational memory network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Emotion recognition in conversations</td>\n",
       "      <td>empathetic machines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Analyzing emotional dynamics in conversations</td>\n",
       "      <td>emotional dynamics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Multi-modal Sentiment Analysis</td>\n",
       "      <td>modal attention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sentiment analysis</td>\n",
       "      <td>aspect level sentiment classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Aspect Level Sentiment Classification</td>\n",
       "      <td>aspect level sentiment classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sentiment classification</td>\n",
       "      <td>sentiment classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>general sentiment classification</td>\n",
       "      <td>aspect level sentiment classification identifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Aspect Sentiment Analysis</td>\n",
       "      <td>recurrent attention network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Emotion Recognition in Dyadic Dialogue Videos</td>\n",
       "      <td>dyadic dialogue videos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Actual phrase  \\\n",
       "0                  Grapheme - to - Phoneme Conversion   \n",
       "1          Grapheme - to - phoneme ( G2P ) conversion   \n",
       "2                                      Text to Speech   \n",
       "3   Neural network based end - to - end text to sp...   \n",
       "4                              Text to speech ( TTS )   \n",
       "5                            Neural network based TTS   \n",
       "6                        Text - To - Speech Synthesis   \n",
       "7                text - to - speech ( TTS ) synthesis   \n",
       "8                                  build a TTS system   \n",
       "9                        Learning document embeddings   \n",
       "10                               topic identification   \n",
       "11             L EARNING word and document embeddings   \n",
       "12                                  Smile Recognition   \n",
       "13                      facial expression recognition   \n",
       "14                         SPEECH EMOTION RECOGNITION   \n",
       "15                  Aspect - based Sentiment Analysis   \n",
       "16                                  aspect extraction   \n",
       "17                 Emotion Detection in Conversations   \n",
       "18            Fine - grained Sentiment Classification   \n",
       "19                           Sentiment classification   \n",
       "20                       Multimodal Emotion Detection   \n",
       "21               Emotion recognition in conversations   \n",
       "22      Analyzing emotional dynamics in conversations   \n",
       "23                     Multi-modal Sentiment Analysis   \n",
       "24                                 sentiment analysis   \n",
       "25              Aspect Level Sentiment Classification   \n",
       "26                           sentiment classification   \n",
       "27                   general sentiment classification   \n",
       "28                          Aspect Sentiment Analysis   \n",
       "29      Emotion Recognition in Dyadic Dialogue Videos   \n",
       "\n",
       "                                     Predicted phrase  \n",
       "0                                            grapheme  \n",
       "1                                            grapheme  \n",
       "2                                   controllable text  \n",
       "3                                            end text  \n",
       "4                                                text  \n",
       "5                                      speech quality  \n",
       "6                                speaker verification  \n",
       "7                                        speech audio  \n",
       "8                                          tts system  \n",
       "9                                 document embeddings  \n",
       "10                               topic identification  \n",
       "11                                document embeddings  \n",
       "12                                  smile recognition  \n",
       "13                                  smile recognition  \n",
       "14              multimodal speech emotion recognition  \n",
       "15                    aspect based sentiment analysis  \n",
       "16                    aspect sentiment classification  \n",
       "17                                      attentive rnn  \n",
       "18                           sentiment classification  \n",
       "19                           sentiment classification  \n",
       "20          interactive conversational memory network  \n",
       "21                                empathetic machines  \n",
       "22                                 emotional dynamics  \n",
       "23                                    modal attention  \n",
       "24              aspect level sentiment classification  \n",
       "25              aspect level sentiment classification  \n",
       "26                           sentiment classification  \n",
       "27  aspect level sentiment classification identifi...  \n",
       "28                        recurrent attention network  \n",
       "29                             dyadic dialogue videos  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_predicted_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989dfda9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c10ece1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['topic identification',\n",
       " 'document embeddings',\n",
       " 'smile recognition',\n",
       " 'smile recognition',\n",
       " 'multimodal speech emotion recognition',\n",
       " 'aspect based sentiment analysis',\n",
       " 'aspect sentiment classification',\n",
       " 'attentive rnn',\n",
       " 'sentiment classification',\n",
       " 'sentiment classification']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the predicted keyPhrases between 10 and 20\n",
    "higherCosineS_keyPhrases[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d094986d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['topic identification',\n",
       " 'L EARNING word and document embeddings',\n",
       " 'Smile Recognition',\n",
       " 'facial expression recognition',\n",
       " 'SPEECH EMOTION RECOGNITION',\n",
       " 'Aspect - based Sentiment Analysis',\n",
       " 'aspect extraction',\n",
       " 'Emotion Detection in Conversations',\n",
       " 'Fine - grained Sentiment Classification',\n",
       " 'Sentiment classification']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "824ba24a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'REFERENCE:\\n\\nhttps://towardsdatascience.com/enhancing-keybert-keyword-extraction-results-with-keyphrasevectorizers-3796fa93f4db\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"REFERENCE:\n",
    "\n",
    "https://towardsdatascience.com/enhancing-keybert-keyword-extraction-results-with-keyphrasevectorizers-3796fa93f4db\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc23f6c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python385jvsc74a57bd0cc0b39b73e6949057e82e0fccf6b8b6674bf387641e811617d69795976e90112"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
