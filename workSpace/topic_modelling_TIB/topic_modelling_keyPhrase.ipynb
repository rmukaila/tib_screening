{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f82f5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emotionless/.local/lib/python3.8/site-packages/packaging/requirements.py:66: UserWarning: warn_ungrouped_named_tokens_in_collection: setting results name 'specifier' on And expression collides with '_original_end' on contained expression\n",
      "  VERSION_SPEC = originalTextFor(_VERSION_SPEC)(\"specifier\")\n",
      "/home/emotionless/.local/lib/python3.8/site-packages/packaging/requirements.py:69: UserWarning: warn_ungrouped_named_tokens_in_collection: setting results name 'marker' on And expression collides with '_original_end' on contained expression\n",
      "  MARKER_EXPR = originalTextFor(MARKER_EXPR())(\"marker\")\n"
     ]
    }
   ],
   "source": [
    "from keyphrase_vectorizers import KeyphraseCountVectorizer\n",
    "from keybert import KeyBERT\n",
    "from keyphrase_vectorizers import KeyphraseCountVectorizer\n",
    "from helpers import get_preprocessed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b7be57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preprocessing\n",
    "#Both the training and test data were cloned into\n",
    "#separate local repositories as training-data and test-data respectively\n",
    "\n",
    "training_data_path = \"../../ncg_task_repo/training-data/*/*/info-units/research-problem.json\"\n",
    "test_data_path = \"../../ncg_task_repo/test-data/*/*/info-units/research-problem.json\"\n",
    "\n",
    "#Create a dict of all the the research problem sentence and respective phrase\n",
    "research_keyPhrase_and_sentence_dict, json_cnts = get_preprocessed_data(training_data_path)\n",
    "test_keyPhrase_and_sentence_dict, test_json_cnts = get_preprocessed_data(test_data_path)\n",
    "train_docs = list(research_keyPhrase_and_sentence_dict.values())\n",
    "test_docs = list(test_keyPhrase_and_sentence_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21fb4af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init default vectorizer.\n",
    "vectorizer = KeyphraseCountVectorizer()\n",
    "# print(vectorizer.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecb59824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# After initializing the vectorizer, it can be fitted\n",
    "# to learn the keyphrases from the text documents.\n",
    "# Afterwards, the vectorizer can transform the documents \n",
    "# to a document-keyphrase matrix.\n",
    "# Matrix rows indicate the documents and columns indicate the unique keyphrases.\n",
    "# Each cell represents the count.\n",
    "\n",
    "document_keyphrase_matrix = vectorizer.fit_transform(train_docs).toarray()\n",
    "print(document_keyphrase_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cd39ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyphrases = vectorizer.get_feature_names_out()\n",
    "# print(keyphrases[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "510cceed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init KeyBERT\n",
    "research_problem_model = KeyBERT()\n",
    "# research_problem_model.extract_keywords(docs=train_docs, keyphrase_ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b628593",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emotionless/.local/lib/python3.8/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n",
      "  warnings.warn(\n",
      "429it [00:00, 544.20it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[('token', 0.2733),\n",
       "  ('conversion', 0.2934),\n",
       "  ('phoneme', 0.3567),\n",
       "  ('level ensemble distillation', 0.5382),\n",
       "  ('grapheme', 0.5524)],\n",
       " [('g2p', 0.4203),\n",
       "  ('phoneme', 0.4532),\n",
       "  ('automatic speech recognition', 0.4773),\n",
       "  ('speech systems', 0.4931),\n",
       "  ('grapheme', 0.5763)],\n",
       " [('fast', 0.1955),\n",
       "  ('speech', 0.4257),\n",
       "  ('text', 0.4416),\n",
       "  ('fastspeech', 0.4749),\n",
       "  ('controllable text', 0.5102)],\n",
       " [('speech', 0.2757),\n",
       "  ('tts', 0.2999),\n",
       "  ('text', 0.3136),\n",
       "  ('neural network', 0.3609),\n",
       "  ('end text', 0.3925)],\n",
       " [('attention', 0.3121),\n",
       "  ('deep learning', 0.4098),\n",
       "  ('speech', 0.4179),\n",
       "  ('tts', 0.4337),\n",
       "  ('text', 0.4501)],\n",
       " [('statistical parametric approaches', 0.2192),\n",
       "  ('speech', 0.245),\n",
       "  ('neural network', 0.3255),\n",
       "  ('tts', 0.4535),\n",
       "  ('speech quality', 0.5495)],\n",
       " [('synthesis', 0.3477),\n",
       "  ('speaker', 0.4316),\n",
       "  ('multispeaker text', 0.5284),\n",
       "  ('speech synthesis', 0.6071),\n",
       "  ('speaker verification', 0.6545)],\n",
       " [('neural network', 0.3687),\n",
       "  ('audio', 0.4286),\n",
       "  ('synthesis', 0.4294),\n",
       "  ('voice', 0.4567),\n",
       "  ('speech audio', 0.6025)],\n",
       " [('speakers', 0.3115),\n",
       "  ('speech', 0.4022),\n",
       "  ('tts', 0.4744),\n",
       "  ('natural speech', 0.551),\n",
       "  ('tts system', 0.5821)],\n",
       " [('learning', 0.341),\n",
       "  ('document', 0.3633),\n",
       "  ('uncertainties', 0.3933),\n",
       "  ('embeddings', 0.6725),\n",
       "  ('document embeddings', 0.7504)],\n",
       " [('classifier', 0.3268),\n",
       "  ('embeddings', 0.4373),\n",
       "  ('generative gaussian linear classifier', 0.5455),\n",
       "  ('document embeddings', 0.5737),\n",
       "  ('topic identification', 0.6279)],\n",
       " [('natural language processing', 0.4006),\n",
       "  ('natural language processing applications', 0.4133),\n",
       "  ('information retrieval', 0.4739),\n",
       "  ('embeddings', 0.5086),\n",
       "  ('document embeddings', 0.5796)],\n",
       " [('learning', 0.259),\n",
       "  ('deep learning', 0.4853),\n",
       "  ('smile recognition', 0.767)],\n",
       " [('convolutional neural networks', 0.5207),\n",
       "  ('deep convolutional neural networks', 0.5593),\n",
       "  ('facial expression recognition', 0.5752),\n",
       "  ('particular smile recognition', 0.6246),\n",
       "  ('smile recognition', 0.6651)],\n",
       " [('audio', 0.3506),\n",
       "  ('emotion', 0.4025),\n",
       "  ('emotion recognition', 0.5697),\n",
       "  ('speech emotion recognition', 0.7241),\n",
       "  ('multimodal speech emotion recognition', 0.9263)],\n",
       " [('rotatory attention', 0.3804),\n",
       "  ('sentiment analysis', 0.4562),\n",
       "  ('based sentiment analysis', 0.4631),\n",
       "  ('right separated neural network', 0.526),\n",
       "  ('aspect based sentiment analysis', 0.6401)],\n",
       " [('based sentiment analysis', 0.5066),\n",
       "  ('sentiment classification', 0.5439),\n",
       "  ('aspect extraction', 0.6875),\n",
       "  ('aspect based sentiment analysis', 0.7675),\n",
       "  ('aspect sentiment classification', 0.7971)],\n",
       " [('emotion', 0.3847),\n",
       "  ('conversations', 0.4045),\n",
       "  ('rnn', 0.434),\n",
       "  ('emotion detection', 0.519),\n",
       "  ('attentive rnn', 0.5849)],\n",
       " [('classification', 0.3434),\n",
       "  ('bert', 0.4373),\n",
       "  ('sentiment', 0.4949),\n",
       "  ('sentiment classification', 0.6776)],\n",
       " [('topic', 0.2723),\n",
       "  ('service', 0.2773),\n",
       "  ('classification', 0.4997),\n",
       "  ('sentiment', 0.5611),\n",
       "  ('sentiment classification', 0.7783)],\n",
       " [('icon', 0.3015),\n",
       "  ('memory', 0.3234),\n",
       "  ('emotion', 0.4039),\n",
       "  ('emotion detection', 0.5441),\n",
       "  ('interactive conversational memory network', 0.6798)],\n",
       " [('machines', 0.2708),\n",
       "  ('conversations', 0.4016),\n",
       "  ('emotion', 0.4718),\n",
       "  ('emotion recognition', 0.6142),\n",
       "  ('empathetic machines', 0.7046)],\n",
       " [('complex', 0.2946),\n",
       "  ('complex challenges', 0.3961),\n",
       "  ('conversations', 0.6032),\n",
       "  ('emotional dynamics', 0.7226)],\n",
       " [('multi', 0.2917),\n",
       "  ('attention', 0.3596),\n",
       "  ('sentiment', 0.362),\n",
       "  ('sentiment analysis', 0.4383),\n",
       "  ('modal attention', 0.6077)],\n",
       " [('aspect', 0.4985),\n",
       "  ('sentiment analysis', 0.5804),\n",
       "  ('sentiment classification', 0.6651),\n",
       "  ('level sentiment classification', 0.6811),\n",
       "  ('aspect level sentiment classification', 0.8749)],\n",
       " [('sentiment', 0.4138),\n",
       "  ('attention neural networks', 0.5217),\n",
       "  ('sentiment classification', 0.6115),\n",
       "  ('level sentiment classification', 0.6616),\n",
       "  ('aspect level sentiment classification', 0.8179)],\n",
       " [('classification', 0.4748),\n",
       "  ('long movie reviews', 0.4819),\n",
       "  ('document classification tasks', 0.6518),\n",
       "  ('binary sentiment classification', 0.6751),\n",
       "  ('sentiment classification', 0.6807)],\n",
       " [('general sentiment classification', 0.6417),\n",
       "  ('sentiment classification', 0.6505),\n",
       "  ('level sentiment classification', 0.6738),\n",
       "  ('aspect level sentiment classification', 0.8618),\n",
       "  ('aspect level sentiment classification identifies opinions', 0.902)],\n",
       " [('attention', 0.381),\n",
       "  ('recurrent', 0.3962),\n",
       "  ('sentiment analysis', 0.4719),\n",
       "  ('attention network', 0.5281),\n",
       "  ('recurrent attention network', 0.633)],\n",
       " [('memory', 0.2711),\n",
       "  ('videos', 0.2761),\n",
       "  ('emotion', 0.3244),\n",
       "  ('emotion recognition', 0.4723),\n",
       "  ('dyadic dialogue videos', 0.6571)],\n",
       " [('videos', 0.3011),\n",
       "  ('emotion', 0.3769),\n",
       "  ('conversations', 0.4169),\n",
       "  ('emotion detection', 0.5714),\n",
       "  ('dyadic conversations', 0.5859)],\n",
       " [('emotion', 0.4222),\n",
       "  ('chatbots', 0.4427),\n",
       "  ('opinion mining', 0.4547),\n",
       "  ('public opinion mining', 0.4841),\n",
       "  ('emotion detection', 0.6363)],\n",
       " [('aspect', 0.3943),\n",
       "  ('sensitive memory networks', 0.4537),\n",
       "  ('memory networks', 0.4728),\n",
       "  ('sentiment classification', 0.5751),\n",
       "  ('aspect sentiment classification', 0.7504)],\n",
       " [('classification', 0.4181),\n",
       "  ('aspect', 0.4773),\n",
       "  ('sentiment analysis', 0.5243),\n",
       "  ('sentiment classification', 0.6113),\n",
       "  ('aspect sentiment classification', 0.8146)],\n",
       " [('attention', 0.404),\n",
       "  ('asc', 0.4329),\n",
       "  ('major drawback', 0.4495),\n",
       "  ('attention mechanism', 0.519)],\n",
       " [('aspect term', 0.4199),\n",
       "  ('sentiment', 0.4317),\n",
       "  ('variational semi', 0.4593),\n",
       "  ('sentiment analysis', 0.5451),\n",
       "  ('term sentiment analysis', 0.5707)],\n",
       " [('aspect', 0.4946),\n",
       "  ('absa', 0.51),\n",
       "  ('category sentiment analysis', 0.5225),\n",
       "  ('aspect term', 0.5598),\n",
       "  ('aspect based sentiment analysis', 0.7191)],\n",
       " [('polarity', 0.3384),\n",
       "  ('categories', 0.4039),\n",
       "  ('sentiment', 0.4394),\n",
       "  ('sentiment polarity', 0.4934),\n",
       "  ('acsa', 0.5559)],\n",
       " [('single word', 0.2968),\n",
       "  ('sentiment', 0.3323),\n",
       "  ('text', 0.3603),\n",
       "  ('sentiment polarity', 0.3668),\n",
       "  ('atsa', 0.5187)],\n",
       " [('emotion', 0.3212),\n",
       "  ('eeg', 0.3345),\n",
       "  ('graph', 0.3401),\n",
       "  ('emotion recognition', 0.4977),\n",
       "  ('based emotion recognition', 0.5223)],\n",
       " [('body language', 0.2978),\n",
       "  ('physiological signals', 0.3544),\n",
       "  ('emotions', 0.4639),\n",
       "  ('human emotions', 0.506),\n",
       "  ('affective computing', 0.6078)],\n",
       " [('classification', 0.2295),\n",
       "  ('sentiment', 0.3513),\n",
       "  ('encoder', 0.3995),\n",
       "  ('sentiment classification', 0.5058),\n",
       "  ('attentional encoder network', 0.7372)],\n",
       " [('sentiment', 0.4394),\n",
       "  ('sentiment analysis', 0.5491),\n",
       "  ('sentiment classification', 0.5885),\n",
       "  ('level sentiment classification', 0.6241),\n",
       "  ('aspect level sentiment classification', 0.7904)],\n",
       " [('infancy', 0.3782),\n",
       "  ('neural network models', 0.399),\n",
       "  ('sentiment', 0.4148),\n",
       "  ('sentiment classification task', 0.5366),\n",
       "  ('sentiment classification', 0.5502)],\n",
       " [('attention', 0.3402),\n",
       "  ('sentiment', 0.3616),\n",
       "  ('sentiment analysis', 0.4448),\n",
       "  ('lstm', 0.5457),\n",
       "  ('deep lstm', 0.5924)],\n",
       " [('semeval', 0.3363),\n",
       "  ('deep learning', 0.3834),\n",
       "  ('twitter', 0.4454),\n",
       "  ('sentiment', 0.4653),\n",
       "  ('sentiment analysis', 0.5018)],\n",
       " [('nlp', 0.436),\n",
       "  ('sarcasm detection', 0.4371),\n",
       "  ('sentiment', 0.4948),\n",
       "  ('aspect extraction', 0.5161),\n",
       "  ('sentiment analysis', 0.6758)],\n",
       " [('aspect', 0.4045),\n",
       "  ('based sentiment analysis', 0.5174),\n",
       "  ('sentiment analysis', 0.5204),\n",
       "  ('gated convolutional networks', 0.5613),\n",
       "  ('aspect based sentiment analysis', 0.704)],\n",
       " [('absa', 0.5067),\n",
       "  ('general sentiment analysis', 0.5417),\n",
       "  ('based sentiment analysis', 0.5477),\n",
       "  ('sentiment analysis', 0.5907),\n",
       "  ('aspect based sentiment analysis', 0.7643)],\n",
       " [('sentiment analysis', 0.5066),\n",
       "  ('aspect', 0.5254),\n",
       "  ('term sentiment analysis', 0.5514),\n",
       "  ('aspect term', 0.5607),\n",
       "  ('category sentiment analysis', 0.6156)],\n",
       " [('phrases', 0.4399),\n",
       "  ('classifier', 0.4478),\n",
       "  ('sentiment', 0.4639),\n",
       "  ('aspects', 0.5047),\n",
       "  ('absa classifier', 0.5673)],\n",
       " [('attention', 0.4265),\n",
       "  ('sentiment classification', 0.5725),\n",
       "  ('level sentiment classification', 0.5953),\n",
       "  ('effective attention modeling', 0.6156),\n",
       "  ('aspect level sentiment classification', 0.7854)],\n",
       " [('aspect', 0.3588),\n",
       "  ('attention', 0.3678),\n",
       "  ('sentiment analysis', 0.4366),\n",
       "  ('level sentiment analysis', 0.4779),\n",
       "  ('attention learning', 0.4976)],\n",
       " [('attention mechanisms', 0.4504),\n",
       "  ('dominant neural models', 0.4919),\n",
       "  ('sentiment classification', 0.5247),\n",
       "  ('level sentiment classification', 0.5666),\n",
       "  ('aspect level sentiment classification', 0.6891)],\n",
       " [('attention mechanisms', 0.4607),\n",
       "  ('attention', 0.4853),\n",
       "  ('neural asc models', 0.542),\n",
       "  ('attention learning', 0.6074),\n",
       "  ('useful attention supervision information', 0.6316)],\n",
       " [('aspects', 0.5335),\n",
       "  ('aspect term', 0.5897),\n",
       "  ('general aspect category', 0.6022),\n",
       "  ('specific aspect term', 0.6116),\n",
       "  ('aspect level sentiment classification', 0.7022)],\n",
       " [('networks', 0.3628),\n",
       "  ('recurrent', 0.4267),\n",
       "  ('neural networks', 0.5258),\n",
       "  ('convolutional neural networks', 0.7185),\n",
       "  ('recurrent neural filters', 0.7901)],\n",
       " [('convolution', 0.3171),\n",
       "  ('language', 0.3434),\n",
       "  ('long term dependencies', 0.3818),\n",
       "  ('compositionality', 0.3905),\n",
       "  ('rnns', 0.4928)],\n",
       " [('structured long short', 0.4437),\n",
       "  ('memory networks', 0.5727),\n",
       "  ('term memory', 0.5791),\n",
       "  ('semantic representations', 0.6362),\n",
       "  ('long short term memory', 0.7251)],\n",
       " [('lstms', 0.4803),\n",
       "  ('lstm', 0.5269),\n",
       "  ('strong lstm baselines', 0.5717),\n",
       "  ('sentiment treebank', 0.5848),\n",
       "  ('stanford sentiment treebank', 0.6119)],\n",
       " [('attention', 0.3861),\n",
       "  ('sentiment analysis', 0.4519),\n",
       "  ('level sentiment analysis', 0.5142),\n",
       "  ('attention network', 0.5554),\n",
       "  ('aware bidirectional attention network', 0.6395)],\n",
       " [('networks', 0.2131),\n",
       "  ('neural networks', 0.2852),\n",
       "  ('emotion', 0.3868),\n",
       "  ('emotion recognition', 0.5964),\n",
       "  ('modal emotion recognition on iemocap', 0.9245)],\n",
       " [('emotion', 0.5267),\n",
       "  ('sentiment', 0.5441),\n",
       "  ('emotion recognition', 0.5679),\n",
       "  ('positive sentiment', 0.6121),\n",
       "  ('negative sentiment', 0.6305)],\n",
       " [('emotion', 0.3361),\n",
       "  ('eeg', 0.4698),\n",
       "  ('emotion recognition', 0.4762),\n",
       "  ('hemispheric discrepancy model', 0.5624),\n",
       "  ('eeg emotion recognition', 0.7329)],\n",
       " [('eeg', 0.4467),\n",
       "  ('hemispheres', 0.4467),\n",
       "  ('hemispheric discrepancy model', 0.5408),\n",
       "  ('electroencephalograph', 0.5695),\n",
       "  ('eeg emotion recognition', 0.6236)],\n",
       " [('pattern recognition research communities', 0.389),\n",
       "  ('emotion', 0.4303),\n",
       "  ('emotions', 0.4538),\n",
       "  ('human emotions', 0.5722),\n",
       "  ('emotion recognition', 0.6131)],\n",
       " [('modeling', 0.1529),\n",
       "  ('sentence', 0.298),\n",
       "  ('convolution', 0.2984),\n",
       "  ('tree', 0.4406),\n",
       "  ('discriminative neural sentence modeling', 0.7494)],\n",
       " [('aspect', 0.4453),\n",
       "  ('bert', 0.4543),\n",
       "  ('based sentiment analysis', 0.4645),\n",
       "  ('sentiment analysis', 0.4945),\n",
       "  ('aspect based sentiment analysis', 0.6911)],\n",
       " [('absa', 0.4777),\n",
       "  ('aspect', 0.4813),\n",
       "  ('based sentiment analysis', 0.5557),\n",
       "  ('sentiment analysis', 0.6031),\n",
       "  ('aspect based sentiment analysis', 0.7809)],\n",
       " [('attention', 0.3564),\n",
       "  ('sentiment classification', 0.4896),\n",
       "  ('level sentiment classification', 0.5284),\n",
       "  ('attention network', 0.5366),\n",
       "  ('aspect level sentiment classification', 0.6714)],\n",
       " [('explicit aspect mentions', 0.5332),\n",
       "  ('aspect term', 0.5665),\n",
       "  ('sentiment orientation', 0.5766),\n",
       "  ('aspect level sentiment classification', 0.7463),\n",
       "  ('aspect term extraction', 0.7743)],\n",
       " [('sentiment', 0.3418),\n",
       "  ('attention', 0.3533),\n",
       "  ('sentiment analysis', 0.4528),\n",
       "  ('level sentiment analysis', 0.5428),\n",
       "  ('hierarchical attention based position', 0.5845)],\n",
       " [('aspects', 0.528),\n",
       "  ('aspect', 0.5334),\n",
       "  ('sentiment classification', 0.6479),\n",
       "  ('level sentiment classification', 0.6752),\n",
       "  ('aspect level sentiment classification', 0.8722)],\n",
       " [('target', 0.3467),\n",
       "  ('classification', 0.3612),\n",
       "  ('sentiment', 0.4281),\n",
       "  ('transformation networks', 0.5267),\n",
       "  ('sentiment classification', 0.6427)],\n",
       " [('sentiment', 0.3663),\n",
       "  ('lstm', 0.5361),\n",
       "  ('sentiment classification', 0.5629),\n",
       "  ('level sentiment classification', 0.5766),\n",
       "  ('aspect level sentiment classification', 0.7478)],\n",
       " [('sentiment', 0.4176),\n",
       "  ('neural networks', 0.4214),\n",
       "  ('rnns', 0.5148),\n",
       "  ('recurrent neural networks', 0.523),\n",
       "  ('sentiment analysis', 0.5326)],\n",
       " [('conversations', 0.3262),\n",
       "  ('emotion', 0.3519),\n",
       "  ('enriched transformer', 0.3994),\n",
       "  ('textual conversations', 0.4646),\n",
       "  ('emotion detection', 0.4803)],\n",
       " [('social networks', 0.3095),\n",
       "  ('conversations', 0.3839),\n",
       "  ('emotions', 0.4723),\n",
       "  ('textual conversations', 0.5484),\n",
       "  ('opinion mining', 0.595)],\n",
       " [('conversations', 0.4327),\n",
       "  ('emotion', 0.4638),\n",
       "  ('emotions', 0.4822),\n",
       "  ('conversational context', 0.4975),\n",
       "  ('textual conversations', 0.6133)],\n",
       " [('learning', 0.276),\n",
       "  ('multi', 0.2774),\n",
       "  ('emotion', 0.4556),\n",
       "  ('emo2 vec', 0.526),\n",
       "  ('generalized emotion representation', 0.6738)],\n",
       " [('similarity', 0.3631),\n",
       "  ('sentiment', 0.3763),\n",
       "  ('embeddings', 0.4506),\n",
       "  ('document embeddings', 0.5075),\n",
       "  ('sentiment classification', 0.6436)],\n",
       " [('polarity classification', 0.4631),\n",
       "  ('aspect term', 0.5198),\n",
       "  ('aspect term extraction highlights', 0.6624),\n",
       "  ('aspect term extraction', 0.6995),\n",
       "  ('aspect polarity classification', 0.7182)],\n",
       " [('polarity', 0.4156),\n",
       "  ('aspect', 0.5772),\n",
       "  ('aspect term', 0.6861),\n",
       "  ('aspect term polarity', 0.7731),\n",
       "  ('aspect term extraction', 0.799)],\n",
       " [('aspect', 0.3913),\n",
       "  ('aspect term', 0.4609),\n",
       "  ('chinese review datasets', 0.4893),\n",
       "  ('aspect polarity classification', 0.6634),\n",
       "  ('aspect term extraction', 0.7134)],\n",
       " [('aspects', 0.533),\n",
       "  ('based sentiment analysis', 0.5776),\n",
       "  ('traditional sentiment analysis', 0.6133),\n",
       "  ('sentiment analysis', 0.6286),\n",
       "  ('aspect based sentiment analysis', 0.8084)],\n",
       " [('problem', 0.1916),\n",
       "  ('task', 0.4556),\n",
       "  ('classification problem', 0.5209),\n",
       "  ('classification', 0.5278),\n",
       "  ('apc task', 0.8029)],\n",
       " [('apc problems', 0.4235),\n",
       "  ('deep learning', 0.4537),\n",
       "  ('lstm', 0.4837),\n",
       "  ('apc tasks', 0.5374),\n",
       "  ('long short term memory', 0.5452)],\n",
       " [('sentiment', 0.4432),\n",
       "  ('compositionality', 0.4757),\n",
       "  ('recursive deep models', 0.5827),\n",
       "  ('semantic compositionality', 0.6353),\n",
       "  ('sentiment treebank', 0.7236)],\n",
       " [('richer supervised training', 0.4119),\n",
       "  ('sentiment', 0.4473),\n",
       "  ('composition', 0.4481),\n",
       "  ('sentiment detection', 0.5581),\n",
       "  ('compositionality', 0.575)],\n",
       " [('hand', 0.271),\n",
       "  ('learning', 0.2892),\n",
       "  ('sentiment', 0.4001),\n",
       "  ('sentiment analysis', 0.4413),\n",
       "  ('deep sentiment analysis', 0.683)],\n",
       " [('sentiment', 0.4808),\n",
       "  ('deep neural architectures', 0.4872),\n",
       "  ('polarity classification', 0.5295),\n",
       "  ('sentiment polarity', 0.6036),\n",
       "  ('supervised sentiment polarity classification', 0.7092)],\n",
       " [('sentiment', 0.4447), ('arabic', 0.5791)],\n",
       " [('natural language processing', 0.465),\n",
       "  ('sentiment', 0.4655),\n",
       "  ('natural language processing applications', 0.536),\n",
       "  ('useful natural language processing applications', 0.5535),\n",
       "  ('sentiment analysis', 0.6518)],\n",
       " [('sentences', 0.3345),\n",
       "  ('tasks', 0.3767),\n",
       "  ('sa', 0.3943),\n",
       "  ('level tasks', 0.4044),\n",
       "  ('absa', 0.4687)],\n",
       " [('modeling', 0.2175),\n",
       "  ('sentence', 0.3361),\n",
       "  ('lstm', 0.5833),\n",
       "  ('improved sentence modeling', 0.6906),\n",
       "  ('suffix bidirectional lstm', 0.8166)],\n",
       " [('sequential data', 0.4435),\n",
       "  ('recurrent', 0.4442),\n",
       "  ('natural language processing', 0.4896),\n",
       "  ('textual data', 0.5325),\n",
       "  ('recurrent neural networks', 0.6408)],\n",
       " [('results', 0.1632),\n",
       "  ('classification', 0.3118),\n",
       "  ('sentiment', 0.4129),\n",
       "  ('question classification', 0.4867),\n",
       "  ('sentiment classification', 0.6078)],\n",
       " [('neural networks', 0.4557),\n",
       "  ('recurrent', 0.4805),\n",
       "  ('rnn', 0.5394),\n",
       "  ('sequential data', 0.6505),\n",
       "  ('recurrent neural networks', 0.6857)],\n",
       " [('emotion', 0.4211),\n",
       "  ('ambiguity resolution', 0.4616),\n",
       "  ('emotion recognition', 0.5689),\n",
       "  ('speech emotion recognition', 0.6859),\n",
       "  ('multimodal speech emotion recognition', 0.8784)],\n",
       " [('task', 0.1924),\n",
       "  ('nontrivial task', 0.3574),\n",
       "  ('ambiguous definition', 0.3689),\n",
       "  ('speech', 0.4512),\n",
       "  ('emotion', 0.5371)],\n",
       " [('emotion', 0.3627),\n",
       "  ('deep learning', 0.4039),\n",
       "  ('deep learning algorithms', 0.4275),\n",
       "  ('emotion recognition', 0.5763),\n",
       "  ('speech emotion recognition', 0.7035)],\n",
       " [('features', 0.4137),\n",
       "  ('deep learning', 0.5035),\n",
       "  ('deep learning models', 0.5358),\n",
       "  ('reliant deep learning models', 0.5894),\n",
       "  ('lighter machine learning models', 0.7885)],\n",
       " [('based sentiment analysis', 0.4509),\n",
       "  ('sentiment analysis', 0.4593),\n",
       "  ('targeted aspect', 0.4651),\n",
       "  ('recurrent entity networks', 0.6158),\n",
       "  ('aspect based sentiment analysis', 0.6515)],\n",
       " [('sentiment', 0.5),\n",
       "  ('targeted aspect', 0.5458),\n",
       "  ('based sentiment analysis', 0.5468),\n",
       "  ('sentiment analysis', 0.5606),\n",
       "  ('aspect based sentiment analysis', 0.7239)],\n",
       " [('classification', 0.3471),\n",
       "  ('sentiment', 0.3759),\n",
       "  ('length vector', 0.4015),\n",
       "  ('level sentiment classification', 0.578),\n",
       "  ('sentiment classification', 0.5971)],\n",
       " [('systems', 0.3197),\n",
       "  ('critical role', 0.332),\n",
       "  ('learning', 0.4744),\n",
       "  ('many modern machine learning systems', 0.603),\n",
       "  ('representation learning', 0.6217)],\n",
       " [('sentiment', 0.3167),\n",
       "  ('joint neural model', 0.3846),\n",
       "  ('sentiment analysis', 0.4355),\n",
       "  ('parsing', 0.4718),\n",
       "  ('sentence level discourse parsing', 0.7673)],\n",
       " [('aspect', 0.4805),\n",
       "  ('urban neighbourhoods', 0.482),\n",
       "  ('targeted aspect', 0.5369),\n",
       "  ('aspect based sentiment analysis', 0.6984),\n",
       "  ('targeted aspect based sentiment analysis dataset', 0.8363)],\n",
       " [('aspect', 0.5096),\n",
       "  ('sentiment analysis', 0.5873),\n",
       "  ('based sentiment analysis', 0.5977),\n",
       "  ('targeted aspect', 0.613),\n",
       "  ('aspect based sentiment analysis', 0.8386)],\n",
       " [('certain target entity', 0.3807),\n",
       "  ('opinion polarities', 0.4545),\n",
       "  ('sentiment', 0.4957),\n",
       "  ('sentiment analysis', 0.5869),\n",
       "  ('targeted sentiment analysis', 0.8218)],\n",
       " [('sentiment', 0.5306),\n",
       "  ('sentiment polarity', 0.6019),\n",
       "  ('level sentiment classification', 0.6488),\n",
       "  ('sentiment classification', 0.673),\n",
       "  ('aspect level sentiment classification', 0.8743)],\n",
       " [('context', 0.3385),\n",
       "  ('videos', 0.3884),\n",
       "  ('sentiment', 0.4583),\n",
       "  ('sentiment analysis', 0.507),\n",
       "  ('dependent sentiment analysis', 0.5828)],\n",
       " [('research', 0.272),\n",
       "  ('sentiments', 0.4547),\n",
       "  ('sentiment', 0.4741),\n",
       "  ('sentiment analysis', 0.5585),\n",
       "  ('multimodal sentiment analysis', 0.8458)],\n",
       " [('analysis', 0.2024),\n",
       "  ('approaches', 0.2025),\n",
       "  ('sentiment', 0.4407),\n",
       "  ('sentiment analysis', 0.5547),\n",
       "  ('multimodal sentiment analysis', 0.9135)],\n",
       " [('learning', 0.2525),\n",
       "  ('sentence', 0.3272),\n",
       "  ('embeddings', 0.4953),\n",
       "  ('sentence embeddings', 0.6908),\n",
       "  ('semantic sentence embeddings', 0.8046)],\n",
       " [('paper', 0.0973),\n",
       "  ('level', 0.1662),\n",
       "  ('sentence', 0.3195),\n",
       "  ('level embeddings', 0.636),\n",
       "  ('embeddings', 0.6392)],\n",
       " [('deep generative framework', 0.4995),\n",
       "  ('paraphrase', 0.592),\n",
       "  ('paraphrase generation', 0.8594)],\n",
       " [('problem', 0.0871), ('paper', 0.1512), ('paraphrases', 0.7236)],\n",
       " [('semantics', 0.4371),\n",
       "  ('knowledge base question', 0.495),\n",
       "  ('gated graph neural networks', 0.506),\n",
       "  ('knowledge base', 0.5293),\n",
       "  ('modeling semantics', 0.5641)],\n",
       " [('qa', 0.4771),\n",
       "  ('natural language processing', 0.49),\n",
       "  ('important natural language processing problem', 0.5387),\n",
       "  ('knowledge base', 0.5985),\n",
       "  ('knowledge base question', 0.6171)],\n",
       " [('sentence', 0.3272),\n",
       "  ('sentences', 0.4736),\n",
       "  ('qa', 0.4861),\n",
       "  ('qa model', 0.5287),\n",
       "  ('simple sentence selector', 0.6751)],\n",
       " [('kb', 0.3933),\n",
       "  ('qa', 0.4766),\n",
       "  ('kb qa', 0.5952),\n",
       "  ('parsing', 0.612),\n",
       "  ('semantic parsing', 0.7215)],\n",
       " [('single sentence', 0.3999),\n",
       "  ('queries', 0.436),\n",
       "  ('comprehension', 0.5149),\n",
       "  ('reading comprehension', 0.6903),\n",
       "  ('most reading comprehension methods', 0.7667)],\n",
       " [('evidence', 0.3467),\n",
       "  ('attention', 0.375),\n",
       "  ('textual evidence', 0.519),\n",
       "  ('comprehension', 0.5628),\n",
       "  ('reading comprehension', 0.6949)],\n",
       " [('children', 0.2963),\n",
       "  ('rc', 0.3215),\n",
       "  ('artificial agents', 0.3556),\n",
       "  ('learning', 0.3607),\n",
       "  ('rc ability', 0.4036)],\n",
       " [('match', 0.2763),\n",
       "  ('machine', 0.3093),\n",
       "  ('comprehension', 0.4892),\n",
       "  ('lstm', 0.5577),\n",
       "  ('machine comprehension', 0.706)],\n",
       " [('natural language', 0.3323),\n",
       "  ('artificial intelligence', 0.3686),\n",
       "  ('mc', 0.4617),\n",
       "  ('comprehension', 0.472),\n",
       "  ('machine comprehension', 0.6446)],\n",
       " [('task', 0.3828),\n",
       "  ('mc', 0.3971),\n",
       "  ('insufficient lexical understanding', 0.3984),\n",
       "  ('incorrect answer extraction', 0.4585),\n",
       "  ('mc task', 0.626)],\n",
       " [('models', 0.267),\n",
       "  ('significant performance improvements', 0.2799),\n",
       "  ('documents', 0.2937),\n",
       "  ('qa', 0.3523),\n",
       "  ('neural models', 0.4253)],\n",
       " [('text', 0.3394),\n",
       "  ('visual question', 0.3978),\n",
       "  ('attention', 0.5412),\n",
       "  ('focal visual', 0.5586),\n",
       "  ('text attention', 0.6126)],\n",
       " [('natural language', 0.4036),\n",
       "  ('answer questions', 0.405),\n",
       "  ('computer vision', 0.4221),\n",
       "  ('visual question', 0.4715),\n",
       "  ('vqa', 0.5177)],\n",
       " [('problem', 0.1108),\n",
       "  ('paper', 0.1569),\n",
       "  ('image', 0.358),\n",
       "  ('single image', 0.4852),\n",
       "  ('vqa', 0.5332)],\n",
       " [('answer', 0.2267),\n",
       "  ('answer re', 0.2346),\n",
       "  ('evidence', 0.3479),\n",
       "  ('ranking', 0.3983),\n",
       "  ('evidence aggregation', 0.5336)],\n",
       " [('knowledge', 0.331),\n",
       "  ('questions', 0.3623),\n",
       "  ('qa', 0.4608),\n",
       "  ('answer questions', 0.4679),\n",
       "  ('domain knowledge sources', 0.511)],\n",
       " [('domain', 0.1807),\n",
       "  ('squad', 0.2898),\n",
       "  ('qa', 0.4114),\n",
       "  ('datasets', 0.4945),\n",
       "  ('domain qa datasets', 0.7149)],\n",
       " [('classification', 0.3349),\n",
       "  ('intent', 0.3643),\n",
       "  ('scientific publications', 0.4866),\n",
       "  ('citation', 0.5451),\n",
       "  ('citation intent classification', 0.8657)],\n",
       " [('machine reading', 0.3947),\n",
       "  ('individual publications', 0.4279),\n",
       "  ('scientific literature', 0.5086),\n",
       "  ('scientific papers', 0.5318),\n",
       "  ('citation', 0.5506)],\n",
       " [('classification', 0.3389),\n",
       "  ('intent', 0.4236),\n",
       "  ('citation', 0.5003),\n",
       "  ('citation context', 0.5847),\n",
       "  ('citation intent classification', 0.9053)],\n",
       " [('neural networks', 0.4105),\n",
       "  ('hierarchical neural networks', 0.5409),\n",
       "  ('sentence classification', 0.6045),\n",
       "  ('medical scientific abstracts', 0.6397),\n",
       "  ('sequential sentence classification', 0.6875)],\n",
       " [('classification', 0.4513),\n",
       "  ('structured prediction', 0.5909),\n",
       "  ('traditional sentence classification approaches', 0.7288),\n",
       "  ('sentence classification', 0.7457),\n",
       "  ('sequential sentence classification', 0.7812)],\n",
       " [('sentence', 0.3672),\n",
       "  ('classification', 0.371),\n",
       "  ('translations', 0.5428),\n",
       "  ('additional contexts', 0.5818),\n",
       "  ('sentence classification', 0.6831)],\n",
       " [('language', 0.3697),\n",
       "  ('sentence', 0.3746),\n",
       "  ('evaluator', 0.5288),\n",
       "  ('language model', 0.5394),\n",
       "  ('sentence compression', 0.7355)],\n",
       " [('deletion', 0.3004),\n",
       "  ('sentence', 0.3469),\n",
       "  ('lstms', 0.5964),\n",
       "  ('sentence compression', 0.7606)],\n",
       " [('deletion', 0.3017),\n",
       "  ('language', 0.3032),\n",
       "  ('evaluation operations', 0.4145),\n",
       "  ('evaluator', 0.4586),\n",
       "  ('sentence compression', 0.6917)],\n",
       " [('nlp', 0.4763),\n",
       "  ('paraphrase', 0.5321),\n",
       "  ('standard nlp task', 0.5357),\n",
       "  ('shorter paraphrase', 0.6067),\n",
       "  ('sentence compression', 0.8144)],\n",
       " [('sentence', 0.3102),\n",
       "  ('learning', 0.3484),\n",
       "  ('gaze', 0.5301),\n",
       "  ('sentence compression', 0.5861)],\n",
       " [('word', 0.2454),\n",
       "  ('representations', 0.2531),\n",
       "  ('text', 0.3039),\n",
       "  ('contextualized word representations', 0.5674),\n",
       "  ('prosodic prominence', 0.7227)],\n",
       " [('text', 0.3018),\n",
       "  ('natural language', 0.3747),\n",
       "  ('natural language processing', 0.4625),\n",
       "  ('new natural language processing dataset', 0.5492),\n",
       "  ('prosodic prominence', 0.684)],\n",
       " [('emphasis', 0.3227),\n",
       "  ('speaker', 0.3249),\n",
       "  ('text', 0.4016),\n",
       "  ('sequence labeling task', 0.5748),\n",
       "  ('prosody prediction', 0.7406)],\n",
       " [('dataset', 0.3241),\n",
       "  ('sql task', 0.4355),\n",
       "  ('parsing', 0.4379),\n",
       "  ('semantic parsing', 0.553),\n",
       "  ('domain semantic parsing', 0.6292)],\n",
       " [('natural language', 0.5271),\n",
       "  ('nlp', 0.549),\n",
       "  ('natural language processing', 0.6652),\n",
       "  ('parsing', 0.672),\n",
       "  ('semantic parsing', 0.8104)],\n",
       " [('sp', 0.3298), ('shortcomings', 0.4935), ('datasets', 0.6014)],\n",
       " [('transition', 0.2947),\n",
       "  ('parsing', 0.5078),\n",
       "  ('semantic parsing', 0.5622),\n",
       "  ('neural abstract syntax parser', 0.8358)],\n",
       " [('coarse', 0.2052),\n",
       "  ('parsing', 0.5508),\n",
       "  ('fine decoding', 0.5586),\n",
       "  ('semantic parsing', 0.64),\n",
       "  ('neural semantic parsing', 0.82)],\n",
       " [('natural language', 0.5168),\n",
       "  ('natural language utterances', 0.5472),\n",
       "  ('parsing', 0.6563),\n",
       "  ('structured meaning representations', 0.7454),\n",
       "  ('semantic parsing', 0.795)],\n",
       " [('learning', 0.3275),\n",
       "  ('negbert', 0.372),\n",
       "  ('scope resolution', 0.3751),\n",
       "  ('transfer learning approach', 0.5053),\n",
       "  ('negation detection', 0.6424)],\n",
       " [('discriminative model', 0.4342),\n",
       "  ('gan', 0.5696),\n",
       "  ('generative models', 0.6784),\n",
       "  ('generative model', 0.6789),\n",
       "  ('generative adversarial net', 0.7429)],\n",
       " [('goal', 0.088),\n",
       "  ('sequences', 0.4032),\n",
       "  ('limitations', 0.5069),\n",
       "  ('generating sequences', 0.5503),\n",
       "  ('discrete tokens', 0.6281)],\n",
       " [('real one', 0.253),\n",
       "  ('data', 0.3082),\n",
       "  ('learning', 0.3731),\n",
       "  ('unsupervised learning', 0.5516),\n",
       "  ('sequential synthetic data', 0.7883)],\n",
       " [('training', 0.2474),\n",
       "  ('skip', 0.377),\n",
       "  ('text', 0.3919),\n",
       "  ('adversarial training', 0.5176)],\n",
       " [('text', 0.3649),\n",
       "  ('embeddings', 0.4389),\n",
       "  ('word embeddings', 0.4978),\n",
       "  ('gans', 0.5631),\n",
       "  ('text generation', 0.6687)],\n",
       " [('natural language', 0.472),\n",
       "  ('machine translation', 0.4961),\n",
       "  ('natural language text', 0.5568),\n",
       "  ('text generation', 0.6773),\n",
       "  ('natural language text generation', 0.7603)],\n",
       " [('ranking', 0.3453),\n",
       "  ('language', 0.411),\n",
       "  ('adversarial ranking', 0.6421),\n",
       "  ('language generation', 0.7394)],\n",
       " [('training', 0.2527),\n",
       "  ('text', 0.3973),\n",
       "  ('leaked information', 0.4801),\n",
       "  ('adversarial training', 0.5611),\n",
       "  ('text generation', 0.6537)],\n",
       " [('translation', 0.2952),\n",
       "  ('text', 0.4798),\n",
       "  ('dialogue systems', 0.4876),\n",
       "  ('machine translation', 0.5424),\n",
       "  ('meaningful text', 0.5878)],\n",
       " [('text', 0.4041),\n",
       "  ('dilated convolutions', 0.5137),\n",
       "  ('text modeling', 0.528),\n",
       "  ('variational autoencoders', 0.6632),\n",
       "  ('improved variational autoencoders', 0.6882)],\n",
       " [('text modeling', 0.455),\n",
       "  ('lstm decoders', 0.5564),\n",
       "  ('simpler lstm language models', 0.5898),\n",
       "  ('generative text modeling', 0.612),\n",
       "  ('variational autoencoders', 0.6634)],\n",
       " [('encoder matching model', 0.3627),\n",
       "  ('utterance', 0.4039),\n",
       "  ('level semantic dependency', 0.4522),\n",
       "  ('learning utterance', 0.5957),\n",
       "  ('dialogue generation', 0.7221)],\n",
       " [('technical support agents', 0.3855),\n",
       "  ('chatbots', 0.566),\n",
       "  ('domain chatbots', 0.5855),\n",
       "  ('dialogue generation', 0.708),\n",
       "  ('automatic dialogue generation task', 0.8005)],\n",
       " [('word', 0.1738),\n",
       "  ('inputs', 0.1941),\n",
       "  ('flexible task', 0.2585),\n",
       "  ('responses', 0.3196),\n",
       "  ('conversation generation', 0.7758)],\n",
       " [('task', 0.2303),\n",
       "  ('nsurl', 0.3264),\n",
       "  ('similarity', 0.368),\n",
       "  ('arabic', 0.44),\n",
       "  ('semantic question similarity', 0.6709)],\n",
       " [('text', 0.2692),\n",
       "  ('task', 0.2885),\n",
       "  ('similarity', 0.4433),\n",
       "  ('nsurl', 0.4922),\n",
       "  ('semantic text question similarity task', 0.7674)],\n",
       " [('problems', 0.2182),\n",
       "  ('text', 0.3824),\n",
       "  ('sts', 0.3975),\n",
       "  ('similarity', 0.523),\n",
       "  ('semantic text similarity', 0.7377)],\n",
       " [('sentence', 0.3436),\n",
       "  ('sts', 0.41),\n",
       "  ('paraphrase', 0.5258),\n",
       "  ('paraphrase identification', 0.6441),\n",
       "  ('paraphrase identification task', 0.6648)],\n",
       " [('data annotation team', 0.3241),\n",
       "  ('similarity', 0.4225),\n",
       "  ('arabic', 0.4484),\n",
       "  ('arabic language', 0.4803),\n",
       "  ('semantic question similarity', 0.7154)],\n",
       " [('compare', 0.2129),\n",
       "  ('same meaning', 0.2149),\n",
       "  ('questions', 0.2934),\n",
       "  ('sts', 0.4405),\n",
       "  ('sqs', 0.6016)],\n",
       " [('query', 0.3201), ('document', 0.3418), ('document expansion', 0.6893)],\n",
       " [('passage', 0.4293),\n",
       "  ('ranking', 0.4342),\n",
       "  ('passage re', 0.4441),\n",
       "  ('bert', 0.5591)],\n",
       " [('passage', 0.2683),\n",
       "  ('query', 0.275),\n",
       "  ('passage re', 0.3171),\n",
       "  ('bert', 0.4081),\n",
       "  ('ranking', 0.4109)],\n",
       " [('question', 0.2203),\n",
       "  ('text', 0.3326),\n",
       "  ('neural question', 0.3903),\n",
       "  ('question generation', 0.7746),\n",
       "  ('neural question generation', 0.8978)],\n",
       " [('questions', 0.3891),\n",
       "  ('text passage', 0.3971),\n",
       "  ('automatic question', 0.646),\n",
       "  ('question generation', 0.8185),\n",
       "  ('automatic question generation', 0.8752)],\n",
       " [('natural language', 0.4371),\n",
       "  ('natural language text', 0.4621),\n",
       "  ('automatic question', 0.6913),\n",
       "  ('question generation', 0.7548),\n",
       "  ('automatic question generation', 0.8476)],\n",
       " [('corpus', 0.374),\n",
       "  ('answer pairs', 0.3887),\n",
       "  ('reverse task', 0.4009),\n",
       "  ('large scale corpus', 0.4162),\n",
       "  ('question generation', 0.7024)],\n",
       " [('question', 0.122),\n",
       "  ('visual question', 0.3324),\n",
       "  ('question generation', 0.5737),\n",
       "  ('multimodal differential network', 0.6378),\n",
       "  ('visual question generation', 0.7859)],\n",
       " [('image', 0.3304),\n",
       "  ('natural questions', 0.4044),\n",
       "  ('language modality', 0.4141),\n",
       "  ('semantic task', 0.4413),\n",
       "  ('multimodal representations', 0.6392)],\n",
       " [('au', 0.321),\n",
       "  ('challenging task', 0.3767),\n",
       "  ('questions', 0.4447),\n",
       "  ('thors', 0.4683),\n",
       "  ('natural questions', 0.5438)],\n",
       " [('tagging', 0.4541),\n",
       "  ('adversarial training', 0.4566),\n",
       "  ('multilingual part', 0.539),\n",
       "  ('speech tagging', 0.6525),\n",
       "  ('robust multilingual part', 0.6538)],\n",
       " [('paper', 0.1997),\n",
       "  ('model', 0.2916),\n",
       "  ('pos', 0.3846),\n",
       "  ('tagging', 0.5748),\n",
       "  ('neural pos tagging model', 0.9276)],\n",
       " [('words', 0.2856),\n",
       "  ('learning', 0.3198),\n",
       "  ('sequence', 0.3336),\n",
       "  ('better internal structure', 0.4684)],\n",
       " [('powerful model', 0.1634),\n",
       "  ('model', 0.1643),\n",
       "  ('sequence', 0.2862),\n",
       "  ('statistical sequence labeling', 0.7136)],\n",
       " [('transfer', 0.3048),\n",
       "  ('recurrent', 0.3895),\n",
       "  ('tagging', 0.4509),\n",
       "  ('recurrent networks', 0.5532),\n",
       "  ('sequence tagging', 0.659)],\n",
       " [('multilingual part', 0.4878),\n",
       "  ('term memory', 0.5527),\n",
       "  ('term memory models', 0.5872),\n",
       "  ('long short term memory', 0.5924),\n",
       "  ('speech tagging', 0.6952)],\n",
       " [('unicode', 0.3677),\n",
       "  ('embeddings', 0.3858),\n",
       "  ('tagging', 0.4093),\n",
       "  ('lstms', 0.431),\n",
       "  ('byte embeddings', 0.4339)],\n",
       " [('context', 0.2451),\n",
       "  ('token', 0.2643),\n",
       "  ('bilstm model', 0.3101),\n",
       "  ('tagging', 0.4674),\n",
       "  ('morphosyntactic tagging', 0.7601)],\n",
       " [('cnns', 0.3296),\n",
       "  ('sequence', 0.3505),\n",
       "  ('lstm', 0.507),\n",
       "  ('directional lstm', 0.5235),\n",
       "  ('end sequence labeling', 0.7001)],\n",
       " [('features', 0.2521),\n",
       "  ('handcrafted features', 0.317),\n",
       "  ('sequence', 0.3498),\n",
       "  ('taskspecific knowledge', 0.4301),\n",
       "  ('art sequence labeling systems', 0.6593)],\n",
       " [('deep language understanding', 0.4534),\n",
       "  ('natural language processing community', 0.4751),\n",
       "  ('entity recognition', 0.5242),\n",
       "  ('natural language processing', 0.5276),\n",
       "  ('linguistic sequence labeling', 0.656)],\n",
       " [('pos', 0.2828),\n",
       "  ('dependency', 0.4088),\n",
       "  ('tagging', 0.4373),\n",
       "  ('parsing', 0.5274),\n",
       "  ('joint pos tagging', 0.6084)],\n",
       " [('text', 0.323),\n",
       "  ('semantics', 0.479),\n",
       "  ('comprehension', 0.5748),\n",
       "  ('explicit contextual semantics', 0.7618),\n",
       "  ('text comprehension', 0.7744)],\n",
       " [('progress', 0.2892),\n",
       "  ('machine', 0.2989),\n",
       "  ('document', 0.3105),\n",
       "  ('answer questions', 0.3763),\n",
       "  ('machine reading', 0.6998)],\n",
       " [('machine', 0.2238),\n",
       "  ('context', 0.4319),\n",
       "  ('comprehension', 0.5592),\n",
       "  ('perspective context matching', 0.6397),\n",
       "  ('machine comprehension', 0.7039)],\n",
       " [('deep learning', 0.3838),\n",
       "  ('deep learning models', 0.4191),\n",
       "  ('comprehension', 0.4216),\n",
       "  ('machine comprehension', 0.5709),\n",
       "  ('previous machine comprehension', 0.6369)],\n",
       " [('inference', 0.3248),\n",
       "  ('natural language', 0.3315),\n",
       "  ('attention', 0.4203),\n",
       "  ('natural language inference', 0.5404),\n",
       "  ('attention network', 0.5857)],\n",
       " [('human', 0.2656),\n",
       "  ('reasoning', 0.5132),\n",
       "  ('artificial intelligence', 0.5392),\n",
       "  ('inference', 0.5465)],\n",
       " [('inference', 0.3321),\n",
       "  ('natural language', 0.4199),\n",
       "  ('deep learning', 0.4206),\n",
       "  ('nli', 0.4268),\n",
       "  ('natural language inference', 0.6195)],\n",
       " [('performance', 0.2576),\n",
       "  ('data', 0.2932),\n",
       "  ('nli', 0.5363),\n",
       "  ('snli data', 0.7144),\n",
       "  ('nli data', 0.7522)],\n",
       " [('clinical case reports', 0.4366),\n",
       "  ('comprehension', 0.4987),\n",
       "  ('machine reading', 0.5712),\n",
       "  ('reading comprehension', 0.6453),\n",
       "  ('machine reading comprehension', 0.7292)],\n",
       " [('text', 0.3176),\n",
       "  ('comprehension', 0.4411),\n",
       "  ('correct answer span', 0.4785),\n",
       "  ('reading comprehension', 0.6042),\n",
       "  ('end reading comprehension', 0.6364)],\n",
       " [('task', 0.2059),\n",
       "  ('document', 0.2407),\n",
       "  ('qa', 0.246),\n",
       "  ('rc', 0.4302),\n",
       "  ('answer span prediction style question', 0.465)],\n",
       " [('community question', 0.3415),\n",
       "  ('task', 0.3496),\n",
       "  ('semeval', 0.3526),\n",
       "  ('kelp system', 0.4322),\n",
       "  ('qa', 0.4842)],\n",
       " [('good answers', 0.2369),\n",
       "  ('task', 0.3039),\n",
       "  ('answers', 0.3335),\n",
       "  ('participants', 0.3552),\n",
       "  ('qa', 0.559)],\n",
       " [('computer vision', 0.3683),\n",
       "  ('natural language processing', 0.3778),\n",
       "  ('attention', 0.4045),\n",
       "  ('attention mechanisms', 0.4572),\n",
       "  ('neural networks', 0.5068)],\n",
       " [('attention mechanisms', 0.3764),\n",
       "  ('deep neural networks', 0.3851),\n",
       "  ('attention', 0.3914),\n",
       "  ('sequence compression', 0.527),\n",
       "  ('context fusion', 0.602)],\n",
       " [('learning', 0.374),\n",
       "  ('task', 0.4032),\n",
       "  ('tree', 0.4626),\n",
       "  ('compose task', 0.5563),\n",
       "  ('specific tree structures', 0.567)],\n",
       " [('memory', 0.457),\n",
       "  ('term memory', 0.5105),\n",
       "  ('term memory architecture', 0.5211),\n",
       "  ('lstm', 0.5758),\n",
       "  ('long short term memory', 0.6519)],\n",
       " [('natural language', 0.3631),\n",
       "  ('sentences', 0.381),\n",
       "  ('rte', 0.5055),\n",
       "  ('entailment', 0.6006),\n",
       "  ('textual entailment', 0.6904)],\n",
       " [('nlp', 0.4864),\n",
       "  ('many natural language processing', 0.5445),\n",
       "  ('information extraction', 0.5539),\n",
       "  ('accurate rte systems', 0.579),\n",
       "  ('natural language processing', 0.5836)],\n",
       " [('supervised learning', 0.3673),\n",
       "  ('inference', 0.3759),\n",
       "  ('natural language', 0.4011),\n",
       "  ('natural language inference', 0.6563),\n",
       "  ('universal sentence representations', 0.8033)],\n",
       " [('identification', 0.1779),\n",
       "  ('noisy pretraining', 0.2599),\n",
       "  ('questions', 0.3656),\n",
       "  ('paraphrase', 0.5275),\n",
       "  ('paraphrase identification', 0.7138)],\n",
       " [('identification', 0.24),\n",
       "  ('solution', 0.2404),\n",
       "  ('questions', 0.4305),\n",
       "  ('paraphrase', 0.5573),\n",
       "  ('paraphrase identification', 0.7982)],\n",
       " [('nlp', 0.478),\n",
       "  ('useful nlp application', 0.5365),\n",
       "  ('paraphrase', 0.6127),\n",
       "  ('paraphrase identification', 0.8462),\n",
       "  ('question paraphrase identification', 0.8709)],\n",
       " [('natural language', 0.4078),\n",
       "  ('natural language processing field', 0.4189),\n",
       "  ('mc', 0.4711),\n",
       "  ('comprehension', 0.5644),\n",
       "  ('machine comprehension', 0.721)],\n",
       " [('medical domain', 0.3768),\n",
       "  ('new dataset', 0.3872),\n",
       "  ('dataset', 0.4002),\n",
       "  ('comprehension', 0.5055),\n",
       "  ('machine comprehension', 0.6913)],\n",
       " [('memory', 0.6658), ('neural stored', 0.7492), ('program memory', 0.7851)],\n",
       " [('weights', 0.352),\n",
       "  ('new memory', 0.4916),\n",
       "  ('memory', 0.509),\n",
       "  ('modern computer architectures', 0.5296),\n",
       "  ('program memory', 0.631)],\n",
       " [('networks', 0.2407),\n",
       "  ('conference paper', 0.2744),\n",
       "  ('query', 0.3361),\n",
       "  ('reduction networks', 0.4032),\n",
       "  ('iclr', 0.4898)],\n",
       " [('evidence', 0.2407),\n",
       "  ('single document', 0.2443),\n",
       "  ('significant progress', 0.2471),\n",
       "  ('models', 0.2779),\n",
       "  ('neural models', 0.4618)],\n",
       " [('topic', 0.3684),\n",
       "  ('popular topic', 0.3758),\n",
       "  ('natural language', 0.4678),\n",
       "  ('natural language processing', 0.5118),\n",
       "  ('qa', 0.5847)],\n",
       " [('inference', 0.3966),\n",
       "  ('interaction space', 0.4269),\n",
       "  ('natural language', 0.4654),\n",
       "  ('iclr', 0.4905),\n",
       "  ('natural language inference', 0.6482)],\n",
       " [('learning', 0.3022),\n",
       "  ('inference', 0.4787),\n",
       "  ('natural language', 0.5006),\n",
       "  ('corpus', 0.5204),\n",
       "  ('natural language inference', 0.7912)],\n",
       " [('inference', 0.4619),\n",
       "  ('nli', 0.5206),\n",
       "  ('natural language', 0.5241),\n",
       "  ('entailment', 0.5557),\n",
       "  ('natural language inference', 0.6729)],\n",
       " [('comprehension', 0.4286),\n",
       "  ('neural networks', 0.4509),\n",
       "  ('machine reading', 0.5794),\n",
       "  ('reading comprehension', 0.5858),\n",
       "  ('machine reading comprehension', 0.6565)],\n",
       " [('simple', 0.2525), ('qa', 0.4243), ('neural qa', 0.7828)],\n",
       " [('entity', 0.2864),\n",
       "  ('entities', 0.2982),\n",
       "  ('correct entity', 0.3196),\n",
       "  ('query', 0.333),\n",
       "  ('natural language', 0.3721)],\n",
       " [('simple', 0.1104),\n",
       "  ('features', 0.2757),\n",
       "  ('text', 0.3789),\n",
       "  ('effective text matching', 0.8462)],\n",
       " [('recurrent', 0.4032),\n",
       "  ('knowledge', 0.4424),\n",
       "  ('neural networks', 0.448),\n",
       "  ('memory', 0.4489),\n",
       "  ('recurrent neural networks', 0.6617)],\n",
       " [('recurrent', 0.434),\n",
       "  ('neural networks', 0.4876),\n",
       "  ('term dependencies', 0.5125),\n",
       "  ('long term dependencies', 0.6773),\n",
       "  ('recurrent neural networks', 0.6921)],\n",
       " [('systems', 0.203),\n",
       "  ('dynamic integration', 0.2787),\n",
       "  ('nlu', 0.3725),\n",
       "  ('knowledge', 0.3933),\n",
       "  ('background knowledge', 0.5578)],\n",
       " [('background knowledge', 0.4508),\n",
       "  ('language understanding', 0.4793),\n",
       "  ('natural language understanding', 0.5182),\n",
       "  ('training corpora', 0.527),\n",
       "  ('most neural natural language understanding', 0.6364)],\n",
       " [('approach', 0.1767),\n",
       "  ('question', 0.1787),\n",
       "  ('discrete hard em approach', 0.493),\n",
       "  ('weakly supervised question', 0.6225)],\n",
       " [('questions', 0.2895),\n",
       "  ('challenge', 0.4338),\n",
       "  ('answer questions', 0.4357),\n",
       "  ('documents', 0.4648),\n",
       "  ('unsolved challenge', 0.569)],\n",
       " [('memory', 0.4051),\n",
       "  ('term memory', 0.5463),\n",
       "  ('machine reading', 0.6424),\n",
       "  ('memory networks', 0.6818),\n",
       "  ('long short term memory', 0.7115)],\n",
       " [('tasks', 0.2722),\n",
       "  ('language', 0.3105),\n",
       "  ('sentence', 0.3962),\n",
       "  ('natural language', 0.5882),\n",
       "  ('natural language sentence matching', 0.8042)],\n",
       " [('sentence', 0.3948),\n",
       "  ('sentences', 0.4944),\n",
       "  ('natural language', 0.5495),\n",
       "  ('nlsm', 0.5755),\n",
       "  ('natural language sentence matching', 0.7361)],\n",
       " [('sentences', 0.4496),\n",
       "  ('paraphrase', 0.5255),\n",
       "  ('nlsm', 0.534),\n",
       "  ('paraphrase identification', 0.6773),\n",
       "  ('paraphrase identification task', 0.7011)],\n",
       " [('simple', 0.2814),\n",
       "  ('networks', 0.3287),\n",
       "  ('large scale', 0.3582),\n",
       "  ('memory', 0.3935),\n",
       "  ('memory networks', 0.6154)],\n",
       " [('possible questions', 0.2332),\n",
       "  ('training', 0.3407),\n",
       "  ('questions', 0.3671),\n",
       "  ('large scale', 0.3709),\n",
       "  ('training sources', 0.496)],\n",
       " [('simple', 0.2682),\n",
       "  ('transfer', 0.2743),\n",
       "  ('reasoning', 0.3529),\n",
       "  ('learning', 0.3964),\n",
       "  ('multitask', 0.5793)],\n",
       " [('kb', 0.3443),\n",
       "  ('single fact', 0.3925),\n",
       "  ('multiple facts', 0.42),\n",
       "  ('reasoning', 0.4342),\n",
       "  ('higher reasoning capabilities', 0.5498)],\n",
       " [('comprehension', 0.4449),\n",
       "  ('machine reading', 0.5099),\n",
       "  ('reading comprehension', 0.5979),\n",
       "  ('machine reading comprehension', 0.7041),\n",
       "  ('passage machine reading comprehension', 0.7766)],\n",
       " [('mrc', 0.4502),\n",
       "  ('comprehension', 0.4507),\n",
       "  ('reading comprehension', 0.6214),\n",
       "  ('machine reading', 0.6251),\n",
       "  ('machine reading comprehension', 0.7363)],\n",
       " [('accuracy', 0.3508),\n",
       "  ('questions', 0.3775),\n",
       "  ('mrc', 0.441),\n",
       "  ('mrc models', 0.547),\n",
       "  ('long questions', 0.5522)],\n",
       " [('sentence', 0.2876),\n",
       "  ('representations', 0.4223),\n",
       "  ('dynamic meta', 0.4294),\n",
       "  ('embeddings', 0.518),\n",
       "  ('improved sentence representations', 0.7815)],\n",
       " [('task', 0.357),\n",
       "  ('supervised learning', 0.3979),\n",
       "  ('dynamic meta', 0.4116),\n",
       "  ('representations', 0.4302),\n",
       "  ('embeddings', 0.4907)],\n",
       " [('sequential tasks', 0.4702),\n",
       "  ('rnn', 0.4786),\n",
       "  ('unitary evolution matrices', 0.507),\n",
       "  ('associative memory', 0.5176),\n",
       "  ('recurrent neural networks', 0.6154)],\n",
       " [('limited capacity', 0.3483),\n",
       "  ('term memory', 0.3869),\n",
       "  ('memory', 0.447),\n",
       "  ('rnn', 0.5921)],\n",
       " [('multi', 0.2038),\n",
       "  ('hop question', 0.2583),\n",
       "  ('tasks', 0.2697),\n",
       "  ('generative multi', 0.4309),\n",
       "  ('commonsense', 0.4332)],\n",
       " [('comprehension', 0.3949),\n",
       "  ('qa', 0.441),\n",
       "  ('reading comprehension', 0.5405),\n",
       "  ('extractive qa', 0.6301),\n",
       "  ('comprehension qa tasks', 0.7013)],\n",
       " [('comprehension', 0.4733),\n",
       "  ('machine reading', 0.5408),\n",
       "  ('qa', 0.55),\n",
       "  ('reading comprehension', 0.6055),\n",
       "  ('machine reading comprehension', 0.7114)],\n",
       " [('evidence', 0.3502),\n",
       "  ('mrc', 0.3665),\n",
       "  ('reasoning', 0.3991),\n",
       "  ('qa', 0.4473),\n",
       "  ('babi dataset', 0.4993)],\n",
       " [('model', 0.242),\n",
       "  ('sentence', 0.3392),\n",
       "  ('fast unified model', 0.4378),\n",
       "  ('sentence understanding', 0.5336),\n",
       "  ('parsing', 0.6921)],\n",
       " [('information', 0.4116), ('attention', 0.5274)],\n",
       " [('artificial intelligence', 0.3545),\n",
       "  ('artificial intelligence community', 0.3937),\n",
       "  ('natural language', 0.4552),\n",
       "  ('queries', 0.4555),\n",
       "  ('qa', 0.5181)],\n",
       " [('language', 0.2929),\n",
       "  ('text', 0.4331),\n",
       "  ('natural language', 0.5161),\n",
       "  ('natural language processing', 0.6114),\n",
       "  ('unstructured text', 0.7666)],\n",
       " [('sentence', 0.3227),\n",
       "  ('nli', 0.3778),\n",
       "  ('embeddings', 0.5167),\n",
       "  ('sentence embeddings', 0.7103)],\n",
       " [('sentence', 0.4012),\n",
       "  ('representations', 0.4216),\n",
       "  ('level representations', 0.4954),\n",
       "  ('nlp', 0.5249),\n",
       "  ('various nlp tasks', 0.7298)],\n",
       " [('inference', 0.2987),\n",
       "  ('dataset', 0.3716),\n",
       "  ('commonsense', 0.4614),\n",
       "  ('scale adversarial dataset', 0.551),\n",
       "  ('grounded commonsense inference', 0.6857)],\n",
       " [('reasoning', 0.2969),\n",
       "  ('rc', 0.3425),\n",
       "  ('information retrieval', 0.4284),\n",
       "  ('comprehension', 0.5378),\n",
       "  ('reading comprehension', 0.72)],\n",
       " [('order', 0.3494),\n",
       "  ('language', 0.421),\n",
       "  ('images', 0.4418),\n",
       "  ('embeddings', 0.6926)],\n",
       " [('images', 0.3176),\n",
       "  ('sentences', 0.3982),\n",
       "  ('entailment', 0.4639),\n",
       "  ('textual entailment', 0.5276),\n",
       "  ('semantic hierarchy', 0.5337)],\n",
       " [('images', 0.3182),\n",
       "  ('language', 0.3315),\n",
       "  ('partial order', 0.488),\n",
       "  ('relations', 0.516),\n",
       "  ('visualsemantic hierarchy', 0.7188)],\n",
       " [('machine', 0.2857),\n",
       "  ('flow', 0.3387),\n",
       "  ('comprehension', 0.4451),\n",
       "  ('machine comprehension', 0.5615),\n",
       "  ('conversational machine comprehension', 0.7164)],\n",
       " [('machine', 0.2432),\n",
       "  ('comprehension', 0.4087),\n",
       "  ('dialogs', 0.5378),\n",
       "  ('machine comprehension', 0.5751),\n",
       "  ('conversational machine comprehension', 0.789)],\n",
       " [('domain', 0.256),\n",
       "  ('sentence', 0.2599),\n",
       "  ('shortcut', 0.3225),\n",
       "  ('inference', 0.3916),\n",
       "  ('sentence encoders', 0.5838)],\n",
       " [('encoder', 0.3417),\n",
       "  ('natural language', 0.4176),\n",
       "  ('inference', 0.4203),\n",
       "  ('simple sequential sentence encoder', 0.6222),\n",
       "  ('natural language inference', 0.6849)],\n",
       " [('networks', 0.435),\n",
       "  ('recurrent', 0.523),\n",
       "  ('recurrent relational networks', 1.0)],\n",
       " [('general purpose module', 0.3527),\n",
       "  ('graph', 0.4011),\n",
       "  ('recurrent', 0.4153),\n",
       "  ('graph representation', 0.5501),\n",
       "  ('recurrent relational network', 0.7806)],\n",
       " [('representations', 0.3769),\n",
       "  ('iclr', 0.4229),\n",
       "  ('sen', 0.437),\n",
       "  ('task learning', 0.4914),\n",
       "  ('tence representations', 0.5637)],\n",
       " [('unsupervised manner', 0.3203),\n",
       "  ('natural language', 0.3996),\n",
       "  ('nlp', 0.4549),\n",
       "  ('vector representations', 0.4894),\n",
       "  ('natural language processing', 0.5359)],\n",
       " [('sequences', 0.3501),\n",
       "  ('words', 0.3905),\n",
       "  ('learning', 0.4146),\n",
       "  ('representations', 0.4317),\n",
       "  ('sentences', 0.4791)],\n",
       " [('learning', 0.3326),\n",
       "  ('sentence', 0.3338),\n",
       "  ('general purpose', 0.3802),\n",
       "  ('representations', 0.4491),\n",
       "  ('purpose sentence representations', 0.7946)],\n",
       " [('question', 0.1437),\n",
       "  ('embeddings', 0.5253),\n",
       "  ('subgraph embeddings', 0.683)],\n",
       " [('mc', 0.3284),\n",
       "  ('texts', 0.345),\n",
       "  ('qa', 0.4451),\n",
       "  ('comprehension', 0.5147),\n",
       "  ('machine comprehension', 0.7003)],\n",
       " [('representations', 0.2882),\n",
       "  ('span', 0.3418),\n",
       "  ('recurrent', 0.361),\n",
       "  ('extractive question', 0.4377),\n",
       "  ('learning recurrent span representations', 0.6405)],\n",
       " [('spans', 0.3824),\n",
       "  ('recurrent', 0.3883),\n",
       "  ('evidence document', 0.3945),\n",
       "  ('recurrent network', 0.539),\n",
       "  ('answer extraction task', 0.6918)],\n",
       " [('story', 0.3096),\n",
       "  ('next', 0.3156),\n",
       "  ('comprehension', 0.4472),\n",
       "  ('story comprehension', 0.7379)],\n",
       " [('comprehension', 0.4141),\n",
       "  ('language understanding', 0.4195),\n",
       "  ('natural language understanding', 0.5028),\n",
       "  ('story comprehension', 0.6787),\n",
       "  ('automatic story comprehension', 0.781)],\n",
       " [('reasons', 0.1156),\n",
       "  ('task', 0.2108),\n",
       "  ('stories', 0.352),\n",
       "  ('challenging task', 0.3672),\n",
       "  ('computational linguists', 0.5882)],\n",
       " [('ability', 0.2306),\n",
       "  ('story', 0.2326),\n",
       "  ('task', 0.235),\n",
       "  ('language', 0.376),\n",
       "  ('language generation', 0.5974)],\n",
       " [('answer', 0.2255),\n",
       "  ('compare', 0.254),\n",
       "  ('aggregate model', 0.3473),\n",
       "  ('latent clustering', 0.4721),\n",
       "  ('answer selection', 0.7074)],\n",
       " [('task', 0.3086),\n",
       "  ('sentence', 0.3276),\n",
       "  ('natural language', 0.4406),\n",
       "  ('natural language processing', 0.5387),\n",
       "  ('answer selection', 0.7501)],\n",
       " [('question', 0.1617),\n",
       "  ('primary objective', 0.3022),\n",
       "  ('artificial intelligence', 0.4686),\n",
       "  ('automatic question', 0.626),\n",
       "  ('qa', 0.6269)],\n",
       " [('coarse', 0.2617),\n",
       "  ('evidence', 0.3545),\n",
       "  ('evidence question', 0.3583),\n",
       "  ('grain fine', 0.379),\n",
       "  ('grain coattention net', 0.5262)],\n",
       " [('single document', 0.2147),\n",
       "  ('document', 0.2221),\n",
       "  ('reasoning', 0.2579),\n",
       "  ('datasets', 0.2603),\n",
       "  ('neural question', 0.2958)],\n",
       " [('text', 0.366),\n",
       "  ('machines', 0.4476),\n",
       "  ('answer questions', 0.466),\n",
       "  ('artificial intelligence', 0.5321),\n",
       "  ('teaching machines', 0.6512)],\n",
       " [('reading comprehension', 0.5682),\n",
       "  ('language understanding', 0.6045),\n",
       "  ('machine reading comprehension', 0.6166),\n",
       "  ('many natural language understanding', 0.6217),\n",
       "  ('natural language understanding', 0.68)],\n",
       " [('mrc', 0.3406),\n",
       "  ('hypothesis', 0.4369),\n",
       "  ('language', 0.4467),\n",
       "  ('language understanding', 0.5924)],\n",
       " [('effective multi', 0.3269),\n",
       "  ('paragraph', 0.4178),\n",
       "  ('comprehension', 0.566),\n",
       "  ('reading comprehension', 0.77),\n",
       "  ('paragraph reading comprehension', 0.8348)],\n",
       " [('models', 0.2741),\n",
       "  ('documents', 0.2859),\n",
       "  ('paragraph', 0.3494),\n",
       "  ('entire documents', 0.3762),\n",
       "  ('neural paragraph', 0.5524)],\n",
       " [('key part', 0.2401),\n",
       "  ('solution', 0.2547),\n",
       "  ('questions', 0.3403),\n",
       "  ('models', 0.3708),\n",
       "  ('neural models', 0.5935)],\n",
       " [('simple', 0.2654),\n",
       "  ('simple web', 0.37),\n",
       "  ('parsing', 0.5836),\n",
       "  ('question answering model', 0.6176),\n",
       "  ('semantic parsing', 0.7053)],\n",
       " [('natural language', 0.3201),\n",
       "  ('natural language inference', 0.4051),\n",
       "  ('attention', 0.481),\n",
       "  ('machine translation', 0.4969),\n",
       "  ('attention mechanisms', 0.5606)],\n",
       " [('learning', 0.313),\n",
       "  ('sentence', 0.3436),\n",
       "  ('deep learning', 0.4503),\n",
       "  ('sentence selection', 0.6221),\n",
       "  ('answer sentence selection', 0.8022)],\n",
       " [('main tasks', 0.3426),\n",
       "  ('research', 0.3448),\n",
       "  ('research interest', 0.3602),\n",
       "  ('tasks', 0.3865),\n",
       "  ('qa', 0.5754)],\n",
       " [('reading comprehension', 0.4348),\n",
       "  ('machine reading', 0.492),\n",
       "  ('answer sentence candidates', 0.6014),\n",
       "  ('sentence selection', 0.6231),\n",
       "  ('answer sentence selection', 0.7514)],\n",
       " [('qa', 0.3312),\n",
       "  ('initial qa system', 0.3654),\n",
       "  ('search engine', 0.4044),\n",
       "  ('as2', 0.5904),\n",
       "  ('as2 model', 0.6107)],\n",
       " [('memory', 0.4186),\n",
       "  ('rnn', 0.4666),\n",
       "  ('rnns', 0.5319),\n",
       "  ('unitary rnns', 0.5617),\n",
       "  ('novel recurrent neural network', 0.6062)],\n",
       " [('lstms', 0.5465),\n",
       "  ('gating units', 0.5645),\n",
       "  ('gated recurrent units', 0.6163),\n",
       "  ('long short term memory', 0.6431),\n",
       "  ('recurrent neural networks', 0.6545)],\n",
       " [('units', 0.3582),\n",
       "  ('recurrent', 0.4042),\n",
       "  ('neural networks', 0.4842),\n",
       "  ('gating units', 0.5816),\n",
       "  ('recurrent neural networks', 0.6517)],\n",
       " [('gradients', 0.2278),\n",
       "  ('learning', 0.2531),\n",
       "  ('main advantage', 0.3042),\n",
       "  ('rnns', 0.5706),\n",
       "  ('conventional rnns', 0.6475)],\n",
       " [('question', 0.2173),\n",
       "  ('answer', 0.2636),\n",
       "  ('product', 0.3031),\n",
       "  ('commerce question', 0.3252),\n",
       "  ('aware answer generation', 0.6805)],\n",
       " [('explosive popularity', 0.2349),\n",
       "  ('popularity', 0.2486),\n",
       "  ('qa', 0.4942),\n",
       "  ('comprehension', 0.4961),\n",
       "  ('reading comprehension', 0.6413)],\n",
       " [('textual entailment', 0.5636),\n",
       "  ('reading comprehension', 0.692),\n",
       "  ('text comprehension', 0.7186),\n",
       "  ('machine reading comprehension', 0.7341),\n",
       "  ('core text comprehension', 0.7703)],\n",
       " [('multi', 0.225),\n",
       "  ('comprehension', 0.5449),\n",
       "  ('reading comprehension', 0.6947),\n",
       "  ('generative reading comprehension', 0.9232),\n",
       "  ('style generative reading comprehension', 0.9282)],\n",
       " [('comprehension', 0.4583),\n",
       "  ('language generation', 0.4604),\n",
       "  ('natural language generation', 0.5177),\n",
       "  ('reading comprehension', 0.5939),\n",
       "  ('generative reading comprehension', 0.7775)],\n",
       " [('model', 0.2863),\n",
       "  ('masque', 0.3011),\n",
       "  ('rc', 0.3326),\n",
       "  ('passage', 0.3801),\n",
       "  ('generative model', 0.504)],\n",
       " [('documents', 0.4113), ('representations', 0.4945), ('sentences', 0.4954)],\n",
       " [('pair', 0.283),\n",
       "  ('sentence', 0.3114),\n",
       "  ('interaction', 0.3677),\n",
       "  ('lstms', 0.5139),\n",
       "  ('sentence pair', 0.5595)],\n",
       " [('networks', 0.273),\n",
       "  ('neural networks', 0.3865),\n",
       "  ('interactions', 0.4132),\n",
       "  ('deep neural networks', 0.4185),\n",
       "  ('sentences', 0.4583)],\n",
       " [('text', 0.3523),\n",
       "  ('relevance', 0.3576),\n",
       "  ('similarity', 0.4391),\n",
       "  ('sentence pair', 0.5302),\n",
       "  ('semantic matching', 0.6778)],\n",
       " [('datasets', 0.3795),\n",
       "  ('critical ai capability', 0.4509),\n",
       "  ('commonsense', 0.5904),\n",
       "  ('test commonsense', 0.666),\n",
       "  ('commonsense reasoning', 0.7214)],\n",
       " [('reasoning', 0.3169),\n",
       "  ('datasets', 0.4765),\n",
       "  ('large datasets', 0.5067),\n",
       "  ('commonsense', 0.5142),\n",
       "  ('commonsense reasoning', 0.6625)],\n",
       " [('swag', 0.3375),\n",
       "  ('multiple choice sentence completion', 0.4347),\n",
       "  ('commonsense question', 0.51),\n",
       "  ('commonsense', 0.5296),\n",
       "  ('commonsense dataset adversarially', 0.6498)],\n",
       " [('comprehension', 0.3826),\n",
       "  ('reader', 0.4113),\n",
       "  ('dynamic chunk reader', 0.5459),\n",
       "  ('reading comprehension', 0.5614),\n",
       "  ('neural reading comprehension', 0.6429)],\n",
       " [('text', 0.3463),\n",
       "  ('related document', 0.3465),\n",
       "  ('comprehension', 0.4917),\n",
       "  ('rcqa', 0.5615),\n",
       "  ('reading comprehension', 0.6091)],\n",
       " [('questions', 0.3428),\n",
       "  ('entities', 0.3453),\n",
       "  ('world qa scenario', 0.4154),\n",
       "  ('rcqa', 0.4282),\n",
       "  ('qa', 0.4357)],\n",
       " [('multi', 0.1452),\n",
       "  ('documents', 0.2749),\n",
       "  ('datasets', 0.2759),\n",
       "  ('comprehension', 0.4574),\n",
       "  ('reading comprehension', 0.6507)],\n",
       " [('question', 0.2112),\n",
       "  ('multiple', 0.3262),\n",
       "  ('facts', 0.3888),\n",
       "  ('reasoning', 0.5487),\n",
       "  ('multiple facts', 0.5851)],\n",
       " [('co', 0.1112),\n",
       "  ('information', 0.2988),\n",
       "  ('sentence', 0.3329),\n",
       "  ('recurrent', 0.3984),\n",
       "  ('semantic sentence matching', 0.6938)],\n",
       " [('paraphrase', 0.4003),\n",
       "  ('natural language', 0.4626),\n",
       "  ('paraphrase identification', 0.5413),\n",
       "  ('natural language inference', 0.6208),\n",
       "  ('various natural language tasks', 0.6307)],\n",
       " [('language model', 0.5682),\n",
       "  ('machine reading comprehension', 0.5696),\n",
       "  ('natural language inference tasks', 0.6246),\n",
       "  ('language model training', 0.6263),\n",
       "  ('language representations', 0.6711)],\n",
       " [('language understanding', 0.4981),\n",
       "  ('language representations', 0.5162),\n",
       "  ('natural language understanding', 0.5178),\n",
       "  ('universal language representations', 0.6701),\n",
       "  ('deep contextual language model', 0.697)],\n",
       " [('multi', 0.2142),\n",
       "  ('reasoning', 0.2889),\n",
       "  ('graph', 0.3732),\n",
       "  ('dynamically fused graph network', 0.7357)],\n",
       " [('question', 0.1204),\n",
       "  ('recent years', 0.1517),\n",
       "  ('text', 0.3237),\n",
       "  ('tbqa', 0.4588)],\n",
       " [('natural language', 0.3745),\n",
       "  ('qa', 0.4242),\n",
       "  ('news qa', 0.4635),\n",
       "  ('comprehension', 0.5241),\n",
       "  ('reading comprehension', 0.6288)],\n",
       " [('question', 0.1679),\n",
       "  ('models', 0.2485),\n",
       "  ('open', 0.2878),\n",
       "  ('weakly supervised embedding models', 0.6675)],\n",
       " [('domain', 0.3513),\n",
       "  ('questions', 0.3561),\n",
       "  ('domain question', 0.3667),\n",
       "  ('building systems', 0.3969),\n",
       "  ('answer questions', 0.4402)],\n",
       " [('representations', 0.3963),\n",
       "  ('language understanding', 0.4269),\n",
       "  ('natural language', 0.4484),\n",
       "  ('natural language understanding', 0.4649),\n",
       "  ('rare words', 0.4869)],\n",
       " [('word', 0.3011),\n",
       "  ('learning', 0.3359),\n",
       "  ('embeddings', 0.6183),\n",
       "  ('word embeddings', 0.7953),\n",
       "  ('compute word embeddings', 0.8812)],\n",
       " [('directional self', 0.3771),\n",
       "  ('language understanding', 0.4259),\n",
       "  ('attention', 0.4309),\n",
       "  ('rnn', 0.4715),\n",
       "  ('attention network', 0.6111)],\n",
       " [('style question', 0.3599),\n",
       "  ('natural language processing', 0.3782),\n",
       "  ('natural language', 0.4189),\n",
       "  ('comprehension', 0.4607),\n",
       "  ('machine comprehension', 0.6616)],\n",
       " [('text', 0.4047),\n",
       "  ('natural language', 0.5108),\n",
       "  ('natural language processing', 0.5461),\n",
       "  ('comprehension', 0.5658),\n",
       "  ('machine comprehension', 0.773)],\n",
       " [('text', 0.356),\n",
       "  ('inference', 0.4183),\n",
       "  ('text processing phil blunsom', 0.6002),\n",
       "  ('neural variational inference', 0.7273)],\n",
       " [('neural question', 0.3076),\n",
       "  ('learning', 0.3089),\n",
       "  ('efficient neural question', 0.4742),\n",
       "  ('representation learning', 0.4835),\n",
       "  ('hyperbolic representation learning', 0.7027)],\n",
       " [('deep neural networks', 0.3317),\n",
       "  ('word', 0.3433),\n",
       "  ('similarity', 0.4636),\n",
       "  ('semantic similarity measurement', 0.6331),\n",
       "  ('pairwise word interaction modeling', 0.7154)],\n",
       " [('sentences', 0.3831),\n",
       "  ('semantics', 0.4182),\n",
       "  ('input sentences', 0.462),\n",
       "  ('similarity', 0.5566),\n",
       "  ('textual similarity measurement', 0.8416)],\n",
       " [('language research', 0.4329),\n",
       "  ('many language processing tasks', 0.4351),\n",
       "  ('similarity', 0.4568),\n",
       "  ('paraphrase generation', 0.5615),\n",
       "  ('semantic textual similarity', 0.744)],\n",
       " [('handcrafted features', 0.4178),\n",
       "  ('few handcrafted features', 0.4234),\n",
       "  ('topics', 0.4353),\n",
       "  ('answer questions', 0.5043),\n",
       "  ('knowledge base', 0.5066)],\n",
       " [('machines', 0.3692),\n",
       "  ('answer questions', 0.4486),\n",
       "  ('natural language', 0.4849),\n",
       "  ('artificial intelligence', 0.4901),\n",
       "  ('teaching machines', 0.5562)],\n",
       " [('query', 0.3518),\n",
       "  ('natural language', 0.4307),\n",
       "  ('open qa', 0.4481),\n",
       "  ('such databases', 0.487),\n",
       "  ('knowledge bases', 0.5455)],\n",
       " [('qa', 0.3571),\n",
       "  ('structured format', 0.3621),\n",
       "  ('kbs', 0.453),\n",
       "  ('open qa', 0.4629),\n",
       "  ('freebase', 0.5128)],\n",
       " [('global self', 0.3026),\n",
       "  ('convolution', 0.4243),\n",
       "  ('attention', 0.4787),\n",
       "  ('reading compre', 0.4824),\n",
       "  ('local convolution', 0.5417)],\n",
       " [('neural networks', 0.4192),\n",
       "  ('rnns', 0.4648),\n",
       "  ('machine reading', 0.5302),\n",
       "  ('end machine reading', 0.5451),\n",
       "  ('recurrent neural networks', 0.5695)],\n",
       " [('tasks', 0.3447),\n",
       "  ('comprehension', 0.5004),\n",
       "  ('machine reading', 0.5921),\n",
       "  ('reading comprehension', 0.6227),\n",
       "  ('machine reading comprehension', 0.7633)],\n",
       " [('self', 0.2866),\n",
       "  ('networks', 0.3076),\n",
       "  ('matching networks', 0.3766),\n",
       "  ('comprehension', 0.4614),\n",
       "  ('reading comprehension', 0.6245)],\n",
       " [('questions', 0.3437),\n",
       "  ('answer questions', 0.3797),\n",
       "  ('comprehension', 0.4338),\n",
       "  ('comprehension style question', 0.5376),\n",
       "  ('reading comprehension', 0.5727)],\n",
       " [('sequence', 0.301),\n",
       "  ('denoising sequence', 0.3189),\n",
       "  ('natural language', 0.3578),\n",
       "  ('language generation', 0.5514),\n",
       "  ('natural language generation', 0.6035)],\n",
       " [('bart', 0.168),\n",
       "  ('models', 0.3266),\n",
       "  ('denoising', 0.3311),\n",
       "  ('sequence', 0.4097),\n",
       "  ('sequence models', 0.573)],\n",
       " [('question', 0.1748),\n",
       "  ('answer', 0.2245),\n",
       "  ('distant supervision', 0.4593),\n",
       "  ('answer justification', 0.6379)],\n",
       " [('ml', 0.3899),\n",
       "  ('learning', 0.3978),\n",
       "  ('model', 0.4149),\n",
       "  ('models', 0.4947),\n",
       "  ('interpretable machine learning', 0.7637)],\n",
       " [('conference paper', 0.363),\n",
       "  ('words', 0.3674),\n",
       "  ('iclr', 0.4647),\n",
       "  ('comprehension', 0.4775),\n",
       "  ('reading comprehension', 0.6413)],\n",
       " [('transfer', 0.2826),\n",
       "  ('shot cross', 0.3225),\n",
       "  ('embeddings', 0.419),\n",
       "  ('lingual transfer', 0.546),\n",
       "  ('sentence embeddings', 0.5561)],\n",
       " [('sentence', 0.245),\n",
       "  ('different scripts', 0.3265),\n",
       "  ('representations', 0.3353),\n",
       "  ('languages', 0.4577),\n",
       "  ('joint multilingual sentence representations', 0.8126)],\n",
       " [('recurrent', 0.4516),\n",
       "  ('summarization', 0.4971),\n",
       "  ('text summarization', 0.5426),\n",
       "  ('abstractive text summarization', 0.7013),\n",
       "  ('deep recurrent generative decoder', 0.7148)],\n",
       " [('pointergenerator style models', 0.42),\n",
       "  ('summarization', 0.4941),\n",
       "  ('abstractive summarization', 0.6551),\n",
       "  ('neural abstractive summarization', 0.8103),\n",
       "  ('neural abstractive summarization models', 0.8433)],\n",
       " [('reader', 0.3205),\n",
       "  ('better summary', 0.4531),\n",
       "  ('summary', 0.4599),\n",
       "  ('reader comments', 0.4999),\n",
       "  ('aware abstractive summary generation', 0.8502)],\n",
       " [('summarization', 0.5159),\n",
       "  ('entailment generation', 0.5182),\n",
       "  ('question generation', 0.5482),\n",
       "  ('summarization model', 0.5769),\n",
       "  ('abstractive summarization', 0.5823)],\n",
       " [('document', 0.2591),\n",
       "  ('models', 0.2722),\n",
       "  ('attention', 0.4693),\n",
       "  ('summarization', 0.5759),\n",
       "  ('fine attention models', 0.7163)],\n",
       " [('entailment', 0.3431),\n",
       "  ('task', 0.3544),\n",
       "  ('summarization', 0.4532),\n",
       "  ('question generation', 0.4928),\n",
       "  ('task summarization', 0.687)],\n",
       " [('relevant auxiliary tasks', 0.4188),\n",
       "  ('task learning', 0.4387),\n",
       "  ('summarization', 0.4913),\n",
       "  ('text summarization', 0.5397),\n",
       "  ('abstractive text summarization', 0.6542)],\n",
       " [('summarization', 0.6696), ('abstractive summarization', 0.8713)],\n",
       " [('natural language', 0.4668),\n",
       "  ('longer text', 0.4825),\n",
       "  ('summarization', 0.6726),\n",
       "  ('natural language summaries', 0.7071),\n",
       "  ('text summarization', 0.7788)],\n",
       " [('content', 0.2965),\n",
       "  ('sequence', 0.36),\n",
       "  ('mixture content selection', 0.6337),\n",
       "  ('sequence generation', 0.6595),\n",
       "  ('diverse sequence generation', 0.8424)],\n",
       " [('target sequences', 0.4678),\n",
       "  ('summarization', 0.4703),\n",
       "  ('many nlp applications', 0.5403),\n",
       "  ('diverse sequences', 0.5734),\n",
       "  ('question generation', 0.6079)],\n",
       " [('sequence', 0.3662),\n",
       "  ('sequences', 0.4227),\n",
       "  ('nlp', 0.5274),\n",
       "  ('source sequence', 0.6002),\n",
       "  ('target sequences', 0.6618)],\n",
       " [('sequence generation', 0.521),\n",
       "  ('machine translation', 0.5307),\n",
       "  ('human translators', 0.548),\n",
       "  ('decoder models', 0.5531),\n",
       "  ('encoder', 0.5563)],\n",
       " [('recurrent', 0.4489),\n",
       "  ('summarization', 0.5431),\n",
       "  ('recurrent neural networks', 0.5782),\n",
       "  ('attentive recurrent neural networks', 0.6281),\n",
       "  ('abstractive sentence summarization', 0.7992)],\n",
       " [('sentence', 0.4539),\n",
       "  ('summary', 0.4767),\n",
       "  ('source sentence', 0.4926),\n",
       "  ('summarization', 0.7167),\n",
       "  ('sentence summarization task', 0.8501)],\n",
       " [('promising results', 0.1639),\n",
       "  ('learning', 0.2553),\n",
       "  ('seq2seq', 0.5114),\n",
       "  ('summarization', 0.5692),\n",
       "  ('seq2seq learning', 0.6639)],\n",
       " [('cutting', 0.0919),\n",
       "  ('generations', 0.2544),\n",
       "  ('summarization', 0.4875),\n",
       "  ('abstractive summarization', 0.6408),\n",
       "  ('neural abstractive summarization', 0.8106)],\n",
       " [('abstractive summarization', 0.4516),\n",
       "  ('language generation', 0.4655),\n",
       "  ('machine translation', 0.481),\n",
       "  ('various natural language generation', 0.5324),\n",
       "  ('natural language generation', 0.5514)],\n",
       " [('retrieve', 0.2288),\n",
       "  ('rewrite', 0.27),\n",
       "  ('rerank', 0.4786),\n",
       "  ('summarization', 0.5417),\n",
       "  ('soft template based neural summarization', 0.8562)],\n",
       " [('intriguing task', 0.3741),\n",
       "  ('shorter version', 0.3788),\n",
       "  ('sentence', 0.4333),\n",
       "  ('summarization', 0.6308),\n",
       "  ('abstractive sentence summarization', 0.8485)],\n",
       " [('variants', 0.1592),\n",
       "  ('sequence', 0.4053),\n",
       "  ('seq2seq', 0.4107),\n",
       "  ('abstractive summarization', 0.6059),\n",
       "  ('summarization', 0.6273)],\n",
       " [('text', 0.4291),\n",
       "  ('passage', 0.4393),\n",
       "  ('condensed version', 0.4716),\n",
       "  ('summarization', 0.6413),\n",
       "  ('text summarization', 0.7278)],\n",
       " [('text', 0.3238),\n",
       "  ('summary', 0.3968),\n",
       "  ('original text document', 0.4359),\n",
       "  ('summarization', 0.6718),\n",
       "  ('automatic summarization', 0.787)],\n",
       " [('context', 0.256),\n",
       "  ('cascade', 0.2866),\n",
       "  ('online social media discussions', 0.4374),\n",
       "  ('sarcasm detection', 0.6814),\n",
       "  ('contextual sarcasm detector', 0.8013)],\n",
       " [('cascade', 0.2992),\n",
       "  ('online discussion forums', 0.4197),\n",
       "  ('sarcasm detection', 0.712),\n",
       "  ('contextual sarcasm detection', 0.8602)],\n",
       " [('level', 0.0703),\n",
       "  ('level analysis', 0.1457),\n",
       "  ('literature', 0.2219),\n",
       "  ('text', 0.2297),\n",
       "  ('sarcasm detection', 0.7491)],\n",
       " [('arguments', 0.3432),\n",
       "  ('predicates', 0.4577),\n",
       "  ('semantic role labeling', 0.7401),\n",
       "  ('neural semantic role labeling', 0.8305)],\n",
       " [('relations', 0.3354),\n",
       "  ('srl', 0.4018),\n",
       "  ('predicateargument relations', 0.5033),\n",
       "  ('semantic role labeling', 0.7222)],\n",
       " [('task', 0.1709),\n",
       "  ('sentence', 0.2748),\n",
       "  ('argument structure', 0.3964),\n",
       "  ('srl', 0.4211)],\n",
       " [('goal', 0.1505),\n",
       "  ('task', 0.2244),\n",
       "  ('parsing', 0.3951),\n",
       "  ('semantic parsing', 0.531),\n",
       "  ('semantic role labeling', 0.7889)],\n",
       " [('language understanding', 0.4281),\n",
       "  ('natural language', 0.4872),\n",
       "  ('natural language understanding', 0.5379),\n",
       "  ('relation extraction', 0.6656),\n",
       "  ('semantic role labeling', 0.703)],\n",
       " [('self', 0.344),\n",
       "  ('attention', 0.4684),\n",
       "  ('semantic role labeling', 0.7276),\n",
       "  ('deep semantic role', 0.7399)],\n",
       " [('language understanding', 0.4387),\n",
       "  ('srl', 0.459),\n",
       "  ('natural language', 0.5182),\n",
       "  ('natural language understanding', 0.5318),\n",
       "  ('semantic role labeling', 0.8046)],\n",
       " [('language', 0.2739),\n",
       "  ('questions', 0.4944),\n",
       "  ('natural language', 0.5423),\n",
       "  ('natural language questions', 0.7589)],\n",
       " [('texts', 0.371),\n",
       "  ('sieve', 0.3749),\n",
       "  ('english texts', 0.3962),\n",
       "  ('relation extraction', 0.5395),\n",
       "  ('causal relation extraction', 0.698)],\n",
       " [('relation', 0.3586),\n",
       "  ('temporal relation', 0.5022),\n",
       "  ('structured learning approach', 0.543),\n",
       "  ('relation extraction', 0.7097),\n",
       "  ('temporal relation extraction', 0.8707)],\n",
       " [('events', 0.5077),\n",
       "  ('language understanding', 0.5651),\n",
       "  ('natural language', 0.5959),\n",
       "  ('temporal relations', 0.5999),\n",
       "  ('natural language understanding', 0.6716)],\n",
       " [('time expression', 0.4202),\n",
       "  ('fundamental tasks', 0.4664),\n",
       "  ('timex', 0.4891),\n",
       "  ('temporal relation', 0.5807),\n",
       "  ('temporal processing', 0.7315)],\n",
       " [('image', 0.2813),\n",
       "  ('phrase', 0.2844),\n",
       "  ('common semantic space', 0.5447),\n",
       "  ('phrase grounding', 0.6605),\n",
       "  ('level multimodal common semantic space', 0.765)],\n",
       " [('learning', 0.3095),\n",
       "  ('phrase', 0.3212),\n",
       "  ('visual modalities', 0.4464),\n",
       "  ('common semantic space', 0.5867),\n",
       "  ('phrase grounding', 0.6693)],\n",
       " [('extraction', 0.3311),\n",
       "  ('relations', 0.41),\n",
       "  ('entity', 0.4309),\n",
       "  ('joint extraction', 0.4523),\n",
       "  ('entity mentions', 0.6388)],\n",
       " [('relations', 0.3178),\n",
       "  ('entities', 0.4295),\n",
       "  ('nlp', 0.4693),\n",
       "  ('structured prediction', 0.6095),\n",
       "  ('structured prediction tasks', 0.6746)],\n",
       " [('extraction', 0.3307),\n",
       "  ('entity', 0.3712),\n",
       "  ('entity mention', 0.5574),\n",
       "  ('sentencelevel', 0.5844),\n",
       "  ('relation extraction', 0.7095)],\n",
       " [('learning', 0.2721),\n",
       "  ('similarity', 0.4271),\n",
       "  ('relation', 0.4424),\n",
       "  ('distributional similarity', 0.5498),\n",
       "  ('relation learning', 0.7885)],\n",
       " [('text', 0.3099),\n",
       "  ('relations', 0.4656),\n",
       "  ('entities', 0.4742),\n",
       "  ('natural language', 0.5195),\n",
       "  ('natural language processing', 0.6505)],\n",
       " [('entities', 0.3911),\n",
       "  ('extraction', 0.3944),\n",
       "  ('target entities', 0.4213),\n",
       "  ('relation', 0.4633),\n",
       "  ('relation extraction', 0.7947)],\n",
       " [('dependency', 0.2734),\n",
       "  ('graph', 0.2801),\n",
       "  ('graph convolution', 0.4557),\n",
       "  ('relation', 0.4655),\n",
       "  ('relation extraction', 0.6958)],\n",
       " [('extraction', 0.3541),\n",
       "  ('entity', 0.3827),\n",
       "  ('relation', 0.4393),\n",
       "  ('semantic relationships', 0.577),\n",
       "  ('relation extraction', 0.773)],\n",
       " [('multiple pairs', 0.3386),\n",
       "  ('relations', 0.3892),\n",
       "  ('mre', 0.3932),\n",
       "  ('entity mentions', 0.4756),\n",
       "  ('multiplerelations extraction', 0.6436)],\n",
       " [('ability', 0.0772),\n",
       "  ('documents', 0.3291),\n",
       "  ('facts', 0.3696),\n",
       "  ('knowledge', 0.3977),\n",
       "  ('knowledge bases', 0.5843)],\n",
       " [('language understanding', 0.5212),\n",
       "  ('natural language', 0.5772),\n",
       "  ('relational facts', 0.5805),\n",
       "  ('knowledge base', 0.663),\n",
       "  ('natural language understanding', 0.6716)],\n",
       " [('information', 0.2406),\n",
       "  ('side information', 0.3563),\n",
       "  ('relation', 0.3817),\n",
       "  ('relation extraction', 0.6165),\n",
       "  ('neural relation extraction', 0.7397)],\n",
       " [('relation', 0.4516),\n",
       "  ('knowledge base', 0.487),\n",
       "  ('unstructured text', 0.4976),\n",
       "  ('relation instances', 0.509),\n",
       "  ('relation extraction', 0.7918)],\n",
       " [('classification', 0.2883),\n",
       "  ('attention', 0.3262),\n",
       "  ('cnns', 0.3864),\n",
       "  ('relation', 0.5189),\n",
       "  ('relation classification', 0.7543)],\n",
       " [('extraction', 0.2465),\n",
       "  ('sentence noise reduction', 0.4342),\n",
       "  ('relation', 0.4717),\n",
       "  ('relation extraction', 0.6805),\n",
       "  ('neural relation extraction', 0.8628)],\n",
       " [('raw texts', 0.4278),\n",
       "  ('marked entities', 0.4499),\n",
       "  ('relation', 0.4704),\n",
       "  ('relations', 0.5228),\n",
       "  ('relation extraction', 0.8267)],\n",
       " [('previous studies', 0.1962),\n",
       "  ('extraction', 0.2606),\n",
       "  ('relation', 0.4284),\n",
       "  ('relation extraction', 0.6523),\n",
       "  ('distant supervised relation extraction', 0.8358)],\n",
       " [('one', 0.1545),\n",
       "  ('multiple', 0.2498),\n",
       "  ('pass', 0.2515),\n",
       "  ('transformers', 0.4294),\n",
       "  ('relations', 0.4474)],\n",
       " [('relations', 0.33),\n",
       "  ('paragraph', 0.3307),\n",
       "  ('entity', 0.4571),\n",
       "  ('input paragraph', 0.4616),\n",
       "  ('multiple entity', 0.5167)],\n",
       " [('multiple', 0.2024),\n",
       "  ('extraction', 0.265),\n",
       "  ('corpus', 0.3907),\n",
       "  ('input corpus', 0.415),\n",
       "  ('multiple entityrelations extraction task', 0.7914)],\n",
       " [('entity', 0.3713),\n",
       "  ('relation', 0.4477),\n",
       "  ('entity mentions', 0.5497),\n",
       "  ('semantic relation', 0.5824),\n",
       "  ('relation extraction', 0.7224)],\n",
       " [('effective solution', 0.2561),\n",
       "  ('applications', 0.2582),\n",
       "  ('entities', 0.307),\n",
       "  ('input paragraphs', 0.4309),\n",
       "  ('mre', 0.5149)],\n",
       " [('extraction', 0.2689),\n",
       "  ('convolutional neural networks', 0.3383),\n",
       "  ('relation', 0.4259),\n",
       "  ('distant supervision', 0.4773),\n",
       "  ('relation extraction', 0.6547)],\n",
       " [('relation', 0.3697),\n",
       "  ('aware representations', 0.4102),\n",
       "  ('knowledge base', 0.5688),\n",
       "  ('relation extraction', 0.7127),\n",
       "  ('knowledge base relation extraction', 0.8362)],\n",
       " [('relations', 0.4682),\n",
       "  ('other relations', 0.4903),\n",
       "  ('target relation', 0.5089),\n",
       "  ('level relation extraction', 0.6503),\n",
       "  ('relation extraction', 0.7055)],\n",
       " [('target entity pair', 0.5215),\n",
       "  ('target relation', 0.5674),\n",
       "  ('relation instance', 0.5798),\n",
       "  ('relation extraction', 0.7127),\n",
       "  ('sentential relation extraction task', 0.8255)]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "research_problem_model.extract_keywords(docs=train_docs, vectorizer=KeyphraseCountVectorizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4e6cfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python385jvsc74a57bd0cc0b39b73e6949057e82e0fccf6b8b6674bf387641e811617d69795976e90112"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
